[
  {
    "id": "BL-002",
    "title": "[BL-002] RunEvent Schema Extensions",
    "body": "# [BL-002] RunEvent Schema Extensions\n**Labels:** `type:infrastructure`, `phase:0-foundation`, `priority:critical-path`, `track:infrastructure`, `size:S`\n**Milestone:** M0: Foundation\n**Blocked By:** None\n**Blocks:** BL-001, BL-007, BL-014, BL-016, BL-020, BL-021\n\n**Body:**\n## Overview\nExtend the existing RunEvent type enum with 19 new event types covering planning, subagent fan-out, streaming content, artifacts, clarification, report generation progress, and web research events. This is the foundational schema change that all orchestrator and frontend work depends on.\n\n## Acceptance Criteria\n- [ ] All 19 new event types added to `RunEventType` enum in both `schemas/runs.py` and `db/models/runs.py`\n- [ ] Typed `log_*` helper methods added to `LedgerService` for each new event type, following existing `async def log_*(self, run_id, ...) -> RunEvent` pattern\n- [ ] All new event types round-trip through the ledger (create, read back)\n- [ ] New events appear correctly in the SSE stream via PG LISTEN/NOTIFY\n- [ ] Existing event types and all existing tests remain unaffected\n- [ ] Payload shapes documented as Python TypedDict or Pydantic models\n\n## Technical Notes\n- Existing types to keep: STATE_UPDATE, TOOL_CALL_*, STEP_*\n- New types: PLAN_CREATED, PLAN_TASK_STARTED, PLAN_TASK_COMPLETED, PLAN_TASK_FAILED, SUBAGENT_DISPATCHED, SUBAGENT_COMPLETED, SUBAGENT_FAILED, CONTENT_DELTA, ARTIFACT_CREATED, CLARIFICATION_NEEDED, CLARIFICATION_RECEIVED, REPORT_PREVIEW_START, REPORT_PREVIEW_DELTA, REPORT_PREVIEW_DONE, WEB_SEARCH_STARTED, WEB_SEARCH_COMPLETED, WEB_SCRAPE_STARTED, WEB_SCRAPE_COMPLETED, REFERENCES_FOUND\n- Files to modify: `src/intelli/schemas/runs.py`, `src/intelli/db/models/runs.py`, `src/intelli/services/runs/ledger_service.py`\n- See IMPLEMENTATION-PLAN.md Section 0.2 for full payload schemas\n\n## References\n- BACKLOG.md: BL-002\n- IMPLEMENTATION-PLAN.md: Section 0.2\n\n---",
    "labels": [
      "type:infrastructure",
      "phase:0-foundation",
      "priority:critical-path",
      "track:infrastructure",
      "size:S"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [
      "BL-001",
      "BL-007",
      "BL-014",
      "BL-016",
      "BL-020",
      "BL-021"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-004",
    "title": "[BL-004] NYQST Markup AST Schema",
    "body": "# [BL-004] NYQST Markup AST Schema\n**Labels:** `type:infrastructure`, `phase:0-foundation`, `priority:critical-path`, `track:deliverables`, `size:M`\n**Milestone:** M0: Foundation\n**Blocked By:** None\n**Blocks:** BL-005, BL-009, BL-019\n\n**Body:**\n## Overview\nCreate the Pydantic model definitions for the NYQST Markup AST -- a document tree with 18 node types that represents structured reports. This is the intermediate representation between LLM output and rendered deliverables. Includes a MarkupHealer that auto-repairs invalid trees.\n\n## Acceptance Criteria\n- [ ] `MarkupNodeType` enum with all 18 node types (document, section, columns, column, heading, paragraph, blockquote, table, table_row, table_cell, chart, image, list, list_item, code_block, inline, metric_card, callout)\n- [ ] `MarkupNode` model with type, attrs, children, text, and citation_ids fields\n- [ ] `MarkupDocument` model with version, title, nodes, and metadata\n- [ ] `MarkupHealer.heal()` coerces unknown node types to PARAGRAPH\n- [ ] `MarkupHealer.validate()` returns list of validation warnings\n- [ ] Round-trip `JSON -> MarkupDocument -> JSON` is stable (idempotent)\n- [ ] `MarkupDocument.model_validate(json)` works for all 18 node types\n\n## Technical Notes\n- Net-new file: `src/intelli/schemas/markup.py`\n- Chart node attrs: chart_type, data, config\n- Heading node attrs: level (1-6)\n- Inline node attrs: bold, italic, code, href, citation_id\n- Metric_card node attrs: label, value, delta, trend\n- Callout node attrs: type (info/warn/error/success)\n- See IMPLEMENTATION-PLAN.md Section 0.3 for full schema\n\n## References\n- BACKLOG.md: BL-004\n- IMPLEMENTATION-PLAN.md: Section 0.3\n\n---",
    "labels": [
      "type:infrastructure",
      "phase:0-foundation",
      "priority:critical-path",
      "track:deliverables",
      "size:M"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [
      "BL-005",
      "BL-009",
      "BL-019"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-008",
    "title": "[BL-008] DeliverableSelector Component",
    "body": "# [BL-008] DeliverableSelector Component\n**Labels:** `type:frontend`, `phase:0-foundation`, `priority:medium`, `track:frontend`, `size:S`\n**Milestone:** M0: Foundation\n**Blocked By:** BL-015 (weak \u2014 DeliverableSelector writes to useDeliverableStore)\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a segmented control component positioned above the chat composer that lets users select the deliverable type (Report, Website, Slides, Document) before submitting a research query. Selection is stored in the DeliverableStore and included as `deliverable_type` on the user message payload.\n\n## Acceptance Criteria\n- [ ] Segmented control renders with 4 options: Report | Website | Slides | Document\n- [ ] Each segment has an appropriate Lucide icon (FileText, Globe, Presentation, FileDown)\n- [ ] Selection updates `useDeliverableStore().selectedType`\n- [ ] Chat submit handler includes `deliverable_type` in the message request payload\n- [ ] Selector auto-clears after submission (follow-up messages send `null`)\n- [ ] Uses existing shadcn/ui ToggleGroup component\n\n## Technical Notes\n- Net-new file: `ui/src/components/chat/DeliverableSelector.tsx`\n- Modify existing chat submit handler in ChatPanel.tsx to include deliverable_type\n- Per chat export analysis: `deliverable_type` is on the user Message, not the Conversation\n- Follow-up messages without explicit selection default to null\n\n## References\n- BACKLOG.md: BL-008\n- IMPLEMENTATION-PLAN.md: Section 3.2\n\n---",
    "labels": [
      "type:frontend",
      "phase:0-foundation",
      "priority:medium",
      "track:frontend",
      "size:S"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [
      "BL-015"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-015",
    "title": "[BL-015] DeliverableStore (Zustand)",
    "body": "# [BL-015] DeliverableStore (Zustand)\n**Labels:** `type:frontend`, `phase:0-foundation`, `priority:medium`, `track:frontend`, `size:XS`\n**Milestone:** M0: Foundation\n**Blocked By:** None\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate the 6th Zustand store to manage deliverable selection state and active preview state. Tracks which deliverable type is selected, whether generation is in progress, current generation phase label, and async entity creation status.\n\n## Acceptance Criteria\n- [ ] Store interface includes: selectedType, activePreview (artifactSha256, manifestSha256, isGenerating, generationPhase, generationProgress, hasAsyncEntitiesInProgress)\n- [ ] All action methods typed: setSelectedType, setGenerationPhase, setActiveArtifact, setAsyncEntitiesInProgress, clearPreview\n- [ ] Store compiles with no TypeScript errors\n- [ ] Exported correctly alongside existing 5 stores\n\n## Technical Notes\n- Net-new file: `ui/src/stores/deliverable-store.ts`\n- Existing stores: auth-store.ts, conversation-store.ts, workbench-store.ts, run-store.ts, tour-store.ts\n- `generationProgress` is 0-100 numeric\n- `generationPhase` is human-readable string like \"Writing outline...\" or \"Building components...\"\n\n## References\n- BACKLOG.md: BL-015\n- IMPLEMENTATION-PLAN.md: Section 3.1\n\n---",
    "labels": [
      "type:frontend",
      "phase:0-foundation",
      "priority:medium",
      "track:frontend",
      "size:XS"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-012",
    "title": "[BL-012] Billing System",
    "body": "# [BL-012] Billing System\n**Labels:** `type:billing`, `phase:4-billing`, `priority:high`, `track:billing`, `size:L`\n**Milestone:** M4: Billing & Polish\n**Blocked By:** MIG-0005C (billing tables)\n**Blocks:** BL-013\n\n**Body:**\n## Overview\nPort and adapt the Stripe billing system from okestraai/DocuIntelli to the NYQST platform. Implements checkout sessions, webhook processing, subscription management, and per-run usage tracking. Billing unit: 1 run = 1 AI message generation; reads are free.\n\n## Acceptance Criteria\n- [ ] `POST /api/v1/billing/checkout` creates a Stripe checkout session for Pro plan ($20/month)\n- [ ] `POST /api/v1/billing/webhook` processes Stripe events with signature verification (checkout.session.completed, customer.subscription.updated, customer.subscription.deleted, invoice.payment_succeeded, invoice.payment_failed)\n- [ ] `GET /api/v1/billing/subscription` returns current plan, status, and period end date\n- [ ] `GET /api/v1/billing/usage` returns run count for current billing period\n- [ ] `POST /api/v1/billing/portal` returns Stripe customer portal URL\n- [ ] Usage record created per run creation (not per retry -- check retry_attempts)\n- [ ] Plan limits enforced: free=5 runs/month + 2 reports, pro=200 runs/month + $0.50/run overage\n\n## Technical Notes\n- Source: okestraai/DocuIntelli (public GitHub) -- port Stripe code, adapt from Supabase to SQLAlchemy\n- New files: `src/intelli/api/v1/billing.py`, `src/intelli/services/billing/{stripe_service,subscription_service,usage_service}.py`, `src/intelli/db/models/billing.py`\n- Billing tables (subscriptions, usage_records) already created in migration 0005 (Phase 0)\n- Existing `Run.cost_cents` and `Run.token_usage` JSONB fields available for cost tracking\n- Config vars: STRIPE_SECRET_KEY, STRIPE_WEBHOOK_SECRET, STRIPE_PRICE_ID\n\n### Sub-Issues\n\n#### [BL-012a] Billing ORM Models and Schemas\n**Labels:** `type:infrastructure`, `phase:4-billing`, `priority:high`, `track:billing`, `size:S`\n- Create SQLAlchemy models for subscriptions and usage_records tables (already in migration 0005)\n- Create Pydantic request/response schemas for billing endpoints\n\n#### [BL-012b] Stripe Service Layer\n**Labels:** `type:integration`, `phase:4-billing`, `priority:high`, `track:billing`, `size:M`\n- Implement StripeService: create_checkout_session, create_portal_session, construct_webhook_event\n- Implement SubscriptionService: create/update/cancel subscription from webhook events\n- Implement UsageService: record_usage, get_period_usage, check_quota\n\n#### [BL-012c] Billing API Routes\n**Labels:** `type:backend`, `phase:4-billing`, `priority:high`, `track:billing`, `size:S`\n- Create all 5 billing endpoints in billing.py router\n- Register router in `api/v1/__init__.py`\n- Webhook endpoint: no JWT auth, Stripe signature verification only\n\n#### [BL-012d] Billing Integration Tests\n**Labels:** `type:test`, `phase:4-billing`, `priority:high`, `track:billing`, `size:S`\n- Mock Stripe webhook payloads, verify subscription state transitions\n- Test usage recording per run\n- Test quota checking logic\n\n## References\n- BACKLOG.md: BL-012\n- IMPLEMENTATION-PLAN.md: Section 4.1\n- Source repo: okestraai/DocuIntelli\n\n---\n\n### Wave 1: Depends on Wave 0 items\n\n---",
    "labels": [
      "type:billing",
      "phase:4-billing",
      "priority:high",
      "track:billing",
      "size:L"
    ],
    "milestone": "M4: Billing & Polish",
    "blocked_by": [
      "MIG-0005C"
    ],
    "blocks": [
      "BL-013"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-001",
    "title": "[BL-001] Research Orchestrator Graph",
    "body": "# [BL-001] Research Orchestrator Graph\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:XL`\n**Milestone:** M1: Orchestrator\n**Blocked By:** BL-002\n**Blocks:** BL-003, BL-005, BL-006, BL-017, BL-018, BL-021, BL-022\n\n**Body:**\n## Overview\nExtend the existing ResearchAssistantGraph (not replace it) with a planner node, Send() fan-out to parallel research workers, fan-in aggregation, synthesis node, and deliverable router. This transforms the current single-agent loop into a multi-workstream orchestrator that mirrors Superagent's 13+ parallel task pattern. The existing agent/tools/capture_sources loop is preserved and wrapped by the new research_worker_node.\n\n## Acceptance Criteria\n- [ ] Planner node decomposes query into 3-13 ResearchTask dicts and emits PLAN_CREATED event\n- [ ] Fan-out dispatches Send() per task, each creating a child Run with parent_run_id FK\n- [ ] Research workers execute in parallel using existing agent+tools loop\n- [ ] Fan-in node aggregates all TaskResult dicts\n- [ ] Synthesis node produces structured DataBrief in graph state\n- [ ] Deliverable router routes by deliverable_type to appropriate generation node\n- [ ] SSE stream shows: PLAN_CREATED, N x SUBAGENT_DISPATCHED, N x PLAN_TASK_*, STATE_UPDATE, CHECKPOINT\n- [ ] AI message hydrated_content contains `<gml-View*>` components\n- [ ] Failed tasks emit PLAN_TASK_FAILED without crashing the run\n- [ ] All existing graph tests continue to pass\n\n## Technical Notes\n- Extends: `src/intelli/agents/graphs/research_assistant.py`\n- Existing graph: agent -> (tools_condition) -> tools -> capture_sources -> agent (loop)\n- New nodes: planner_node, fan_out, research_worker_node, fan_in_node, synthesis_node, deliverable_router\n- Entry point: modify existing `POST /api/v1/agent/chat` or add `POST /api/v1/runs/research`\n- research_worker_node creates child Run via `Run(parent_run_id=state[\"run_id\"])` -- self-referential FK\n- LLM system prompt must enforce `<answer>...</answer>` wrapping with `<gml-*>` component refs\n- See IMPLEMENTATION-PLAN.md Section 1.2 for full graph diagram\n\n### Sub-Issues\n\n#### [BL-001a] ResearchState Extension\n**Labels:** `type:infrastructure`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:S`\n- Extend ResearchState dataclass with: query, deliverable_type, plan, task_results, data_brief, web_sources, meta_reasoning_done, clarification_pending, output_artifact_sha256, child_run_ids\n- All new fields must have defaults (backward-compatible)\n\n#### [BL-001b] Planner Node\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:M`\n- LLM call to decompose query + deliverable_type into ResearchTask list\n- Emit PLAN_CREATED event via LedgerService\n- System prompt for structured JSON output of task decomposition\n\n#### [BL-001c] Fan-Out / Fan-In Infrastructure\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:L`\n- Fan-out: returns `[Send(\"research_worker_node\", {...}) for t in plan]`\n- Research worker node: wraps existing agent+tools loop, creates child Run with parent_run_id\n- Fan-in: accumulates TaskResult dicts, emits SUBAGENT_COMPLETED per task\n- Handle per-node async DB session lifecycle (no shared session across parallel nodes)\n\n#### [BL-001d] Synthesis Node and Deliverable Router\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:M`\n- Synthesis: LLM call to produce DataBrief from all TaskResults\n- Deliverable router: conditional edge routing by state[\"deliverable_type\"]\n- Wire to placeholder nodes for report/website/slides/document (implemented in Phase 2)\n\n#### [BL-001e] Integration Tests and Event Verification\n**Labels:** `type:test`, `phase:1-orchestrator`, `priority:high`, `track:orchestrator`, `size:M`\n- End-to-end test with real LLM: submit query, verify full event sequence in SSE\n- Verify DataBrief populated in final state\n- Verify child Run records have correct parent_run_id\n- Contract test: ResearchState backward-compat with existing tests\n\n## References\n- BACKLOG.md: BL-001\n- IMPLEMENTATION-PLAN.md: Sections 1.1, 1.2\n\n---",
    "labels": [
      "type:feature",
      "phase:1-orchestrator",
      "priority:critical-path",
      "track:orchestrator",
      "size:XL"
    ],
    "milestone": "M1: Orchestrator",
    "blocked_by": [
      "BL-002"
    ],
    "blocks": [
      "BL-003",
      "BL-005",
      "BL-006",
      "BL-017",
      "BL-018",
      "BL-021",
      "BL-022"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-007",
    "title": "[BL-007] PlanViewer Component",
    "body": "# [BL-007] PlanViewer Component\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:high`, `track:frontend`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-002\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a plan visualization component showing numbered task cards with live status indicators, inspired by Superagent's activity panel. Tasks are grouped by phase and update in real-time via SSE events. Renders in a new \"Plan\" tab within the existing DetailsPanel.\n\n## Acceptance Criteria\n- [ ] Task cards appear immediately on receiving PLAN_CREATED event\n- [ ] Each card shows: numbered badge, task name, phase grouping header\n- [ ] Status updates live: pending (gray) -> processing (amber) -> completed (green) / failed (red)\n- [ ] Failed tasks show error message in tooltip\n- [ ] Duration shown on completed tasks\n- [ ] Renders in new \"Plan\" tab in DetailsPanel.tsx\n- [ ] Empty state when no plan exists for the current run\n\n## Technical Notes\n- Net-new file: `ui/src/components/plans/PlanViewer.tsx`\n- Data source: PLAN_CREATED (initial list), PLAN_TASK_STARTED/COMPLETED/FAILED (live updates)\n- Modify: `ui/src/components/workbench/DetailsPanel.tsx` to add Plan tab\n- Event wiring via existing `use-sse.ts` hook\n- Left border color indicates status; visual style per IMPLEMENTATION-PLAN.md Section 3.4\n\n## References\n- BACKLOG.md: BL-007\n- IMPLEMENTATION-PLAN.md: Section 3.4\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:high",
      "track:frontend",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-002"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-014",
    "title": "[BL-014] Enhanced RunTimeline",
    "body": "# [BL-014] Enhanced RunTimeline\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:medium`, `track:frontend`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-002\n**Blocks:** None\n\n**Body:**\n## Overview\nEnhance the existing RunTimeline/TimelinePanel to render all 19 new BL-002 event types with proper icons, labels, phase grouping, and subagent task cards. The timeline should remain flat for runs without a plan and group by phases when PLAN_CREATED is present.\n\n## Acceptance Criteria\n- [ ] All 19 new event types have distinct icons and human-readable labels (no raw enum fallback)\n- [ ] Events grouped under collapsible phase headers when PLAN_CREATED is present\n- [ ] Subagent task rows show compact card with task name, duration, tool call count\n- [ ] CONTENT_DELTA events collapsed by default (expandable)\n- [ ] Child run events surfaced inline under parent subagent card\n- [ ] Timeline remains flat for runs without a plan (backward compatible)\n\n## Technical Notes\n- Check which file is active: `ui/src/components/workbench/TimelinePanel.tsx` vs `components/runs/RunTimeline.tsx`\n- Extends existing component -- do not create a new timeline\n- Phase grouping uses the phases array from PLAN_CREATED event payload\n\n## References\n- BACKLOG.md: BL-014\n- IMPLEMENTATION-PLAN.md: Section 3.5\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:medium",
      "track:frontend",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-002"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-020",
    "title": "[BL-020] Generation Progress Overlay",
    "body": "# [BL-020] Generation Progress Overlay\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:high`, `track:frontend`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-002\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a full-screen overlay that shows generation progress with dual-status display (primary action + substep), continuous progress indicator, and phase labels. Users tolerate 2+ minute waits when they see visible progress. Also handles the \"Creating notes...\" secondary state for async entity creation.\n\n## Acceptance Criteria\n- [ ] Overlay appears on REPORT_PREVIEW_START event, hides on REPORT_PREVIEW_DONE\n- [ ] Shows deliverable type (\"Generating your report...\", \"Building your website...\")\n- [ ] Phase label updates in real-time from REPORT_PREVIEW_DELTA payload\n- [ ] Animated spinner and indeterminate progress bar displayed\n- [ ] Secondary \"Creating notes...\" indicator shown while hasAsyncEntitiesInProgress is true\n- [ ] Updates DeliverableStore: isGenerating, generationPhase, generationProgress\n- [ ] Sets activePreview.artifactSha256 on REPORT_PREVIEW_DONE\n\n## Technical Notes\n- Net-new file: `ui/src/components/generation/GenerationOverlay.tsx`\n- Wired to existing SSE via `use-sse.ts` hook -- do NOT add a new streaming mechanism\n- Integrates with DeliverableStore (BL-015) for state management\n- See IMPLEMENTATION-PLAN.md Section 3.3 for visual mockup\n\n## References\n- BACKLOG.md: BL-020\n- IMPLEMENTATION-PLAN.md: Section 3.3\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:high",
      "track:frontend",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-002"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-016",
    "title": "[BL-016] Entity/Citation Substrate",
    "body": "# [BL-016] Entity/Citation Substrate\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:infrastructure`, `size:M`\n**Milestone:** M2: Deliverables\n**Blocked By:** BL-002, MIG-0005A (entity_type + tags columns)\n**Blocks:** BL-011\n\n**Body:**\n## Overview\nComplete the entity/citation service layer on top of the Artifact model. Migration 0005 (Phase 0) adds entity_type and tags columns to Artifact. This task builds the service that creates entity artifacts from REFERENCES_FOUND events, provides deduplication via URL hashing, and exposes a per-run entities API endpoint. Entity creation runs asynchronously via the existing arq + Redis job queue.\n\n> **Note:** BL-005 is a soft dependency for citation-binding integration testing only.\n\n## Acceptance Criteria\n- [ ] `create_entity_artifact(url, title, snippet, entity_type)` helper in ArtifactService\n- [ ] Deduplication: entity artifacts keyed by sha256 of canonical URL in `tags[\"canonical_id\"]`\n- [ ] Async entity creation: REFERENCES_FOUND event dispatches arq background job\n- [ ] `GET /api/v1/runs/{run_id}/entities` returns entities grouped by entity_type\n- [ ] Citation IDs in generated reports resolve to entity artifacts\n- [ ] Existing artifact operations unaffected\n\n## Technical Notes\n- Extends: `src/intelli/services/substrate/artifact_service.py`\n- New endpoint in: `src/intelli/api/v1/runs.py`\n- Async job in: `src/intelli/core/jobs.py` (arq + Redis already configured)\n- ArtifactEntityType enum: WEB_SOURCE, API_DATA, GENERATED_CONTENT, GENERATED_REPORT, GENERATED_WEBSITE, GENERATED_PRESENTATION, GENERATED_DOCUMENT, KNOWLEDGE_BASE, USER_UPLOAD, CITATION_BUNDLE\n- Decision: extend Artifact with entity_type field (not new table) -- avoids schema proliferation\n\n## References\n- BACKLOG.md: BL-016\n- IMPLEMENTATION-PLAN.md: Section 2.2\n\n---\n\n### Wave 2: Depends on BL-001 (orchestrator) and/or BL-004 (markup AST)\n\n---",
    "labels": [
      "type:feature",
      "phase:2-deliverables",
      "priority:high",
      "track:infrastructure",
      "size:M"
    ],
    "milestone": "M2: Deliverables",
    "blocked_by": [
      "BL-002",
      "MIG-0005A"
    ],
    "blocks": [
      "BL-011"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-003",
    "title": "[BL-003] Web Research MCP Tools",
    "body": "# [BL-003] Web Research MCP Tools\n**Labels:** `type:integration`, `phase:1-orchestrator`, `priority:critical-path`, `track:orchestrator`, `size:M`\n**Milestone:** M1: Orchestrator\n**Blocked By:** None (standalone tools); BL-001 (integration wiring into orchestrator)\n**Blocks:** BL-011\n\n**Body:**\n## Overview\nAdd web research tools (Brave Search and Jina Reader) to the agent's tool arsenal. These are registered as MCP tools alongside the existing search_documents, list_notebooks, get_document_info, and compare_manifests. Each invocation emits the corresponding WEB_SEARCH_* / WEB_SCRAPE_* RunEvents via the ledger.\n\n> **Note:** Brave/Jina API wrappers can be built and tested independently in Wave 0. Integration into research_worker_node requires BL-001 (Wave 2).\n\n## Acceptance Criteria\n- [ ] `brave_web_search(query, count)` returns search results from Brave Search API\n- [ ] `jina_web_scrape(url)` returns cleaned text content from Jina Reader API\n- [ ] Both tools registered in MCP server alongside existing tools\n- [ ] WEB_SEARCH_STARTED/COMPLETED events emitted on each search invocation\n- [ ] WEB_SCRAPE_STARTED/COMPLETED events emitted on each scrape invocation\n- [ ] Timeouts configured: 15s for Brave, 30s for Jina\n- [ ] API keys read from config: BRAVE_SEARCH_API_KEY, JINA_API_KEY\n\n## Technical Notes\n- Net-new MCP registration file: `src/intelli/mcp/tools/research_tools.py` (distinct from `agents/tools/research_tools.py`)\n- Register in `src/intelli/mcp/server.py`\n- Brave endpoint: `https://api.search.brave.com/res/v1/web/search`\n- Jina endpoint: `https://r.jina.ai/{url}`\n- Uses httpx.AsyncClient for both\n- See IMPLEMENTATION-PLAN.md Section 1.3 for implementation detail\n\n## References\n- BACKLOG.md: BL-003\n- IMPLEMENTATION-PLAN.md: Section 1.3\n\n---",
    "labels": [
      "type:integration",
      "phase:1-orchestrator",
      "priority:critical-path",
      "track:orchestrator",
      "size:M"
    ],
    "milestone": "M1: Orchestrator",
    "blocked_by": [
      "BL-001"
    ],
    "blocks": [
      "BL-011"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-022",
    "title": "[BL-022] Shared Data Brief",
    "body": "# [BL-022] Shared Data Brief\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:high`, `track:orchestrator`, `size:S`\n**Milestone:** M1: Orchestrator\n**Blocked By:** None (design phase)\n**Blocks:** None\n\n**Body:**\n## Overview\nDesign and implement the shared data brief -- a structured intermediate representation produced by the synthesis node that all downstream generators reference for data consistency. This is a LangGraph state field, not a new table. The brief ensures 100% data consistency (same numbers across all deliverable files), mirroring Superagent's pattern.\n\n> **Note:** DataBrief schema design must precede BL-001 (feeds into ResearchState). Integration testing requires BL-001.\n\n## Acceptance Criteria\n- [ ] DataBrief shape defined: key_facts, entities (name/type/value/source_url), financial_figures (label/value/unit/source_url), summary\n- [ ] DataBrief populated by synthesis_node from aggregated TaskResults\n- [ ] DataBrief appears in final graph state after a test run\n- [ ] Downstream deliverable nodes receive DataBrief via state (not re-fetched)\n- [ ] Existing graph tests unaffected\n\n## Technical Notes\n- DataBrief is a dict in `ResearchState.data_brief` (LangGraph state field)\n- Option (a) chosen: state carries it naturally, no new table or artifact needed\n- Synthesis node uses LLM to extract structured facts from raw TaskResults\n- See IMPLEMENTATION-PLAN.md Section 1.1 for DataBrief shape\n\n## References\n- BACKLOG.md: BL-022\n- IMPLEMENTATION-PLAN.md: Section 1.1\n\n---",
    "labels": [
      "type:feature",
      "phase:1-orchestrator",
      "priority:high",
      "track:orchestrator",
      "size:S"
    ],
    "milestone": "M1: Orchestrator",
    "blocked_by": [],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-017",
    "title": "[BL-017] Meta-Reasoning Node",
    "body": "# [BL-017] Meta-Reasoning Node\n**Labels:** `type:feature`, `phase:1-orchestrator`, `priority:high`, `track:orchestrator`, `size:M`\n**Milestone:** M1: Orchestrator\n**Blocked By:** BL-001\n**Blocks:** None\n\n**Body:**\n## Overview\nAdd a meta-reasoning node to the orchestrator graph that evaluates research quality after fan-in. Identifies data gaps, failed tasks, and incomplete coverage, then dispatches targeted recovery tasks. Adds 30-60s latency but dramatically improves output quality. Includes a skip heuristic for simple queries.\n\n## Acceptance Criteria\n- [ ] Meta-reasoning LLM call evaluates TaskResults against original plan\n- [ ] Identifies three categories: data gaps, failed tasks, incomplete coverage\n- [ ] When gaps found: dispatches recovery tasks via same Send() pattern\n- [ ] When no gaps: routes directly to synthesis node\n- [ ] Skip heuristic: bypasses for `len(plan) <= 2` or explicit config flag\n- [ ] STATE_UPDATE event emitted with quality assessment payload\n- [ ] Latency overhead logged (target: < 30s for meta-reasoning LLM call)\n\n## Technical Notes\n- Extends: `src/intelli/agents/graphs/research_assistant.py` (new node in graph)\n- Recovery dispatch reuses research_worker_node\n- Prompt pattern: system prompt evaluates plan vs results, returns JSON list of follow-up tasks (empty = no gaps)\n- `state[\"meta_reasoning_done\"]` prevents infinite loops\n- See IMPLEMENTATION-PLAN.md Section 1.4 for prompt template\n\n## References\n- BACKLOG.md: BL-017\n- IMPLEMENTATION-PLAN.md: Section 1.4\n\n---",
    "labels": [
      "type:feature",
      "phase:1-orchestrator",
      "priority:high",
      "track:orchestrator",
      "size:M"
    ],
    "milestone": "M1: Orchestrator",
    "blocked_by": [
      "BL-001"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-005",
    "title": "[BL-005] Report Generation Node",
    "body": "# [BL-005] Report Generation Node\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:critical-path`, `track:deliverables`, `size:L`\n**Milestone:** M2: Deliverables\n**Blocked By:** BL-001, BL-004, MIG-0005A\n**Blocks:** BL-016, BL-019, BL-009\n\n**Body:**\n## Overview\nCreate the report generation pipeline as a LangGraph node. Transforms research results via 4 passes (outline, section generation, review, assembly) into a MarkupDocument AST stored as an Artifact. Also handles co-generation (website requests produce a companion report). The report generation node is the primary deliverable pipeline.\n\n## Acceptance Criteria\n- [ ] 4-pass pipeline: outline -> parallel section generation -> review pass -> assembly + storage\n- [ ] Output is a valid MarkupDocument JSON passing MarkupHealer.validate()\n- [ ] Stored as Artifact with entity_type=GENERATED_REPORT\n- [ ] AI message hydrated_content contains `<gml-ViewReport props='{\"identifier\": \"{sha256}\"}'>`\n- [ ] message.first_report_identifier set to artifact sha256\n- [ ] Citation IDs in document reference entities from data brief\n- [ ] REPORT_PREVIEW_START/DELTA/DONE events emitted at appropriate stages\n- [ ] Co-generation: triggered as companion when deliverable_type=\"website\"\n\n## Technical Notes\n- Net-new file: `src/intelli/agents/graphs/nodes/report_generation.py`\n- Parallel section gen uses Send() per section from outline\n- MarkupHealer runs as safety net before storage\n- Co-generation triggered via arq job queue when deliverable_type=\"website\"\n- Answer format: `<answer>...<gml-ViewReport props='{\"identifier\":\"...\"}'>...</answer>`\n- See IMPLEMENTATION-PLAN.md Section 2.1 for full pipeline detail\n\n### Sub-Issues\n\n#### [BL-005a] Report Outline Pass\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:critical-path`, `track:deliverables`, `size:S`\n- LLM call: DataBrief + query -> section outline\n- Emit REPORT_PREVIEW_START event\n- Output: list of section headings with assigned TaskResult data\n\n#### [BL-005b] Parallel Section Generation\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:critical-path`, `track:deliverables`, `size:M`\n- Send() per section from outline\n- Each section LLM call produces MarkupNode subtree\n- Citation IDs embedded from data_brief entities\n- REPORT_PREVIEW_DELTA emitted per section\n\n#### [BL-005c] Review Pass and Assembly\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:deliverables`, `size:M`\n- LLM review of full draft, targeted section rewrites\n- Assembly: MarkupDocument construction, MarkupHealer validation\n- Store as Artifact, set message.first_report_identifier\n- Emit REPORT_PREVIEW_DONE + ARTIFACT_CREATED\n\n## References\n- BACKLOG.md: BL-005\n- IMPLEMENTATION-PLAN.md: Section 2.1\n\n---",
    "labels": [
      "type:feature",
      "phase:2-deliverables",
      "priority:critical-path",
      "track:deliverables",
      "size:L"
    ],
    "milestone": "M2: Deliverables",
    "blocked_by": [
      "BL-001",
      "BL-004",
      "MIG-0005A"
    ],
    "blocks": [
      "BL-016",
      "BL-019",
      "BL-009"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-006",
    "title": "[BL-006] Website Generation Pipeline",
    "body": "# [BL-006] Website Generation Pipeline\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:deliverables`, `size:L`\n**Milestone:** M2: Deliverables\n**Blocked By:** BL-001, MIG-0005A\n**Blocks:** BL-010\n\n**Body:**\n## Overview\nCreate a 7-stage website generation pipeline as a LangGraph node. Produces a multi-file website bundle (HTML/CSS/JS) stored as a Manifest of Artifacts. Includes co-generation of a companion report. Follows Superagent's observed sequence: planning, scaffolding, content, styling, data viz, review, bundle.\n\n## Acceptance Criteria\n- [ ] 7-stage pipeline: planning -> scaffolding -> content -> styling -> data viz -> review -> bundle\n- [ ] Output stored as Manifest with individual files as Artifacts\n- [ ] Root Artifact tagged entity_type=GENERATED_WEBSITE\n- [ ] Manifest includes at minimum: index.html, styles.css\n- [ ] `GET /api/v1/manifests/{sha256}` returns the bundle tree\n- [ ] AI message hydrated_content includes both `<gml-ViewWebsite>` and `<gml-ViewReport>`\n- [ ] REPORT_PREVIEW_START/DELTA per stage, MANIFEST_CREATED, REPORT_PREVIEW_DONE events emitted\n- [ ] Co-generation: also triggers report generation (companion artifact)\n\n## Technical Notes\n- Net-new file: `src/intelli/agents/graphs/nodes/website_generation.py`\n- Uses existing Artifact/Manifest storage (already working)\n- Each file = separate Artifact; Manifest groups them into bundle\n- Co-generation pattern: both gml-ViewWebsite and gml-ViewReport in AI response (confirmed from chat export)\n- See IMPLEMENTATION-PLAN.md Section 2.3 for full pipeline detail\n\n### Sub-Issues\n\n#### [BL-006a] Website Planning and Scaffolding (Stages 1-2)\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:deliverables`, `size:M`\n- LLM determines page structure and tech stack\n- Generates HTML/CSS/JS skeleton per page\n- Emits REPORT_PREVIEW_START and REPORT_PREVIEW_DELTA events\n\n#### [BL-006b] Content, Styling, and Data Viz (Stages 3-5)\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:deliverables`, `size:M`\n- Fill sections from DataBrief, refine CSS/typography\n- Embed charts and tables from research data\n- REPORT_PREVIEW_DELTA per stage\n\n#### [BL-006c] Review, Bundle, and Co-Generation (Stages 6-7)\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:high`, `track:deliverables`, `size:M`\n- LLM critique and fix pass\n- Assemble Manifest: each file as Artifact, root = index.html\n- Trigger companion report generation via arq\n- Emit MANIFEST_CREATED and REPORT_PREVIEW_DONE\n\n## References\n- BACKLOG.md: BL-006\n- IMPLEMENTATION-PLAN.md: Section 2.3\n\n---",
    "labels": [
      "type:feature",
      "phase:2-deliverables",
      "priority:high",
      "track:deliverables",
      "size:L"
    ],
    "milestone": "M2: Deliverables",
    "blocked_by": [
      "BL-001",
      "MIG-0005A"
    ],
    "blocks": [
      "BL-010"
    ],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-018",
    "title": "[BL-018] Slides Deliverable Pipeline",
    "body": "# [BL-018] Slides Deliverable Pipeline\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:medium`, `track:deliverables`, `size:M`\n**Milestone:** M2: Deliverables\n**Blocked By:** BL-001, MIG-0005A\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a slides generation pipeline producing a reveal.js HTML bundle from research results. 4-stage process: outline, per-slide content, assembly, and artifact storage. Output is a single HTML file artifact viewable in an iframe.\n\n## Acceptance Criteria\n- [ ] 4-stage pipeline: outline -> per-slide content -> reveal.js assembly -> artifact storage\n- [ ] Output stored as single Artifact with entity_type=GENERATED_PRESENTATION\n- [ ] Artifact content is valid reveal.js HTML\n- [ ] AI message hydrated_content includes gml-ViewSlides (or gml-ViewWebsite -- decide before implementation)\n- [ ] `GET /api/v1/artifacts/{sha256}/content` returns the HTML\n\n## Technical Notes\n- Net-new file: `src/intelli/agents/graphs/nodes/slides_generation.py`\n- AD-3 decision: reveal.js HTML format (consistent with web artifact pattern)\n- Single HTML file artifact (not multi-file Manifest)\n- See IMPLEMENTATION-PLAN.md Section 2.4\n\n## References\n- BACKLOG.md: BL-018\n- IMPLEMENTATION-PLAN.md: Section 2.4\n\n---",
    "labels": [
      "type:feature",
      "phase:2-deliverables",
      "priority:medium",
      "track:deliverables",
      "size:M"
    ],
    "milestone": "M2: Deliverables",
    "blocked_by": [
      "BL-001",
      "MIG-0005A"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-021",
    "title": "[BL-021] Clarification Flow",
    "body": "# [BL-021] Clarification Flow\n**Labels:** `type:feature`, `phase:3-frontend`, `priority:medium`, `track:orchestrator`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-001, BL-002\n**Blocks:** None\n\n**Body:**\n## Overview\nImplement mid-run pause/resume via CLARIFICATION_NEEDED events. When the planner detects an ambiguous query, it emits the event, pauses the graph (checkpointed via existing AsyncPostgresSaver), and waits for user input. The ClarificationPrompt component renders in the chat UI, and POST /api/v1/runs/{run_id}/clarify resumes the graph from checkpoint.\n\n## Acceptance Criteria\n- [ ] Ambiguous query triggers CLARIFICATION_NEEDED event with question and context payload\n- [ ] Run status set to PAUSED; graph checkpointed via AsyncPostgresSaver\n- [ ] `POST /api/v1/runs/{run_id}/clarify` accepts answer, logs CLARIFICATION_RECEIVED, resumes graph\n- [ ] ClarificationPrompt.tsx appears in chat UI when CLARIFICATION_NEEDED received on active run SSE\n- [ ] After answer submitted, run resumes from checkpoint and completes normally\n- [ ] `message.needs_clarification_message` populated on pause, cleared on resume\n\n## Technical Notes\n- Server side: conditional route after planner_node; reuse existing AsyncPostgresSaver from db/checkpointer.py\n- Client side: net-new `ui/src/components/chat/ClarificationPrompt.tsx`\n- New endpoint: `POST /api/v1/runs/{run_id}/clarify` in runs.py\n- CLARIFICATION_NEEDED and CLARIFICATION_RECEIVED already in BL-002 event types\n- Note: full UI may slip to v1.5 per BACKLOG.md tradeoff log, but schema is ready\n- See IMPLEMENTATION-PLAN.md Section 3.9\n\n## References\n- BACKLOG.md: BL-021\n- IMPLEMENTATION-PLAN.md: Section 3.9\n\n---",
    "labels": [
      "type:feature",
      "phase:3-frontend",
      "priority:medium",
      "track:orchestrator",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-001",
      "BL-002"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-019",
    "title": "[BL-019] Document Deliverable (PDF/DOCX Export)",
    "body": "# [BL-019] Document Deliverable (PDF/DOCX Export)\n**Labels:** `type:feature`, `phase:2-deliverables`, `priority:medium`, `track:deliverables`, `size:M`\n**Milestone:** M2: Deliverables\n**Blocked By:** BL-004, BL-005\n**Blocks:** None\n\n**Body:**\n## Overview\nBuild an export pipeline that converts MarkupDocument AST to PDF (via weasyprint) and DOCX (via python-docx). Provides a new API endpoint that loads a report artifact, deserializes the MarkupDocument, renders to the requested format, stores the output as a new Artifact, and returns a download URL.\n\n## Acceptance Criteria\n- [ ] `POST /api/v1/artifacts/{sha256}/export` with `{\"format\": \"pdf\"}` returns valid PDF\n- [ ] `POST /api/v1/artifacts/{sha256}/export` with `{\"format\": \"docx\"}` returns valid DOCX\n- [ ] PDF preserves heading hierarchy, tables, and at least one chart rendered as image\n- [ ] DOCX preserves heading hierarchy and table structure\n- [ ] Output stored as new Artifact with appropriate entity_type (GENERATED_DOCUMENT)\n- [ ] Response includes download URL for the generated file\n\n## Technical Notes\n- Net-new files: `src/intelli/services/export/document_export.py`, `src/intelli/services/export/markup_to_html.py`\n- New endpoint in: `src/intelli/api/v1/artifacts.py`\n- Pipeline: MarkupDocument -> HTML (markup_to_html) -> weasyprint -> PDF bytes\n- Pipeline: MarkupDocument -> python-docx Document -> bytes\n- Dependencies to add: `weasyprint>=62.0`, `python-docx>=1.1.0`\n- AD-4 decision: weasyprint (server-side, CSS-driven)\n- See IMPLEMENTATION-PLAN.md Section 2.5\n\n## References\n- BACKLOG.md: BL-019\n- IMPLEMENTATION-PLAN.md: Section 2.5\n\n---\n\n### Wave 3: Depends on Wave 2 items\n\n---",
    "labels": [
      "type:feature",
      "phase:2-deliverables",
      "priority:medium",
      "track:deliverables",
      "size:M"
    ],
    "milestone": "M2: Deliverables",
    "blocked_by": [
      "BL-004",
      "BL-005"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-009",
    "title": "[BL-009] ReportRenderer Component",
    "body": "# [BL-009] ReportRenderer Component\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:critical-path`, `track:frontend`, `size:L`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-004, BL-005\n**Blocks:** None\n\n**Body:**\n## Overview\nBuild a recursive React renderer that transforms MarkupDocument JSON into React elements for all 18 node types. Triggered by `<gml-ViewReport>` tags in AI message hydrated_content. Includes a GmlComponentParser that walks hydrated_content, extracts `<gml-*>` tags, and renders the appropriate React component.\n\n## Acceptance Criteria\n- [ ] All 18 MarkupNodeType values render without errors\n- [ ] CHART nodes render as Recharts charts (bar, line, pie, etc.)\n- [ ] METRIC_CARD nodes render as styled KPI cards with label, value, delta, trend\n- [ ] TABLE nodes render as structured HTML tables\n- [ ] Citation numbers render as inline superscripts using existing CitationLink.tsx\n- [ ] Unknown node types fall back gracefully (render as paragraph)\n- [ ] GmlComponentParser extracts `<gml-ViewReport>` from hydrated_content and launches ReportRenderer\n- [ ] Data fetched from `GET /api/v1/artifacts/{sha256}/content`\n\n## Technical Notes\n- Net-new files: `ui/src/components/reports/ReportRenderer.tsx`, `ui/src/types/markup.ts`, `ui/src/components/chat/GmlComponentParser.tsx`\n- Chart rendering: recharts (add to package.json if absent)\n- Code blocks: react-syntax-highlighter (add if absent)\n- Citations: extend existing CitationLink.tsx, do not replace\n- See IMPLEMENTATION-PLAN.md Section 3.6 for TypeScript types\n\n## References\n- BACKLOG.md: BL-009\n- IMPLEMENTATION-PLAN.md: Section 3.6\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:critical-path",
      "track:frontend",
      "size:L"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-004",
      "BL-005"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-010",
    "title": "[BL-010] WebsitePreview Component",
    "body": "# [BL-010] WebsitePreview Component\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:medium`, `track:frontend`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-006\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a website preview component that fetches a generated website Manifest, loads the index.html as a blob URL, and renders it in a sandboxed iframe. Triggered by `<gml-ViewWebsite>` tags in AI message hydrated_content.\n\n## Acceptance Criteria\n- [ ] Fetches Manifest via `GET /api/v1/manifests/{sha256}`\n- [ ] Locates index.html entry in Manifest tree\n- [ ] Loads artifact content, creates blob URL, renders in sandboxed iframe\n- [ ] iframe sandbox: `allow-scripts allow-same-origin`\n- [ ] Blob URL properly revoked on component unmount (no memory leak)\n- [ ] Loading state shown while fetching manifest and artifact\n\n## Technical Notes\n- Net-new file: `ui/src/components/deliverables/WebsitePreview.tsx`\n- Uses existing Manifest and Artifact APIs (already working)\n- Triggered by GmlComponentParser when it encounters `<gml-ViewWebsite>` tag\n- See IMPLEMENTATION-PLAN.md Section 3.8\n\n## References\n- BACKLOG.md: BL-010\n- IMPLEMENTATION-PLAN.md: Section 3.8\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:medium",
      "track:frontend",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-006"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-011",
    "title": "[BL-011] Enhanced SourcesPanel",
    "body": "# [BL-011] Enhanced SourcesPanel\n**Labels:** `type:frontend`, `phase:3-frontend`, `priority:medium`, `track:frontend`, `size:M`\n**Milestone:** M3: Frontend\n**Blocked By:** BL-003, BL-016\n**Blocks:** None\n\n**Body:**\n## Overview\nEnhance the existing SourcesPanel component to add a \"Web Sources\" tab alongside the existing RAG documents tab. Web sources are fetched from the entity API endpoint and display favicon, title, URL, snippet, and relevance badge. The existing SourcesPanel.tsx, SourcesContext.tsx, and use-thread-sources.ts hook are preserved and extended.\n\n## Acceptance Criteria\n- [ ] \"Web Sources\" tab appears when run has WEB_SOURCE entity artifacts\n- [ ] Each source displays: favicon (via Google favicons API), title, URL, snippet\n- [ ] Relevance badge shown per source\n- [ ] Click opens source URL in new tab\n- [ ] Count badge on tab shows source count\n- [ ] Existing RAG sources tab completely unaffected\n- [ ] Data fetched from `GET /api/v1/runs/{run_id}/entities?entity_type=web_source`\n\n## Technical Notes\n- Extends existing: `ui/src/components/chat/SourcesPanel.tsx`\n- Understand existing SourcesContext.tsx and use-thread-sources.ts data shape before modifying\n- Favicon URL pattern: `https://www.google.com/s2/favicons?domain={domain}`\n- See IMPLEMENTATION-PLAN.md Section 3.7\n- Sources panel needs entity API endpoint from BL-016 for web_source entities.\n\n## References\n- BACKLOG.md: BL-011\n- IMPLEMENTATION-PLAN.md: Section 3.7\n\n---",
    "labels": [
      "type:frontend",
      "phase:3-frontend",
      "priority:medium",
      "track:frontend",
      "size:M"
    ],
    "milestone": "M3: Frontend",
    "blocked_by": [
      "BL-003",
      "BL-016"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "BL-013",
    "title": "[BL-013] Quota Enforcement Middleware",
    "body": "# [BL-013] Quota Enforcement Middleware\n**Labels:** `type:billing`, `phase:4-billing`, `priority:high`, `track:billing`, `size:S`\n**Milestone:** M4: Billing & Polish\n**Blocked By:** BL-012\n**Blocks:** None\n\n**Body:**\n## Overview\nCreate a FastAPI dependency that checks usage quota before allowing new run creation. Loads the user's subscription, queries current-period usage, compares against plan limits, and returns HTTP 429 when quota is exceeded. Pro accounts allow overage at $0.50/run.\n\n## Acceptance Criteria\n- [ ] FastAPI `Depends()` function on run creation endpoints\n- [ ] Free account at limit returns HTTP 429 with `{\"error\": \"quota_exceeded\", \"limit\": N, \"current\": N}`\n- [ ] Pro account within limit allows run creation\n- [ ] Pro account overage tracked for billing (via Stripe metered billing or manual invoice)\n- [ ] Usage record created after successful run creation (not on retry)\n- [ ] No quota check on read operations (GET endpoints)\n\n## Technical Notes\n- Net-new file: `src/intelli/api/middleware/quota_middleware.py`\n- Plan limits: free=5 runs/month + 2 reports, pro=200 runs/month + $0.50/run overage\n- Query usage_records table for current billing period\n- Frontend should show toast on 429 quota exceeded\n\n## References\n- BACKLOG.md: BL-013\n- IMPLEMENTATION-PLAN.md: Section 4.2\n\n---\n\n## 4. GitHub CLI Commands\n\n### Label Creation\n\n```bash\n# Type labels\ngh label create \"type:feature\" --color \"0E8A16\" --description \"New feature implementation\"\ngh label create \"type:infrastructure\" --color \"D93F0B\" --description \"Schema, migration, or platform infrastructure\"\ngh label create \"type:frontend\" --color \"1D76DB\" --description \"React/UI component work\"\ngh label create \"type:backend\" --color \"5319E7\" --description \"Python/FastAPI backend logic\"\ngh label create \"type:integration\" --color \"FBCA04\" --description \"External API or service integration\"\ngh label create \"type:billing\" --color \"B60205\" --description \"Stripe billing and quota enforcement\"\ngh label create \"type:test\" --color \"C5DEF5\" --description \"Test suite or test infrastructure\"\ngh label create \"type:docs\" --color \"0075CA\" --description \"Documentation updates\"\n\n# Phase labels\ngh label create \"phase:0-foundation\" --color \"BFD4F2\" --description \"Phase 0: Schema, migration, environment (Weeks 1-2)\"\ngh label create \"phase:1-orchestrator\" --color \"D4C5F9\" --description \"Phase 1: Research orchestrator fan-out (Weeks 3-5)\"\ngh label create \"phase:2-deliverables\" --color \"FEF2C0\" --description \"Phase 2: Report, website, slides, export pipelines (Weeks 6-8)\"\ngh label create \"phase:3-frontend\" --color \"C2E0C6\" --description \"Phase 3: React UI components and views (Weeks 9-11)\"\ngh label create \"phase:4-billing\" --color \"F9D0C4\" --description \"Phase 4: Billing, quota, production hardening (Weeks 12-13)\"\n\n# Priority labels\ngh label create \"priority:critical-path\" --color \"B60205\" --description \"On the critical dependency chain; blocks other work\"\ngh label create \"priority:high\" --color \"D93F0B\" --description \"Important but not on the longest path\"\ngh label create \"priority:medium\" --color \"FBCA04\" --description \"Standard priority; can be reordered within phase\"\ngh label create \"priority:low\" --color \"0E8A16\" --description \"Nice to have; can slip without impact\"\n\n# Track labels\ngh label create \"track:orchestrator\" --color \"7057FF\" --description \"Research orchestrator graph and agent nodes\"\ngh label create \"track:frontend\" --color \"008672\" --description \"React components and Zustand stores\"\ngh label create \"track:billing\" --color \"E4E669\" --description \"Stripe integration and quota enforcement\"\ngh label create \"track:deliverables\" --color \"FF7619\" --description \"Report, website, slides, document generation\"\ngh label create \"track:infrastructure\" --color \"6F42C1\" --description \"Schema, models, migrations, services\"\n\n# Size labels\ngh label create \"size:XS\" --color \"EDEDED\" --description \"~1 story point: trivial change, < 2 hours\"\ngh label create \"size:S\" --color \"D4C5F9\" --description \"~2 story points: small task, half day\"\ngh label create \"size:M\" --color \"BFD4F2\" --description \"~3 story points: moderate task, 1-2 days\"\ngh label create \"size:L\" --color \"FEF2C0\" --description \"~5 story points: large task, 3-5 days\"\ngh label create \"size:XL\" --color \"F9D0C4\" --description \"~8 story points: epic-level, full week+\"\n\n# Status labels\ngh label create \"status:blocked\" --color \"B60205\" --description \"Waiting on another issue to complete\"\ngh label create \"status:ready-to-start\" --color \"0E8A16\" --description \"All dependencies met; can begin work\"\ngh label create \"status:in-review\" --color \"FBCA04\" --description \"PR submitted; awaiting review\"\n```\n\n### Milestone Creation\n\n```bash\ngh milestone create \"M0: Foundation\" \\\n  --description \"Phase 0: Schema extensions, migration 0005, Markup AST models, dev environment verification. All schema work lands here. (Weeks 1-2)\" \\\n  --due-date \"2026-03-14\"\n\ngh milestone create \"M1: Orchestrator\" \\\n  --description \"Phase 1: Extend ResearchAssistantGraph with planner, Send() fan-out, web tools, meta-reasoning, synthesis, and shared data brief. Backend-only; verified via SSE stream. (Weeks 3-5)\" \\\n  --due-date \"2026-04-04\"\n\ngh milestone create \"M2: Deliverables\" \\\n  --description \"Phase 2: Report, website, slides generation pipelines and PDF/DOCX export. Entity/citation substrate. All backend deliverable nodes operational. (Weeks 6-8)\" \\\n  --due-date \"2026-04-25\"\n\ngh milestone create \"M3: Frontend\" \\\n  --description \"Phase 3: PlanViewer, DeliverableSelector, ReportRenderer, WebsitePreview, GenerationOverlay, enhanced SourcesPanel and RunTimeline, clarification flow UI. (Weeks 9-11)\" \\\n  --due-date \"2026-05-16\"\n\ngh milestone create \"M4: Billing & Polish\" \\\n  --description \"Phase 4: Stripe billing system, quota enforcement middleware, production hardening, observability, and final E2E testing. (Weeks 12-13)\" \\\n  --due-date \"2026-05-30\"\n```\n\n### Issue Creation Examples (3 real examples with full commands)\n\n**Example 1: BL-002 (Wave 0, critical path, infrastructure)**\n\n```bash\ngh issue create \\\n  --title \"[BL-002] RunEvent Schema Extensions\" \\\n  --label \"type:infrastructure,phase:0-foundation,priority:critical-path,track:infrastructure,size:S,status:ready-to-start\" \\\n  --milestone \"M0: Foundation\" \\\n  --body \"$(cat <<'EOF'\n## Overview\nExtend the existing RunEvent type enum with 19 new event types covering planning, subagent fan-out, streaming content, artifacts, clarification, report generation progress, and web research events. This is the foundational schema change that all orchestrator and frontend work depends on.\n\n## Acceptance Criteria\n- [ ] All 19 new event types added to `RunEventType` enum in both `schemas/runs.py` and `db/models/runs.py`\n- [ ] Typed `log_*` helper methods added to `LedgerService` for each new event type\n- [ ] All new event types round-trip through the ledger (create, read back)\n- [ ] New events appear correctly in the SSE stream via PG LISTEN/NOTIFY\n- [ ] Existing event types and all existing tests remain unaffected\n- [ ] Payload shapes documented as Python TypedDict or Pydantic models\n\n## Technical Notes\n- Files to modify: `src/intelli/schemas/runs.py`, `src/intelli/db/models/runs.py`, `src/intelli/services/runs/ledger_service.py`\n- New types: PLAN_CREATED, PLAN_TASK_STARTED, PLAN_TASK_COMPLETED, PLAN_TASK_FAILED, SUBAGENT_DISPATCHED, SUBAGENT_COMPLETED, SUBAGENT_FAILED, CONTENT_DELTA, ARTIFACT_CREATED, CLARIFICATION_NEEDED, CLARIFICATION_RECEIVED, REPORT_PREVIEW_START, REPORT_PREVIEW_DELTA, REPORT_PREVIEW_DONE, WEB_SEARCH_STARTED, WEB_SEARCH_COMPLETED, WEB_SCRAPE_STARTED, WEB_SCRAPE_COMPLETED, REFERENCES_FOUND\n- See IMPLEMENTATION-PLAN.md Section 0.2 for full payload schemas\n\n## Dependencies\n- **Blocked by:** None\n- **Blocks:** #BL-001, #BL-007, #BL-014, #BL-016, #BL-020, #BL-021\n\n## References\n- BACKLOG.md: BL-002\n- IMPLEMENTATION-PLAN.md: Section 0.2\nEOF\n)\"\n```\n\n**Example 2: BL-001 (Wave 1, XL epic, orchestrator track)**\n\n```bash\ngh issue create \\\n  --title \"[BL-001] Research Orchestrator Graph\" \\\n  --label \"type:feature,phase:1-orchestrator,priority:critical-path,track:orchestrator,size:XL,status:blocked\" \\\n  --milestone \"M1: Orchestrator\" \\\n  --body \"$(cat <<'EOF'\n## Overview\nExtend the existing ResearchAssistantGraph (not replace it) with a planner node, Send() fan-out to parallel research workers, fan-in aggregation, synthesis node, and deliverable router. This transforms the current single-agent loop into a multi-workstream orchestrator that mirrors Superagent's 13+ parallel task pattern.\n\n## Acceptance Criteria\n- [ ] Planner node decomposes query into 3-13 ResearchTask dicts and emits PLAN_CREATED event\n- [ ] Fan-out dispatches Send() per task, each creating a child Run with parent_run_id FK\n- [ ] Research workers execute in parallel using existing agent+tools loop\n- [ ] Fan-in node aggregates all TaskResult dicts\n- [ ] Synthesis node produces structured DataBrief in graph state\n- [ ] Deliverable router routes by deliverable_type to appropriate generation node\n- [ ] SSE stream shows: PLAN_CREATED, N x SUBAGENT_DISPATCHED, N x PLAN_TASK_*, STATE_UPDATE\n- [ ] AI message hydrated_content contains `<gml-View*>` components\n- [ ] Failed tasks emit PLAN_TASK_FAILED without crashing the run\n- [ ] All existing graph tests continue to pass\n\n## Sub-Issues\n- [ ] [BL-001a] ResearchState Extension\n- [ ] [BL-001b] Planner Node\n- [ ] [BL-001c] Fan-Out / Fan-In Infrastructure\n- [ ] [BL-001d] Synthesis Node and Deliverable Router\n- [ ] [BL-001e] Integration Tests and Event Verification\n\n## Technical Notes\n- Extends: `src/intelli/agents/graphs/research_assistant.py`\n- Existing graph: agent -> (tools_condition) -> tools -> capture_sources -> agent (loop)\n- New nodes: planner_node, fan_out, research_worker_node, fan_in_node, synthesis_node, deliverable_router\n- research_worker_node creates child Run via `Run(parent_run_id=state[\"run_id\"])`\n- See IMPLEMENTATION-PLAN.md Sections 1.1, 1.2 for full graph diagram\n\n## Dependencies\n- **Blocked by:** BL-002\n- **Blocks:** BL-003, BL-005, BL-006, BL-017, BL-018, BL-021, BL-022\n\n## References\n- BACKLOG.md: BL-001\n- IMPLEMENTATION-PLAN.md: Sections 1.1, 1.2\nEOF\n)\"\n```\n\n**Example 3: BL-009 (Wave 3, frontend track, large)**\n\n```bash\ngh issue create \\\n  --title \"[BL-009] ReportRenderer Component\" \\\n  --label \"type:frontend,phase:3-frontend,priority:critical-path,track:frontend,size:L,status:blocked\" \\\n  --milestone \"M3: Frontend\" \\\n  --body \"$(cat <<'EOF'\n## Overview\nBuild a recursive React renderer that transforms MarkupDocument JSON into React elements for all 18 node types. Triggered by `<gml-ViewReport>` tags in AI message hydrated_content. Includes a GmlComponentParser that walks hydrated_content, extracts `<gml-*>` tags, and renders the appropriate React component.\n\n## Acceptance Criteria\n- [ ] All 18 MarkupNodeType values render without errors\n- [ ] CHART nodes render as Recharts charts (bar, line, pie, etc.)\n- [ ] METRIC_CARD nodes render as styled KPI cards with label, value, delta, trend\n- [ ] TABLE nodes render as structured HTML tables\n- [ ] Citation numbers render as inline superscripts using existing CitationLink.tsx\n- [ ] Unknown node types fall back gracefully (render as paragraph)\n- [ ] GmlComponentParser extracts `<gml-ViewReport>` from hydrated_content\n- [ ] Data fetched from `GET /api/v1/artifacts/{sha256}/content`\n\n## Technical Notes\n- Net-new files: `ui/src/components/reports/ReportRenderer.tsx`, `ui/src/types/markup.ts`, `ui/src/components/chat/GmlComponentParser.tsx`\n- Chart rendering: recharts (add to package.json if absent)\n- Code blocks: react-syntax-highlighter (add if absent)\n- Citations: extend existing CitationLink.tsx, do not replace\n- See IMPLEMENTATION-PLAN.md Section 3.6 for TypeScript types\n\n## Dependencies\n- **Blocked by:** BL-004, BL-005\n- **Blocks:** None\n\n## References\n- BACKLOG.md: BL-009\n- IMPLEMENTATION-PLAN.md: Section 3.6\nEOF\n)\"\n```\n\n### Bulk Creation Script\n\n```bash\n#!/usr/bin/env bash\n# bulk-create-issues.sh\n# Creates all 22 BL issues in dependency order (Wave 0 first, then Wave 1, etc.)\n# Run from the nyqst-intelli-230126 repository root.\n#\n# Prerequisites:\n#   1. gh CLI authenticated (gh auth status)\n#   2. Labels created (run label creation commands above)\n#   3. Milestones created (run milestone creation commands above)\n#\n# Usage: bash bulk-create-issues.sh 2>&1 | tee issue-creation.log\n\nset -euo pipefail\n\n# Map BL-IDs to GitHub issue numbers as they are created\ndeclare -A ISSUE_MAP\n\ncreate_issue() {\n  local bl_id=\"$1\"\n  local title=\"$2\"\n  local labels=\"$3\"\n  local milestone=\"$4\"\n  local body=\"$5\"\n\n  echo \"Creating issue: ${title}...\"\n  local issue_url\n  issue_url=$(gh issue create \\\n    --title \"${title}\" \\\n    --label \"${labels}\" \\\n    --milestone \"${milestone}\" \\\n    --body \"${body}\" \\\n    2>&1 | tail -1)\n\n  # Extract issue number from URL\n  local issue_num\n  issue_num=$(echo \"${issue_url}\" | grep -oE '[0-9]+$')\n  ISSUE_MAP[\"${bl_id}\"]=\"${issue_num}\"\n  echo \"  -> Created #${issue_num} for ${bl_id}\"\n  sleep 1  # Rate limit courtesy\n}\n\necho \"==========================================\"\necho \"WAVE 0: No dependencies (can start immediately)\"\necho \"==========================================\"\n\ncreate_issue \"BL-002\" \\\n  \"[BL-002] RunEvent Schema Extensions\" \\\n  \"type:infrastructure,phase:0-foundation,priority:critical-path,track:infrastructure,size:S,status:ready-to-start\" \\\n  \"M0: Foundation\" \\\n  \"$(cat <<'BODY'\n## Overview\nExtend RunEvent type enum with 19 new event types for planning, subagent fan-out, content streaming, artifacts, clarification, report progress, and web research.\n\n## Acceptance Criteria\n- [ ] 19 new event types in both schemas/runs.py and db/models/runs.py\n- [ ] Typed log_* helpers in LedgerService\n- [ ] Round-trip through ledger and SSE stream\n- [ ] Existing tests unaffected\n\n## Dependencies\n- **Blocked by:** None\n- **Blocks:** BL-001, BL-007, BL-014, BL-016, BL-020, BL-021\nBODY\n)\"\n\ncreate_issue \"BL-004\" \\\n  \"[BL-004] NYQST Markup AST Schema\" \\\n  \"type:infrastructure,phase:0-foundation,priority:critical-path,track:deliverables,size:M,status:ready-to-start\" \\\n  \"M0: Foundation\" \\\n  \"$(cat <<'BODY'\n## Overview\nPydantic models for the NYQST Markup AST document tree with 18 node types plus MarkupHealer.\n\n## Acceptance Criteria\n- [ ] 18 node types in MarkupNodeType enum\n- [ ] MarkupNode, MarkupDocument models\n- [ ] MarkupHealer.heal() and validate()\n- [ ] Round-trip JSON stability\n\n## Dependencies\n- **Blocked by:** None\n- **Blocks:** BL-005, BL-009, BL-019\nBODY\n)\"\n\ncreate_issue \"BL-008\" \\\n  \"[BL-008] DeliverableSelector Component\" \\\n  \"type:frontend,phase:0-foundation,priority:medium,track:frontend,size:S,status:ready-to-start\" \\\n  \"M0: Foundation\" \\\n  \"$(cat <<'BODY'\n## Overview\nSegmented control for deliverable type selection (Report|Website|Slides|Document) above the chat composer.\n\n## Acceptance Criteria\n- [ ] 4-segment toggle with Lucide icons\n- [ ] Syncs to DeliverableStore\n- [ ] deliverable_type included in message payload\n- [ ] Auto-clears after submission\n\n## Dependencies\n- **Blocked by:** BL-015 (weak \u2014 DeliverableSelector writes to useDeliverableStore)\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-015\" \\\n  \"[BL-015] DeliverableStore (Zustand)\" \\\n  \"type:frontend,phase:0-foundation,priority:medium,track:frontend,size:XS,status:ready-to-start\" \\\n  \"M0: Foundation\" \\\n  \"$(cat <<'BODY'\n## Overview\n6th Zustand store for deliverable selection and generation progress state.\n\n## Acceptance Criteria\n- [ ] selectedType, activePreview state shape\n- [ ] All action methods typed\n- [ ] Compiles, exports correctly\n\n## Dependencies\n- **Blocked by:** None\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-012\" \\\n  \"[BL-012] Billing System\" \\\n  \"type:billing,phase:4-billing,priority:high,track:billing,size:L\" \\\n  \"M4: Billing & Polish\" \\\n  \"$(cat <<'BODY'\n## Overview\nStripe billing: checkout, webhooks, subscriptions, usage tracking. Port from okestraai/DocuIntelli.\n\n## Acceptance Criteria\n- [ ] Checkout session creation\n- [ ] Webhook processing with signature verification\n- [ ] Subscription and usage endpoints\n- [ ] Usage record per run (not retry)\n\n## Dependencies\n- **Blocked by:** MIG-0005C (billing tables)\n- **Blocks:** BL-013\nBODY\n)\"\n\necho \"\"\necho \"==========================================\"\necho \"WAVE 1: Depends on Wave 0\"\necho \"==========================================\"\n\ncreate_issue \"BL-001\" \\\n  \"[BL-001] Research Orchestrator Graph\" \\\n  \"type:feature,phase:1-orchestrator,priority:critical-path,track:orchestrator,size:XL,status:blocked\" \\\n  \"M1: Orchestrator\" \\\n  \"$(cat <<'BODY'\n## Overview\nExtend ResearchAssistantGraph with planner, Send() fan-out, fan-in, synthesis, and deliverable router.\n\n## Acceptance Criteria\n- [ ] Planner -> fan-out -> parallel workers -> fan-in -> synthesis -> deliverable router\n- [ ] PLAN_CREATED and SUBAGENT_* events in SSE\n- [ ] DataBrief populated in final state\n- [ ] Child Runs with parent_run_id\n- [ ] Existing tests pass\n\n## Dependencies\n- **Blocked by:** BL-002 (#${ISSUE_MAP[BL-002]})\n- **Blocks:** BL-003, BL-005, BL-006, BL-017, BL-018, BL-021, BL-022\nBODY\n)\"\n\ncreate_issue \"BL-007\" \\\n  \"[BL-007] PlanViewer Component\" \\\n  \"type:frontend,phase:3-frontend,priority:high,track:frontend,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nNumbered task cards with live status indicators in a Plan tab in DetailsPanel.\n\n## Acceptance Criteria\n- [ ] Cards on PLAN_CREATED, live status updates\n- [ ] Phase grouping, error tooltips, duration display\n- [ ] New Plan tab in DetailsPanel\n\n## Dependencies\n- **Blocked by:** BL-002 (#${ISSUE_MAP[BL-002]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-014\" \\\n  \"[BL-014] Enhanced RunTimeline\" \\\n  \"type:frontend,phase:3-frontend,priority:medium,track:frontend,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nEnhance RunTimeline with icons/labels for 19 new event types, phase grouping, and subagent cards.\n\n## Acceptance Criteria\n- [ ] All new event types have icons and labels\n- [ ] Phase grouping when PLAN_CREATED present\n- [ ] Backward compatible for non-plan runs\n\n## Dependencies\n- **Blocked by:** BL-002 (#${ISSUE_MAP[BL-002]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-020\" \\\n  \"[BL-020] Generation Progress Overlay\" \\\n  \"type:frontend,phase:3-frontend,priority:high,track:frontend,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nFull-screen overlay with dual-status display and progress during deliverable generation.\n\n## Acceptance Criteria\n- [ ] Show on REPORT_PREVIEW_START, hide on DONE\n- [ ] Phase label updates from DELTA events\n- [ ] Async entity \"Creating notes...\" indicator\n\n## Dependencies\n- **Blocked by:** BL-002 (#${ISSUE_MAP[BL-002]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-016\" \\\n  \"[BL-016] Entity/Citation Substrate\" \\\n  \"type:feature,phase:2-deliverables,priority:high,track:infrastructure,size:M,status:blocked\" \\\n  \"M2: Deliverables\" \\\n  \"$(cat <<'BODY'\n## Overview\nEntity/citation service layer: create entity artifacts from REFERENCES_FOUND events, dedup, per-run entities API.\n\n## Acceptance Criteria\n- [ ] create_entity_artifact helper\n- [ ] Async creation via arq job\n- [ ] GET /api/v1/runs/{run_id}/entities endpoint\n- [ ] Citation IDs resolve to entities\n\n## Dependencies\n- **Blocked by:** BL-002 (#${ISSUE_MAP[BL-002]}), MIG-0005A (entity_type + tags columns)\n- **Blocks:** BL-011\n\n> **Note:** BL-005 is a soft dependency for citation-binding integration testing only.\nBODY\n)\"\n\necho \"\"\necho \"==========================================\"\necho \"WAVE 2: Depends on BL-001 and/or BL-004\"\necho \"==========================================\"\n\ncreate_issue \"BL-003\" \\\n  \"[BL-003] Web Research MCP Tools\" \\\n  \"type:integration,phase:1-orchestrator,priority:critical-path,track:orchestrator,size:M,status:blocked\" \\\n  \"M1: Orchestrator\" \\\n  \"$(cat <<'BODY'\n## Overview\nBrave Search and Jina Reader MCP tools for web research with RunEvent emission.\n\n## Acceptance Criteria\n- [ ] brave_web_search returns results\n- [ ] jina_web_scrape returns cleaned text\n- [ ] Both registered in MCP server\n- [ ] WEB_SEARCH_*/WEB_SCRAPE_* events emitted\n\n## Dependencies\n- **Blocked by:** None (standalone tools); BL-001 (integration wiring into orchestrator)\n- **Blocks:** BL-011\n\n> **Note:** Brave/Jina API wrappers can be built and tested independently in Wave 0. Integration into research_worker_node requires BL-001 (Wave 2).\nBODY\n)\"\n\ncreate_issue \"BL-022\" \\\n  \"[BL-022] Shared Data Brief\" \\\n  \"type:feature,phase:1-orchestrator,priority:high,track:orchestrator,size:S,status:blocked\" \\\n  \"M1: Orchestrator\" \\\n  \"$(cat <<'BODY'\n## Overview\nStructured data brief as LangGraph state field for cross-deliverable data consistency.\n\n## Acceptance Criteria\n- [ ] DataBrief shape: key_facts, entities, financial_figures, summary\n- [ ] Populated by synthesis_node\n- [ ] Available in final state\n- [ ] Downstream nodes reference without re-fetch\n\n## Dependencies\n- **Blocked by:** None (design phase)\n- **Blocks:** None\n\n> **Note:** DataBrief schema design must precede BL-001 (feeds into ResearchState). Integration testing requires BL-001.\nBODY\n)\"\n\ncreate_issue \"BL-017\" \\\n  \"[BL-017] Meta-Reasoning Node\" \\\n  \"type:feature,phase:1-orchestrator,priority:high,track:orchestrator,size:M,status:blocked\" \\\n  \"M1: Orchestrator\" \\\n  \"$(cat <<'BODY'\n## Overview\nResearch quality evaluator node with recovery dispatch for data gaps and failed tasks.\n\n## Acceptance Criteria\n- [ ] Evaluates plan vs results, identifies gaps\n- [ ] Dispatches recovery tasks when gaps found\n- [ ] Skip heuristic for simple queries\n- [ ] Latency < 30s for meta-reasoning call\n\n## Dependencies\n- **Blocked by:** BL-001 (#${ISSUE_MAP[BL-001]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-005\" \\\n  \"[BL-005] Report Generation Node\" \\\n  \"type:feature,phase:2-deliverables,priority:critical-path,track:deliverables,size:L,status:blocked\" \\\n  \"M2: Deliverables\" \\\n  \"$(cat <<'BODY'\n## Overview\n4-pass report generation: outline, parallel sections, review, assembly into MarkupDocument artifact.\n\n## Acceptance Criteria\n- [ ] Valid MarkupDocument passing MarkupHealer.validate()\n- [ ] Stored as GENERATED_REPORT artifact\n- [ ] hydrated_content contains gml-ViewReport\n- [ ] Citation IDs reference data brief entities\n- [ ] Co-generation for website requests\n\n## Dependencies\n- **Blocked by:** BL-001 (#${ISSUE_MAP[BL-001]}), BL-004 (#${ISSUE_MAP[BL-004]}), MIG-0005A\n- **Blocks:** BL-016, BL-019, BL-009\nBODY\n)\"\n\ncreate_issue \"BL-006\" \\\n  \"[BL-006] Website Generation Pipeline\" \\\n  \"type:feature,phase:2-deliverables,priority:high,track:deliverables,size:L,status:blocked\" \\\n  \"M2: Deliverables\" \\\n  \"$(cat <<'BODY'\n## Overview\n7-stage website generation producing multi-file HTML/CSS/JS bundle as Manifest with co-generation.\n\n## Acceptance Criteria\n- [ ] 7-stage pipeline: planning through bundle\n- [ ] Manifest with index.html + styles.css minimum\n- [ ] Both gml-ViewWebsite and gml-ViewReport in response\n- [ ] entity_type=GENERATED_WEBSITE\n\n## Dependencies\n- **Blocked by:** BL-001 (#${ISSUE_MAP[BL-001]}), MIG-0005A\n- **Blocks:** BL-010\nBODY\n)\"\n\ncreate_issue \"BL-018\" \\\n  \"[BL-018] Slides Deliverable Pipeline\" \\\n  \"type:feature,phase:2-deliverables,priority:medium,track:deliverables,size:M,status:blocked\" \\\n  \"M2: Deliverables\" \\\n  \"$(cat <<'BODY'\n## Overview\nSlides generation producing reveal.js HTML bundle from research results.\n\n## Acceptance Criteria\n- [ ] 4-stage pipeline: outline, content, assembly, storage\n- [ ] Valid reveal.js HTML as single artifact\n- [ ] entity_type=GENERATED_PRESENTATION\n\n## Dependencies\n- **Blocked by:** BL-001 (#${ISSUE_MAP[BL-001]}), MIG-0005A\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-021\" \\\n  \"[BL-021] Clarification Flow\" \\\n  \"type:feature,phase:3-frontend,priority:medium,track:orchestrator,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nMid-run pause/resume via CLARIFICATION_NEEDED events with AsyncPostgresSaver checkpoint.\n\n## Acceptance Criteria\n- [ ] CLARIFICATION_NEEDED pauses run\n- [ ] POST /api/v1/runs/{run_id}/clarify resumes\n- [ ] ClarificationPrompt.tsx in chat UI\n- [ ] needs_clarification_message populated\n\n## Dependencies\n- **Blocked by:** BL-001 (#${ISSUE_MAP[BL-001]}), BL-002 (#${ISSUE_MAP[BL-002]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-019\" \\\n  \"[BL-019] Document Deliverable (PDF/DOCX Export)\" \\\n  \"type:feature,phase:2-deliverables,priority:medium,track:deliverables,size:M,status:blocked\" \\\n  \"M2: Deliverables\" \\\n  \"$(cat <<'BODY'\n## Overview\nExport pipeline: MarkupDocument AST to PDF (weasyprint) and DOCX (python-docx).\n\n## Acceptance Criteria\n- [ ] POST /api/v1/artifacts/{sha256}/export with format=pdf returns valid PDF\n- [ ] format=docx returns valid DOCX\n- [ ] Preserves heading hierarchy, tables, charts (as images in PDF)\n- [ ] Output stored as new artifact\n\n## Dependencies\n- **Blocked by:** BL-004 (#${ISSUE_MAP[BL-004]}), BL-005 (#${ISSUE_MAP[BL-005]})\n- **Blocks:** None\nBODY\n)\"\n\necho \"\"\necho \"==========================================\"\necho \"WAVE 3: Depends on Wave 2\"\necho \"==========================================\"\n\ncreate_issue \"BL-009\" \\\n  \"[BL-009] ReportRenderer Component\" \\\n  \"type:frontend,phase:3-frontend,priority:critical-path,track:frontend,size:L,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nRecursive React renderer for MarkupDocument JSON with 18 node types and GmlComponentParser.\n\n## Acceptance Criteria\n- [ ] All 18 node types render\n- [ ] Charts via Recharts, code via react-syntax-highlighter\n- [ ] Citations via existing CitationLink.tsx\n- [ ] GmlComponentParser extracts gml-ViewReport tags\n\n## Dependencies\n- **Blocked by:** BL-004 (#${ISSUE_MAP[BL-004]}), BL-005 (#${ISSUE_MAP[BL-005]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-010\" \\\n  \"[BL-010] WebsitePreview Component\" \\\n  \"type:frontend,phase:3-frontend,priority:medium,track:frontend,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nWebsite preview via sandboxed iframe loading Manifest bundle as blob URL.\n\n## Acceptance Criteria\n- [ ] Fetches Manifest, loads index.html as blob URL\n- [ ] Sandboxed iframe rendering\n- [ ] Blob URL revoked on unmount\n- [ ] Loading state during fetch\n\n## Dependencies\n- **Blocked by:** BL-006 (#${ISSUE_MAP[BL-006]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-011\" \\\n  \"[BL-011] Enhanced SourcesPanel\" \\\n  \"type:frontend,phase:3-frontend,priority:medium,track:frontend,size:M,status:blocked\" \\\n  \"M3: Frontend\" \\\n  \"$(cat <<'BODY'\n## Overview\nAdd Web Sources tab to existing SourcesPanel with favicon, title, URL, snippet per source.\n\n## Acceptance Criteria\n- [ ] Web Sources tab when WEB_SOURCE entities exist\n- [ ] Favicon, title, URL, snippet display\n- [ ] Count badge, click-to-open\n- [ ] Existing RAG tab unaffected\n\n## Dependencies\n- **Blocked by:** BL-003 (#${ISSUE_MAP[BL-003]}), BL-016 (#${ISSUE_MAP[BL-016]})\n- **Blocks:** None\nBODY\n)\"\n\ncreate_issue \"BL-013\" \\\n  \"[BL-013] Quota Enforcement Middleware\" \\\n  \"type:billing,phase:4-billing,priority:high,track:billing,size:S,status:blocked\" \\\n  \"M4: Billing & Polish\" \\\n  \"$(cat <<'BODY'\n## Overview\nFastAPI Depends() quota check on run creation: 429 when quota exceeded.\n\n## Acceptance Criteria\n- [ ] Free at limit -> 429\n- [ ] Pro within limit -> allowed\n- [ ] Pro overage tracked\n- [ ] No check on read ops\n\n## Dependencies\n- **Blocked by:** BL-012 (#${ISSUE_MAP[BL-012]})\n- **Blocks:** None\nBODY\n)\"\n\necho \"\"\necho \"==========================================\"\necho \"DONE: All 22 issues created\"\necho \"==========================================\"\necho \"\"\necho \"Issue Map:\"\nfor bl_id in $(echo \"${!ISSUE_MAP[@]}\" | tr ' ' '\\n' | sort); do\n  echo \"  ${bl_id} -> #${ISSUE_MAP[${bl_id}]}\"\ndone\n```\n\n---\n\n## 5. GitHub Project Board Structure\n\n### Project Setup\n\nCreate a GitHub Projects (v2) board named **\"Superagent Parity\"** in the repository.\n\n### Custom Fields\n\n| Field Name | Field Type | Options |\n|------------|-----------|---------|\n| Status | Single select | Backlog, Ready, In Progress, In Review, Done, Blocked |\n| Phase | Single select | 0-Foundation, 1-Orchestrator, 2-Deliverables, 3-Frontend, 4-Billing |\n| Track | Single select | Orchestrator, Frontend, Billing, Deliverables, Infrastructure |\n| Size | Number | 1, 2, 3, 5, 8 (story points) |\n| Priority | Single select | Critical Path, High, Medium, Low |\n| Wave | Number | 0, 1, 2, 3 (dependency wave) |\n| BL-ID | Text | BL-001 through BL-022 |\n\n### Views\n\n#### View 1: Sprint Board (default)\n- **Layout:** Board\n- **Group by:** Status\n- **Columns:** Backlog | Ready | In Progress | In Review | Done | Blocked\n- **Sort within columns:** Priority (Critical Path first), then Size (largest first)\n- **Filter:** None (shows all)\n\n#### View 2: By Phase\n- **Layout:** Board\n- **Group by:** Phase\n- **Columns:** 0-Foundation | 1-Orchestrator | 2-Deliverables | 3-Frontend | 4-Billing\n- **Sort within columns:** Priority, then Size\n- **Use case:** Sprint planning -- see what is in each milestone\n\n#### View 3: By Track\n- **Layout:** Board\n- **Group by:** Track\n- **Columns:** Orchestrator | Frontend | Billing | Deliverables | Infrastructure\n- **Sort within columns:** Phase (ascending), then Priority\n- **Use case:** Team assignment -- each dev owns a track\n\n#### View 4: Dependency Map\n- **Layout:** Table\n- **Columns visible:** BL-ID, Title, Status, Wave, Phase, Blocked By (text field), Priority\n- **Sort:** Wave (ascending), then Priority\n- **Filter:** Status != Done\n- **Use case:** Identify what can start next, what is blocked\n\n#### View 5: Burndown (By Size)\n- **Layout:** Table\n- **Columns visible:** BL-ID, Title, Size, Status, Phase\n- **Group by:** Status\n- **Use case:** Track total story points remaining per status\n\n### Automation Rules\n\n| Trigger | Action |\n|---------|--------|\n| Issue added to project | Set Status = \"Backlog\" |\n| Pull request linked to issue | Set Status = \"In Progress\" |\n| Pull request marked ready for review | Set Status = \"In Review\" |\n| Pull request merged | Set Status = \"Done\" |\n| Label `status:blocked` added | Set Status = \"Blocked\" |\n| Label `status:blocked` removed | Set Status = \"Ready\" |\n| Label `status:ready-to-start` added | Set Status = \"Ready\" |\n\n### Setup Commands\n\n```bash\n# Create the project (v2)\ngh project create --title \"Superagent Parity\" --owner $(gh repo view --json owner -q '.owner.login')\n\n# Note: Custom fields and views must be configured via the GitHub web UI\n# or the GraphQL API. The gh CLI does not yet support project field creation.\n# See: https://docs.github.com/en/issues/planning-and-tracking-with-projects\n```\n\n---\n\n## 6. Dependency Tracking Strategy\n\n### Approach: Multi-Layer Dependency Tracking\n\nGitHub Issues does not have native dependency enforcement. We use three complementary strategies:\n\n#### Layer 1: Issue Body \"Dependencies\" Section\n\nEvery issue includes a structured Dependencies section:\n\n```markdown\n## Dependencies\n- **Blocked by:** #12, #15 (BL-002, BL-004)\n- **Blocks:** #18, #22 (BL-005, BL-019)\n```\n\nGitHub auto-links issue numbers, making cross-navigation easy.\n\n#### Layer 2: Task Lists in Milestone Epic Issues\n\nCreate one \"epic\" tracking issue per milestone that uses task lists to track constituent issues:\n\n```bash\ngh issue create \\\n  --title \"[EPIC] M1: Orchestrator\" \\\n  --label \"type:docs\" \\\n  --milestone \"M1: Orchestrator\" \\\n  --body \"$(cat <<'EOF'\n## Phase 1: Research Orchestrator (Weeks 3-5)\n\n### Wave 1 (unblocked after BL-002)\n- [ ] #XX [BL-001] Research Orchestrator Graph\n\n### Wave 2 (unblocked after BL-001)\n- [ ] #XX [BL-003] Web Research MCP Tools\n- [ ] #XX [BL-022] Shared Data Brief\n- [ ] #XX [BL-017] Meta-Reasoning Node\n\n### Completion Criteria\n- [ ] SSE stream shows full PLAN_CREATED -> SUBAGENT_* -> synthesis flow\n- [ ] DataBrief populated in final graph state\n- [ ] Meta-reasoning fires for complex queries, skips for simple\n- [ ] All integration tests passing\nEOF\n)\"\n```\n\nCreate 5 epic issues (one per milestone). As issues are completed, check them off in the epic. The task list progress bar provides at-a-glance milestone completion tracking.\n\n#### Layer 3: \"Blocked by\" Label Discipline\n\n- When an issue's dependencies are NOT all closed, apply `status:blocked` label\n- When all blocking issues close, remove `status:blocked` and apply `status:ready-to-start`\n- This can be partially automated via GitHub Actions:\n\n```yaml\n# .github/workflows/dependency-check.yml\nname: Dependency Check\non:\n  issues:\n    types: [closed]\njobs:\n  unblock:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check if closing this unblocks others\n        uses: actions/github-script@v7\n        with:\n          script: |\n            // Parse all open issues for \"Blocked by: #N\" references\n            // If #N matches the just-closed issue, check if ALL blockers are now closed\n            // If so, remove status:blocked and add status:ready-to-start\n            // (Implementation left as exercise -- or use a community action)\n```\n\n#### Layer 4: PR-to-Issue Auto-Close\n\nUse conventional branch naming and PR body references:\n\n```\nBranch: feat/BL-002-runevent-schema\nPR body: Closes #12\n```\n\nWhen the PR merges, GitHub auto-closes #12 and the dependency check workflow fires.\n\n#### Layer 5: Wave-Based Work Ordering\n\nThe `Wave` field on the project board provides a simple numeric ordering:\n\n| Wave | Issues | Can Start When |\n|------|--------|----------------|\n| 0 | BL-002, BL-004, BL-008, BL-015, BL-012, BL-022 (design), BL-003 (API wrapper) | Immediately |\n| 1 | BL-001, BL-007, BL-014, BL-020, BL-016 | Wave 0 items they depend on are done |\n| 2 | BL-003 (integration), BL-017, BL-005, BL-006, BL-018, BL-021, BL-019 | Wave 0-1 items they depend on are done |\n| 3 | BL-009, BL-010, BL-011, BL-013 | Wave 0-2 items they depend on are done |\n\nIn sprint planning, only pull from the lowest available wave with unblocked items.\n\n### Dependency Graph Summary\n\n```\nWave 0 (no deps or design-phase only):\n  BL-002 \u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  BL-004 \u2500\u2500\u2524                                                      \u2502\n  BL-008   \u2502 (weak dep on BL-015)                                 \u2502\n  BL-015   \u2502 (independent)                                        \u2502\n  BL-012 \u2500\u2500\u2524 (needs Mig-0005c)                                    \u2502\n  BL-022   \u2502 (design phase; integration wiring needs BL-001)      \u2502\n  BL-003   \u2502 (API wrappers; integration wiring needs BL-001)      \u2502\n            \u2502                                                      \u2502\nWave 1:     \u2502                                                      \u2502\n  BL-001 \u25c4\u2500\u2524 (needs BL-002)                                      \u2502\n  BL-007 \u25c4\u2500\u2524 (needs BL-002)                                      \u2502\n  BL-014 \u25c4\u2500\u2524 (needs BL-002)                                      \u2502\n  BL-020 \u25c4\u2500\u2524 (needs BL-002)                                      \u2502\n  BL-016 \u25c4\u2500\u2524 (needs BL-002 + Mig-0005a)                          \u2502\n            \u2502                                                      \u2502\nWave 2:     \u2502                                                      \u2502\n  BL-003 \u25c4\u2500\u2524 (integration: needs BL-001)                         \u2502\n  BL-017 \u25c4\u2500\u2524 (needs BL-001)                                      \u2502\n  BL-005 \u25c4\u2500\u2524 (needs BL-001, BL-004, Mig-0005a)                   \u2502\n  BL-006 \u25c4\u2500\u2524 (needs BL-001, Mig-0005a)                           \u2502\n  BL-018 \u25c4\u2500\u2524 (needs BL-001, Mig-0005a)                           \u2502\n  BL-021 \u25c4\u2500\u2524 (needs BL-001, BL-002)                              \u2502\n  BL-019 \u25c4\u2500\u2524 (needs BL-004, BL-005)                              \u2502\n            \u2502                                                      \u2502\nWave 3:     \u2502                                                      \u2502\n  BL-009 \u25c4\u2500\u2500\u2500\u2500 (needs BL-004, BL-005)                            \u2502\n  BL-010 \u25c4\u2500\u2500\u2500\u2500 (needs BL-006)                                    \u2502\n  BL-011 \u25c4\u2500\u2500\u2500\u2500 (needs BL-003, BL-016)                            \u2502\n  BL-013 \u25c4\u2500\u2500\u2500\u2500 (needs BL-012)                                    \u2502\n```\n\n**Note on BL-016:** It depends on BL-002 (Wave 0) and MIG-0005A (Wave 0). BL-005 is a soft dependency for citation-binding integration testing only; service layer work can begin after BL-002 + Mig-0005a. In practice, treat as two sub-phases.\n\n**Note on BL-003:** API wrappers (Brave/Jina) can be built and tested in Wave 0. Integration into research_worker_node requires BL-001 (Wave 2).\n\n**Note on BL-022:** DataBrief schema design is Wave 0 (feeds into ResearchState design). Integration testing requires BL-001.\n\n---\n\n## 7. Machine-Readable Index\n\n```json\n{\n  \"metadata\": {\n    \"document_id\": \"GIT-ISSUES\",\n    \"version\": 1,\n    \"date\": \"2026-02-18\",\n    \"target_repo\": \"nyqst-intelli-230126\",\n    \"total_issues\": 22,\n    \"total_story_points\": 72\n  },\n  \"milestones\": [\n    {\"id\": \"M0\", \"title\": \"M0: Foundation\", \"due_date\": \"2026-03-14\", \"story_points\": 5},\n    {\"id\": \"M1\", \"title\": \"M1: Orchestrator\", \"due_date\": \"2026-04-04\", \"story_points\": 16},\n    {\"id\": \"M2\", \"title\": \"M2: Deliverables\", \"due_date\": \"2026-04-25\", \"story_points\": 18},\n    {\"id\": \"M3\", \"title\": \"M3: Frontend\", \"due_date\": \"2026-05-16\", \"story_points\": 23},\n    {\"id\": \"M4\", \"title\": \"M4: Billing & Polish\", \"due_date\": \"2026-05-30\", \"story_points\": 7}\n  ],\n  \"issues\": [\n    {\n      \"bl_id\": \"BL-001\",\n      \"title\": \"[BL-001] Research Orchestrator Graph\",\n      \"labels\": [\"type:feature\", \"phase:1-orchestrator\", \"priority:critical-path\", \"track:orchestrator\", \"size:XL\"],\n      \"milestone\": \"M1\",\n      \"size_points\": 8,\n      \"wave\": 1,\n      \"blocked_by\": [\"BL-002\"],\n      \"blocks\": [\"BL-003\", \"BL-005\", \"BL-006\", \"BL-017\", \"BL-018\", \"BL-021\", \"BL-022\"],\n      \"has_sub_issues\": true,\n      \"sub_issue_count\": 5\n    },\n    {\n      \"bl_id\": \"BL-002\",\n      \"title\": \"[BL-002] RunEvent Schema Extensions\",\n      \"labels\": [\"type:infrastructure\", \"phase:0-foundation\", \"priority:critical-path\", \"track:infrastructure\", \"size:S\"],\n      \"milestone\": \"M0\",\n      \"size_points\": 2,\n      \"wave\": 0,\n      \"blocked_by\": [],\n      \"blocks\": [\"BL-001\", \"BL-007\", \"BL-014\", \"BL-016\", \"BL-020\", \"BL-021\"],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-003\",\n      \"title\": \"[BL-003] Web Research MCP Tools\",\n      \"labels\": [\"type:integration\", \"phase:1-orchestrator\", \"priority:critical-path\", \"track:orchestrator\", \"size:M\"],\n      \"milestone\": \"M1\",\n      \"size_points\": 3,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001 (integration only)\"],\n      \"blocks\": [\"BL-011\"],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-004\",\n      \"title\": \"[BL-004] NYQST Markup AST Schema\",\n      \"labels\": [\"type:infrastructure\", \"phase:0-foundation\", \"priority:critical-path\", \"track:deliverables\", \"size:M\"],\n      \"milestone\": \"M0\",\n      \"size_points\": 3,\n      \"wave\": 0,\n      \"blocked_by\": [],\n      \"blocks\": [\"BL-005\", \"BL-009\", \"BL-019\"],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-005\",\n      \"title\": \"[BL-005] Report Generation Node\",\n      \"labels\": [\"type:feature\", \"phase:2-deliverables\", \"priority:critical-path\", \"track:deliverables\", \"size:L\"],\n      \"milestone\": \"M2\",\n      \"size_points\": 5,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001\", \"BL-004\", \"Migration-0005a\"],\n      \"blocks\": [\"BL-016\", \"BL-019\", \"BL-009\"],\n      \"has_sub_issues\": true,\n      \"sub_issue_count\": 3\n    },\n    {\n      \"bl_id\": \"BL-006\",\n      \"title\": \"[BL-006] Website Generation Pipeline\",\n      \"labels\": [\"type:feature\", \"phase:2-deliverables\", \"priority:high\", \"track:deliverables\", \"size:L\"],\n      \"milestone\": \"M2\",\n      \"size_points\": 5,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001\", \"Migration-0005a\"],\n      \"blocks\": [\"BL-010\"],\n      \"has_sub_issues\": true,\n      \"sub_issue_count\": 3\n    },\n    {\n      \"bl_id\": \"BL-007\",\n      \"title\": \"[BL-007] PlanViewer Component\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:high\", \"track:frontend\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 1,\n      \"blocked_by\": [\"BL-002\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-008\",\n      \"title\": \"[BL-008] DeliverableSelector Component\",\n      \"labels\": [\"type:frontend\", \"phase:0-foundation\", \"priority:medium\", \"track:frontend\", \"size:S\"],\n      \"milestone\": \"M0\",\n      \"size_points\": 2,\n      \"wave\": 0,\n      \"blocked_by\": [\"BL-015 (weak)\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-009\",\n      \"title\": \"[BL-009] ReportRenderer Component\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:critical-path\", \"track:frontend\", \"size:L\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 5,\n      \"wave\": 3,\n      \"blocked_by\": [\"BL-004\", \"BL-005\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-010\",\n      \"title\": \"[BL-010] WebsitePreview Component\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:medium\", \"track:frontend\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 3,\n      \"blocked_by\": [\"BL-006\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-011\",\n      \"title\": \"[BL-011] Enhanced SourcesPanel\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:medium\", \"track:frontend\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 3,\n      \"blocked_by\": [\"BL-003\", \"BL-016\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-012\",\n      \"title\": \"[BL-012] Billing System\",\n      \"labels\": [\"type:billing\", \"phase:4-billing\", \"priority:high\", \"track:billing\", \"size:L\"],\n      \"milestone\": \"M4\",\n      \"size_points\": 5,\n      \"wave\": 0,\n      \"blocked_by\": [\"Migration-0005c\"],\n      \"blocks\": [\"BL-013\"],\n      \"has_sub_issues\": true,\n      \"sub_issue_count\": 4\n    },\n    {\n      \"bl_id\": \"BL-013\",\n      \"title\": \"[BL-013] Quota Enforcement Middleware\",\n      \"labels\": [\"type:billing\", \"phase:4-billing\", \"priority:high\", \"track:billing\", \"size:S\"],\n      \"milestone\": \"M4\",\n      \"size_points\": 2,\n      \"wave\": 3,\n      \"blocked_by\": [\"BL-012\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-014\",\n      \"title\": \"[BL-014] Enhanced RunTimeline\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:medium\", \"track:frontend\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 1,\n      \"blocked_by\": [\"BL-002\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-015\",\n      \"title\": \"[BL-015] DeliverableStore (Zustand)\",\n      \"labels\": [\"type:frontend\", \"phase:0-foundation\", \"priority:medium\", \"track:frontend\", \"size:XS\"],\n      \"milestone\": \"M0\",\n      \"size_points\": 1,\n      \"wave\": 0,\n      \"blocked_by\": [],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-016\",\n      \"title\": \"[BL-016] Entity/Citation Substrate\",\n      \"labels\": [\"type:feature\", \"phase:2-deliverables\", \"priority:high\", \"track:infrastructure\", \"size:M\"],\n      \"milestone\": \"M2\",\n      \"size_points\": 3,\n      \"wave\": 1,\n      \"blocked_by\": [\"BL-002\", \"Migration-0005a\"],\n      \"blocks\": [\"BL-011\"],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-017\",\n      \"title\": \"[BL-017] Meta-Reasoning Node\",\n      \"labels\": [\"type:feature\", \"phase:1-orchestrator\", \"priority:high\", \"track:orchestrator\", \"size:M\"],\n      \"milestone\": \"M1\",\n      \"size_points\": 3,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-018\",\n      \"title\": \"[BL-018] Slides Deliverable Pipeline\",\n      \"labels\": [\"type:feature\", \"phase:2-deliverables\", \"priority:medium\", \"track:deliverables\", \"size:M\"],\n      \"milestone\": \"M2\",\n      \"size_points\": 3,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001\", \"Migration-0005a\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-019\",\n      \"title\": \"[BL-019] Document Deliverable (PDF/DOCX Export)\",\n      \"labels\": [\"type:feature\", \"phase:2-deliverables\", \"priority:medium\", \"track:deliverables\", \"size:M\"],\n      \"milestone\": \"M2\",\n      \"size_points\": 3,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-004\", \"BL-005\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-020\",\n      \"title\": \"[BL-020] Generation Progress Overlay\",\n      \"labels\": [\"type:frontend\", \"phase:3-frontend\", \"priority:high\", \"track:frontend\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 1,\n      \"blocked_by\": [\"BL-002\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-021\",\n      \"title\": \"[BL-021] Clarification Flow\",\n      \"labels\": [\"type:feature\", \"phase:3-frontend\", \"priority:medium\", \"track:orchestrator\", \"size:M\"],\n      \"milestone\": \"M3\",\n      \"size_points\": 3,\n      \"wave\": 2,\n      \"blocked_by\": [\"BL-001\", \"BL-002\"],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    },\n    {\n      \"bl_id\": \"BL-022\",\n      \"title\": \"[BL-022] Shared Data Brief\",\n      \"labels\": [\"type:feature\", \"phase:1-orchestrator\", \"priority:high\", \"track:orchestrator\", \"size:S\"],\n      \"milestone\": \"M1\",\n      \"size_points\": 2,\n      \"wave\": 0,\n      \"blocked_by\": [],\n      \"blocks\": [],\n      \"has_sub_issues\": false,\n      \"sub_issue_count\": 0\n    }\n  ],\n  \"waves\": {\n    \"0\": [\"BL-002\", \"BL-004\", \"BL-008\", \"BL-015\", \"BL-012\", \"BL-022\", \"BL-003 (API wrapper)\"],\n    \"1\": [\"BL-001\", \"BL-007\", \"BL-014\", \"BL-020\", \"BL-016\"],\n    \"2\": [\"BL-003 (integration)\", \"BL-017\", \"BL-005\", \"BL-006\", \"BL-018\", \"BL-021\", \"BL-019\"],\n    \"3\": [\"BL-009\", \"BL-010\", \"BL-011\", \"BL-013\"]\n  },\n  \"critical_path\": [\"BL-002\", \"BL-001\", \"BL-005\", \"BL-009\"],\n  \"story_points_by_milestone\": {\n    \"M0\": 5,\n    \"M1\": 16,\n    \"M2\": 19,\n    \"M3\": 23,\n    \"M4\": 7\n  },\n  \"story_points_by_track\": {\n    \"orchestrator\": 19,\n    \"frontend\": 23,\n    \"billing\": 7,\n    \"deliverables\": 19,\n    \"infrastructure\": 5\n  }\n}\n```\n\n---\n\n## Appendix A: Complete Dependency Matrix\n\n| BL-ID | Blocked By | Blocks | Wave | Phase | Size |\n|-------|-----------|--------|------|-------|------|\n| BL-001 | BL-002 | BL-003, BL-005, BL-006, BL-017, BL-018, BL-021, BL-022 | 1 | 1 | XL(8) |\n| BL-002 | -- | BL-001, BL-007, BL-014, BL-016, BL-020, BL-021 | 0 | 0 | S(2) |\n| BL-003 | None (standalone); BL-001 (integration) | BL-011 | 0/2 | 1 | M(3) |\n| BL-004 | -- | BL-005, BL-009, BL-019 | 0 | 0 | M(3) |\n| BL-005 | BL-001, BL-004, Mig-0005a | BL-016, BL-019, BL-009 | 2 | 2 | L(5) |\n| BL-006 | BL-001, Mig-0005a | BL-010 | 2 | 2 | L(5) |\n| BL-007 | BL-002 | -- | 1 | 3 | M(3) |\n| BL-008 | BL-015 (weak) | -- | 0 | 0 | S(2) |\n| BL-009 | BL-004, BL-005 | -- | 3 | 3 | L(5) |\n| BL-010 | BL-006 | -- | 3 | 3 | M(3) |\n| BL-011 | BL-003, BL-016 | -- | 3 | 3 | M(3) |\n| BL-012 | Mig-0005c | BL-013 | 0 | 4 | L(5) |\n| BL-013 | BL-012 | -- | 3 | 4 | S(2) |\n| BL-014 | BL-002 | -- | 1 | 3 | M(3) |\n| BL-015 | -- | -- | 0 | 0 | XS(1) |\n| BL-016 | BL-002, Mig-0005a | BL-011 | 1* | 2 | M(3) |\n| BL-017 | BL-001 | -- | 2 | 1 | M(3) |\n| BL-018 | BL-001, Mig-0005a | -- | 2 | 2 | M(3) |\n| BL-019 | BL-004, BL-005 | -- | 2 | 2 | M(3) |\n| BL-020 | BL-002 | -- | 1 | 3 | M(3) |\n| BL-021 | BL-001, BL-002 | -- | 2 | 3 | M(3) |\n| BL-022 | None (design phase) | -- | 0 | 1 | S(2) |\n\n*BL-016 is Wave 1 for the service scaffolding (needs BL-002 only) but Wave 2+ for citation binding (needs BL-005). In practice, start early and complete after BL-005 lands.\n\n**Totals:** 22 issues, 70 story points across 5 milestones and 4 dependency waves.\n\n---\n\n## Appendix B: Quick Reference Card\n\n### Sprint Planning Checklist\n\n1. Check milestone due date -- are we on track?\n2. Look at Wave 0/1/2/3 -- what is unblocked?\n3. Look at critical path items first (BL-002 -> BL-001 -> BL-005 -> BL-009)\n4. Assign by track: orchestrator dev gets BL-001/003/017/022, frontend dev gets BL-007/008/009/010, etc.\n5. Check `status:blocked` label -- anything newly unblocked?\n6. Update epic tracking issues with checkmarks\n\n### Branch Naming Convention\n\n```\nfeat/BL-002-runevent-schema\nfeat/BL-001a-research-state-extension\nfeat/BL-005-report-generation\nfix/BL-009-chart-rendering\n```\n\n### PR Title Convention\n\n```\nfeat(BL-002): add 19 new RunEvent types to schema\nfeat(BL-001): extend research orchestrator with fan-out\nfix(BL-009): handle unknown node types in ReportRenderer\n```\n\n### PR Body Convention\n\n```markdown\n## Summary\n[What changed and why]\n\n## Backlog Item\nCloses #XX (BL-YYY)\n\n## Testing\n- [ ] Unit tests added/updated\n- [ ] Integration test passes\n- [ ] Existing tests unaffected\n\n## Dependencies\nUnblocks: #AA (BL-ZZZ), #BB (BL-WWW)\n```",
    "labels": [
      "type:billing",
      "phase:4-billing",
      "priority:high",
      "track:billing",
      "size:S"
    ],
    "milestone": "M4: Billing & Polish",
    "blocked_by": [
      "BL-012"
    ],
    "blocks": [],
    "source": "GIT-ISSUES-STRUCTURE.md"
  },
  {
    "id": "P0-001",
    "title": "[P0-001] Fix arq worker job registration (WorkerSettings.functions empty)",
    "body": "# [P0-001] Fix arq worker job registration (WorkerSettings.functions empty)\n\n**Why this matters**\nThe arq worker currently boots with an empty `functions` list because `WorkerSettings.functions` is evaluated before jobs are registered. That means background ingestion jobs will never run when you start `arq intelli.core.jobs.WorkerSettings`.\n\n**Repo evidence**\n- `src/intelli/core/jobs.py` defines `WorkerSettings` before `@job(...)` functions, and sets `functions = list(_job_registry.values())` at class definition time (registry still empty).\n\n**Goal**\n- Worker starts and can execute registered jobs (e.g., `parse_document_job`) without manual patching.\n\n**Implementation (recommended)**\n1. In `src/intelli/core/jobs.py`, ensure `WorkerSettings.functions` is populated *after* all jobs are registered.\n   - Option A (cleanest): move `class WorkerSettings` to the bottom of the module (after all `@job` decorated functions).\n   - Option B: keep class where it is, but set `WorkerSettings.functions = list(_job_registry.values())` at the end of the file after job registration.\n2. Confirm arq expects callables, not names/strings (keep a list of callables).\n3. Add a minimal integration test (or smoke script) that imports `WorkerSettings` and asserts `parse_document_job` is included in `WorkerSettings.functions`.\n\n**Acceptance criteria**\n- Starting the worker (`arq intelli.core.jobs.WorkerSettings`) no longer logs \u201c0 functions registered\u201d.\n- A queued `parse_document_job` executes end-to-end and persists expected outputs.\n\n**Test plan**\n- Unit: import `WorkerSettings` and assert non-empty.\n- Integration: enqueue a document parse job, confirm completion + created artifacts.\n",
    "labels": [
      "type:bug",
      "priority:P0",
      "area:infra"
    ],
    "milestone": "P0: Stabilization",
    "blocked_by": [],
    "blocks": [],
    "source": "repo_audit"
  },
  {
    "id": "P0-002",
    "title": "[P0-002] Fix RunEvent sequence_num race (unique constraint violations under concurrency)",
    "body": "# [P0-002] Fix RunEvent sequence_num race (unique constraint violations under concurrency)\n\n**Why this matters**\n`sequence_num` is computed as `MAX(sequence_num)+1` per run. Under concurrent inserts, this can collide and violate the unique constraint on `(run_id, sequence_num)`.\n\n**Repo evidence**\n- `src/intelli/repositories/runs.py` uses `_get_next_sequence()` which selects max + 1 without locking.\n\n**Goal**\n- Multiple concurrent event writes for the same run never fail (or retry safely).\n\n**Implementation options**\n- Preferred: acquire a per-run transactional advisory lock before selecting max+1, then insert.\n  - Example: `SELECT pg_advisory_xact_lock(hashtext(:run_id::text));`\n- Alternative: optimistic insert + retry on unique violation (loop with max+1 recompute).\n\n**Acceptance criteria**\n- Stress test: 100 concurrent inserts for same `run_id` produces 100 unique, strictly increasing sequence numbers with no errors.\n- No measurable regression in single-writer throughput.\n\n**Test plan**\n- Add a concurrency test using `asyncio.gather()` with 50\u2013200 emitters against a local Postgres.\n",
    "labels": [
      "type:bug",
      "priority:P0",
      "area:backend",
      "area:db"
    ],
    "milestone": "P0: Stabilization",
    "blocked_by": [],
    "blocks": [],
    "source": "repo_audit"
  },
  {
    "id": "P0-003",
    "title": "[P0-003] Make local stack boot reliably (redis profile / env defaults / docs)",
    "body": "# [P0-003] Make local stack boot reliably (redis profile / env defaults / docs)\n\n**Why this matters**\nDevelopers should be able to run the platform with one command. Right now redis can be skipped depending on compose profile usage, and `.env` defaults are unclear.\n\n**Repo evidence**\n- `docker-compose.yml` marks redis under a `full` profile (not started by default).\n- Settings allow `redis_url=None`, so jobs silently downgrade to sync mode.\n\n**Goal**\n- `docker compose up` starts the full dev stack (api + db + redis + minio + opensearch) with predictable defaults.\n- Docs explicitly state what is optional vs required.\n\n**Implementation**\n1. Remove the `profiles: [full]` gate from redis (or add a documented default profile).\n2. Ensure `.env.example` includes `REDIS_URL=redis://redis:6379`.\n3. Add a `make dev` (or `justfile`) that starts compose and runs migrations.\n4. Update `README.md` with a \u201cfirst run\u201d section.\n\n**Acceptance criteria**\n- Fresh clone \u2192 `docker compose up` + `make migrate` works without manual env edits.\n- Background jobs run when worker started.\n\n",
    "labels": [
      "type:chore",
      "priority:P0",
      "area:infra",
      "area:docs"
    ],
    "milestone": "P0: Stabilization",
    "blocked_by": [],
    "blocks": [],
    "source": "repo_audit"
  },
  {
    "id": "P0-004",
    "title": "[P0-004] Add tenant_id to core tables (runs, artifacts, manifests, pointers) and enforce isolation",
    "body": "# [P0-004] Add tenant_id to core tables (runs, artifacts, manifests, pointers) and enforce isolation\n\n**Why this matters**\nTenant isolation cannot be \u201cadded later\u201d if core tables don\u2019t carry tenant identity. It is a design constraint for enterprise controls, quotas, and data access.\n\n**Repo evidence**\n- Tenant model exists (e.g., `src/intelli/db/models/tenants.py`), but `Run` and substrate tables do not include `tenant_id`.\n\n**Goal**\n- Every core record is tenant-scoped and queries enforce tenant filters.\n\n**Implementation**\n1. Create a migration (suggested `0005d_add_tenant_id_to_core_tables.py`):\n   - Add `tenant_id` FK columns to `runs`, `artifacts`, `manifests`, `pointers` (and other high-risk tables).\n   - Backfill tenant_id via workspace/session where possible; otherwise default to a \u201csystem\u201d tenant and document.\n2. Update repositories/services to require `tenant_id` context and enforce it in queries.\n3. Update API layer to derive tenant_id from auth context (JWT claims / session) and pass through.\n4. Add tests: cross-tenant access denied.\n\n**Acceptance criteria**\n- It is impossible to query a run/artifact from another tenant through service/repo APIs.\n- Migration backfill is safe and idempotent.\n",
    "labels": [
      "type:feature",
      "priority:P0",
      "area:backend",
      "area:db",
      "security"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [],
    "source": "Build Guide v5"
  },
  {
    "id": "P0-005",
    "title": "[P0-005] Add production Dockerfiles (api + ui) and minimal CI build step",
    "body": "# [P0-005] Add production Dockerfiles (api + ui) and minimal CI build step\n\n**Why this matters**\nWithout Dockerfiles, deploy and CI parity are fragile.\n\n**Repo evidence**\n- No `Dockerfile` at repo root.\n- CI currently runs lint/test but not container builds.\n\n**Goal**\n- Build and run the API and UI in containers locally and in CI.\n\n**Implementation**\n1. Add `Dockerfile.api` (or `Dockerfile`) for FastAPI:\n   - multi-stage, installs deps, runs `uvicorn intelli.main:app`.\n2. Add `ui/Dockerfile` (or `Dockerfile.ui`) for the frontend:\n   - build static assets, serve with nginx or a lightweight node server.\n3. Add `docker-compose.prod.yml` (optional) or document how to run both.\n4. Update GitHub Actions workflow to `docker build` both images (no push required yet).\n\n**Acceptance criteria**\n- `docker build` succeeds for both images.\n- `docker compose -f docker-compose.yml -f docker-compose.prod.yml up` serves UI + API locally.\n",
    "labels": [
      "type:chore",
      "priority:P1",
      "area:infra",
      "area:ci"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [],
    "source": "repo_audit"
  },
  {
    "id": "MIG-0005A",
    "title": "[MIG-0005A] Substrate metadata extensions (entity_type/entity_id, manifest meta) per Build Guide v5",
    "body": "# [MIG-0005A] Substrate metadata extensions (entity_type/entity_id, manifest meta) per Build Guide v5\n\n**Purpose**\nEnable first-class linkage between artifacts/manifests and domain entities (runs, documents, bundles, etc.), and carry richer metadata for provenance.\n\n**Repo starting point**\n- `src/intelli/db/models/substrate.py`:\n  - `Artifact` has `mime_type` + `metadata` but no explicit `entity_type/entity_id`.\n  - `Manifest` has `tree` + `message` but no `meta` JSONB field.\n\n**Target changes**\n1. Add to `artifacts`:\n   - `entity_type` (TEXT, nullable initially)\n   - `entity_id` (UUID, nullable initially)\n   - optional: `content_type` if you want semantic classification separate from MIME\n2. Add to `manifests`:\n   - `meta` JSONB (nullable)\n3. Consider adding indexes:\n   - `(entity_type, entity_id)` on artifacts\n4. Update services to accept / populate these fields when creating artifacts/manifests.\n\n**Acceptance criteria**\n- Migration applies cleanly on an existing DB.\n- Services can create artifacts with `(entity_type, entity_id)` populated.\n- No regressions in document upload / ingestion.\n\n**Notes**\nThis migration is referenced by multiple BL items (planner, entities, deliverables). Treat it as a dependency unlocker.\n",
    "labels": [
      "type:chore",
      "area:db",
      "priority:P0"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [],
    "source": "Build Guide v5"
  },
  {
    "id": "MIG-0005B",
    "title": "[MIG-0005B] Entity + Citation tables (entities, citations) per Build Guide v5",
    "body": "# [MIG-0005B] Entity + Citation tables (entities, citations) per Build Guide v5\n\n**Purpose**\nPersist entities/claims/citations so sources are not ephemeral chat output.\n\n**Target schema (suggested)**\n- `entities`:\n  - `id` UUID PK\n  - `run_id` UUID FK (nullable, for run-scoped entities)\n  - `artifact_id` UUID FK (nullable, for artifact-scoped entities)\n  - `type` TEXT (Claim, Source, Chunk, Finding, Person, Company, etc.)\n  - `label` TEXT\n  - `data` JSONB (arbitrary attributes; include provenance fields)\n  - timestamps\n- `citations`:\n  - `id` UUID PK\n  - `entity_id` FK\n  - `artifact_id` FK (what is being cited)\n  - `locator` JSONB (page, offsets, chunk_id, quote hash)\n  - `confidence` FLOAT\n  - timestamps\n\n**Acceptance criteria**\n- Migration applies cleanly.\n- Minimal CRUD service exists (even if API comes later) to write/read entities.\n- One integration test: create run \u2192 emit entity + citation \u2192 read back.\n\n",
    "labels": [
      "type:chore",
      "area:db",
      "priority:P0"
    ],
    "milestone": "M0: Foundation",
    "blocked_by": [],
    "blocks": [],
    "source": "Build Guide v5"
  },
  {
    "id": "MIG-0005C",
    "title": "[MIG-0005C] Billing + metering tables (usage meters, subscriptions, quotas)",
    "body": "# [MIG-0005C] Billing + metering tables (usage meters, subscriptions, quotas)\n\n**Purpose**\nSupport usage-based billing, quotas, and per-run cost attribution.\n\n**Target schema (suggested)**\n- `billing_accounts` (tenant_id, stripe_customer_id, status, plan)\n- `usage_meters` (tenant_id, period_start, period_end, tokens_in/out, cost_cents)\n- `quotas` (tenant_id, token_limit, spend_limit, reset_period)\n- optional `billing_events` (append-only ledger, if not using RunEvent)\n\n**Acceptance criteria**\n- Migration applies cleanly.\n- Minimal service layer can:\n  - record token usage deltas per run and aggregate to tenant meter\n  - enforce quota checks pre-run\n",
    "labels": [
      "type:chore",
      "area:db",
      "priority:P1"
    ],
    "milestone": "M1: Agents & Streaming",
    "blocked_by": [],
    "blocks": [],
    "source": "Build Guide v5"
  },
  {
    "id": "GAP-001",
    "title": "[GAP-001] DEC-048 locks Plotly.js (`react-plotly.js`) as the chart library. This is correct and grounded in Superagent bundle analysis (Superagent uses Plotly via `gml-chartcontainer`). However, the decision has NOT been written back into four documents that still specify Recharts: IMPLEMENTATION-PLAN section 3.6, GIT-ISSUES BL-009 acceptance criteria (\"CHART nodes render as Recharts charts\"), STRATEGIC-REVIEW (recommended Recharts for bundle size), and the LIBRARY-REFERENCE LIB-13 section. A developer reading any of these documents will use the wrong library.",
    "body": "# [GAP-001] DEC-048 locks Plotly.js (`react-plotly.js`) as the chart library. This is correct and grounded in Superagent bundle analysis (Superagent uses Plotly via `gml-chartcontainer`). However, the decision has NOT been written back into four documents that still specify Recharts: IMPLEMENTATION-PLAN section 3.6, GIT-ISSUES BL-009 acceptance criteria (\"CHART nodes render as Recharts charts\"), STRATEGIC-REVIEW (recommended Recharts for bundle size), and the LIBRARY-REFERENCE LIB-13 section. A developer reading any of these documents will use the wrong library.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-001\n- **Severity**: CRITICAL\n- **Description**: DEC-048 locks Plotly.js (`react-plotly.js`) as the chart library. This is correct and grounded in Superagent bundle analysis (Superagent uses Plotly via `gml-chartcontainer`). However, the decision has NOT been written back into four documents that still specify Recharts: IMPLEMENTATION-PLAN section 3.6, GIT-ISSUES BL-009 acceptance criteria (\"CHART nodes render as Recharts charts\"), STRATEGIC-REVIEW (recommended Recharts for bundle size), and the LIBRARY-REFERENCE LIB-13 section. A developer reading any of these documents will use the wrong library.\n- **Affected BL Items**: BL-004, BL-005, BL-009, BL-019\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS I-01, I-14; hypothesis-consistency.md H1; EXTRACTION-SUMMARY confirms Plotly in Superagent bundle\n- **Resolution**: Update IMPLEMENTATION-PLAN section 3.6 to \"Chart rendering: react-plotly.js\". Update GIT-ISSUES BL-009 acceptance criteria to Plotly. Update STRATEGIC-REVIEW to reflect DEC-048. Confirm LIB-13 in LIBRARY-REFERENCE documents `react-plotly.js`. Mark I-01 and I-14 as resolved.\n- **Owner Recommendation**: Documentation lead / plan owner; 30-minute task per document\n- **Wave**: P0 \u2014 must complete before any implementation code is written\n\n---\n\n### GAP-002 \u2014 GML Rendering Pipeline Split Not Propagated",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-002",
    "title": "[GAP-002] DEC-015 was split into DEC-015a (backend MarkupDocument JSON AST, used by BL-004/BL-005 report generation) and DEC-015b (frontend GML rendering uses rehype-to-JSX, NOT a JSON AST intermediate layer). This split resolves the conflict between DEC-015 and GML-RENDERING-ANALYSIS. However, multiple documents still reference the old undivided DEC-015 and the conflict is still listed as open. CONSISTENCY-AUDIT-ANALYSIS Section 5.3 flagged this as the \"most significant unresolved conflict in the entire document set.\" GML-RENDERING-ANALYSIS's Section 4 recommendation (skip JSON AST, use rehype-to-JSX) is NOW CORRECT under DEC-015b, but the document doesn't know this because DEC-015 was not split when GML-RENDERING-ANALYSIS was written.",
    "body": "# [GAP-002] DEC-015 was split into DEC-015a (backend MarkupDocument JSON AST, used by BL-004/BL-005 report generation) and DEC-015b (frontend GML rendering uses rehype-to-JSX, NOT a JSON AST intermediate layer). This split resolves the conflict between DEC-015 and GML-RENDERING-ANALYSIS. However, multiple documents still reference the old undivided DEC-015 and the conflict is still listed as open. CONSISTENCY-AUDIT-ANALYSIS Section 5.3 flagged this as the \"most significant unresolved conflict in the entire document set.\" GML-RENDERING-ANALYSIS's Section 4 recommendation (skip JSON AST, use rehype-to-JSX) is NOW CORRECT under DEC-015b, but the document doesn't know this because DEC-015 was not split when GML-RENDERING-ANALYSIS was written.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-002\n- **Severity**: CRITICAL\n- **Description**: DEC-015 was split into DEC-015a (backend MarkupDocument JSON AST, used by BL-004/BL-005 report generation) and DEC-015b (frontend GML rendering uses rehype-to-JSX, NOT a JSON AST intermediate layer). This split resolves the conflict between DEC-015 and GML-RENDERING-ANALYSIS. However, multiple documents still reference the old undivided DEC-015 and the conflict is still listed as open. CONSISTENCY-AUDIT-ANALYSIS Section 5.3 flagged this as the \"most significant unresolved conflict in the entire document set.\" GML-RENDERING-ANALYSIS's Section 4 recommendation (skip JSON AST, use rehype-to-JSX) is NOW CORRECT under DEC-015b, but the document doesn't know this because DEC-015 was not split when GML-RENDERING-ANALYSIS was written.\n- **Affected BL Items**: BL-004, BL-005, BL-009 (report generation and rendering pipeline)\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS SC-02, I-13; CONSISTENCY-AUDIT-ANALYSIS C-04, C-11; hypothesis-consistency.md H3 gap 2\n- **Resolution**: Add a \"Status Update\" note to GML-RENDERING-ANALYSIS Section 4 clarifying that the DEC-015 split has resolved the conflict \u2014 its rehype-to-JSX recommendation is confirmed as DEC-015b. Update DEC-015 entry in DECISION-REGISTER to show the split clearly. Update any document that cross-references DEC-015 to distinguish the two sub-decisions.\n- **Owner Recommendation**: Architecture lead; requires 1\u20132 hours to update all cross-references\n- **Wave**: P0 \u2014 required before BL-004 or BL-009 implementation begins\n\n---\n\n### GAP-003 \u2014 Open Questions Still Appear Open in Source Documents",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-003",
    "title": "[GAP-003] OQ-001 through OQ-007 were resolved in DECISION-REGISTER v2 with new decisions DEC-042\u2013052 (as of 2026-02-19). However, documents that originally asked these questions still show them as open. A developer reading STRATEGIC-REVIEW Section 8 will see seven unresolved questions. GML-RENDERING-ANALYSIS OQ-005 framing is based on a false premise that has since been resolved by DEC-043 (separate ReportPanel). CODEX-ANALYSIS-SUMMARY lists infrastructure choices as \"Unresolved\" that are in fact locked (Auth: DEC-038, Web search: DEC-032/DEC-046, Observability: DEC-037).",
    "body": "# [GAP-003] OQ-001 through OQ-007 were resolved in DECISION-REGISTER v2 with new decisions DEC-042\u2013052 (as of 2026-02-19). However, documents that originally asked these questions still show them as open. A developer reading STRATEGIC-REVIEW Section 8 will see seven unresolved questions. GML-RENDERING-ANALYSIS OQ-005 framing is based on a false premise that has since been resolved by DEC-043 (separate ReportPanel). CODEX-ANALYSIS-SUMMARY lists infrastructure choices as \"Unresolved\" that are in fact locked (Auth: DEC-038, Web search: DEC-032/DEC-046, Observability: DEC-037).\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-003\n- **Severity**: CRITICAL\n- **Description**: OQ-001 through OQ-007 were resolved in DECISION-REGISTER v2 with new decisions DEC-042\u2013052 (as of 2026-02-19). However, documents that originally asked these questions still show them as open. A developer reading STRATEGIC-REVIEW Section 8 will see seven unresolved questions. GML-RENDERING-ANALYSIS OQ-005 framing is based on a false premise that has since been resolved by DEC-043 (separate ReportPanel). CODEX-ANALYSIS-SUMMARY lists infrastructure choices as \"Unresolved\" that are in fact locked (Auth: DEC-038, Web search: DEC-032/DEC-046, Observability: DEC-037).\n- **Affected BL Items**: All BL items \u2014 affects developer onboarding and execution confidence\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS Part 2, I-11, I-16; hypothesis-consistency.md H3 gap 3; KNOWLEDGE-MAP Section 10\n- **Resolution**: Add a resolution block to each affected document's open question. For STRATEGIC-REVIEW: append a \"Resolution\" row to each OQ-001\u2013OQ-007 entry pointing to the DEC-04x that resolved it. For GML-RENDERING-ANALYSIS: add a note to OQ-005 section. For CODEX-ANALYSIS-SUMMARY: annotate the infrastructure matrix with resolution citations.\n- **Owner Recommendation**: Documentation lead; mechanical task, no architectural judgment needed\n- **Wave**: P0 \u2014 must be closed before Wave 0 begins to prevent misaligned implementation\n\n---\n\n### GAP-004 \u2014 Analysis Module (Infinite Canvas) Scope Deferral Not Explicit",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-004",
    "title": "[GAP-004] The PRD (03_PLATFORM.md) specifies six integrated modules: Research, Document Management, Analysis (infinite canvas), Modelling (provable methods), Knowledge & Domain, and Organisational Insight. The IMPLEMENTATION-PLAN v3 frames work as \"ten platform primitives\" validated through the Research Module. The Analysis Module (infinite canvas for visual analysis) does not appear anywhere in BL-001 through BL-022. There is no explicit statement in the IMPLEMENTATION-PLAN that the Analysis Module is deferred and why. A product manager or new team member reading both documents cannot determine the deferred scope without cross-referencing all six modules against the backlog.",
    "body": "# [GAP-004] The PRD (03_PLATFORM.md) specifies six integrated modules: Research, Document Management, Analysis (infinite canvas), Modelling (provable methods), Knowledge & Domain, and Organisational Insight. The IMPLEMENTATION-PLAN v3 frames work as \"ten platform primitives\" validated through the Research Module. The Analysis Module (infinite canvas for visual analysis) does not appear anywhere in BL-001 through BL-022. There is no explicit statement in the IMPLEMENTATION-PLAN that the Analysis Module is deferred and why. A product manager or new team member reading both documents cannot determine the deferred scope without cross-referencing all six modules against the backlog.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-004\n- **Severity**: HIGH\n- **Description**: The PRD (03_PLATFORM.md) specifies six integrated modules: Research, Document Management, Analysis (infinite canvas), Modelling (provable methods), Knowledge & Domain, and Organisational Insight. The IMPLEMENTATION-PLAN v3 frames work as \"ten platform primitives\" validated through the Research Module. The Analysis Module (infinite canvas for visual analysis) does not appear anywhere in BL-001 through BL-022. There is no explicit statement in the IMPLEMENTATION-PLAN that the Analysis Module is deferred and why. A product manager or new team member reading both documents cannot determine the deferred scope without cross-referencing all six modules against the backlog.\n- **Affected BL Items**: None in current backlog (the gap IS the absence of any BL item)\n- **Source Evidence**: hypothesis-consistency.md H1 gap 1; KNOWLEDGE-MAP Section 2 (Platform Layer)\n- **Resolution**: Add a \"Deferred Scope\" section to IMPLEMENTATION-PLAN explicitly listing the three deferred PRD modules (Analysis, Modelling, Organisational Insight) with rationale and the ADR/DEC that defers them. This does not require new decisions \u2014 it is a documentation clarification.\n- **Owner Recommendation**: Product lead; 1-hour documentation task\n- **Wave**: W0 \u2014 before Phase 1 design reviews\n\n---\n\n### GAP-005 \u2014 Index Service Not Listed as Layer 1 Primitive",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-005",
    "title": "[GAP-005] ADR-004 specifies the Index Service Architecture (contract-first, pluggable backends: OpenSearch + pgvector). The KNOWLEDGE-MAP confirms it is a key platform component. However, the IMPLEMENTATION-PLAN's \"ten platform primitives\" list does not include the Index Service. It is documented in the ADR and referenced in PLATFORM-FRAMING.md, but a developer building the primitives would not know it belongs at Layer 1 from reading the IMPLEMENTATION-PLAN alone.",
    "body": "# [GAP-005] ADR-004 specifies the Index Service Architecture (contract-first, pluggable backends: OpenSearch + pgvector). The KNOWLEDGE-MAP confirms it is a key platform component. However, the IMPLEMENTATION-PLAN's \"ten platform primitives\" list does not include the Index Service. It is documented in the ADR and referenced in PLATFORM-FRAMING.md, but a developer building the primitives would not know it belongs at Layer 1 from reading the IMPLEMENTATION-PLAN alone.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-005\n- **Severity**: HIGH\n- **Description**: ADR-004 specifies the Index Service Architecture (contract-first, pluggable backends: OpenSearch + pgvector). The KNOWLEDGE-MAP confirms it is a key platform component. However, the IMPLEMENTATION-PLAN's \"ten platform primitives\" list does not include the Index Service. It is documented in the ADR and referenced in PLATFORM-FRAMING.md, but a developer building the primitives would not know it belongs at Layer 1 from reading the IMPLEMENTATION-PLAN alone.\n- **Affected BL Items**: BL-003 (web research MCP tools), BL-016 (entity/citation substrate)\n- **Source Evidence**: hypothesis-consistency.md H1 gap 3; KNOWLEDGE-MAP Section 3 (Infrastructure & Storage)\n- **Resolution**: Add \"Index Service (pluggable search backend)\" as the eleventh platform primitive in IMPLEMENTATION-PLAN, or add a footnote under the existing \"MCP Tool Layer\" primitive that explicitly calls out Index Service as a sub-component. Cross-reference ADR-004.\n- **Owner Recommendation**: Architecture lead\n- **Wave**: W0 \u2014 before BL-003 or BL-016 implementation\n\n---\n\n### GAP-006 \u2014 Document Processing Pipeline Strategy Not in Decision Register",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-006",
    "title": "[GAP-006] ADR-007 specifies a tiered document processing pipeline (Fast, Standard, Deep) with parser adapters (Docling primary, Unstructured fallback, LlamaParse optional). DECISION-REGISTER has DEC-030 (PDF export via WeasyPrint) and DEC-033 (Jina Reader API), but there is no decision capturing the tiered pipeline strategy itself. A developer implementing document ingestion would not know the three-tier approach is specified in ADR-007 or that Docling is the primary parser.",
    "body": "# [GAP-006] ADR-007 specifies a tiered document processing pipeline (Fast, Standard, Deep) with parser adapters (Docling primary, Unstructured fallback, LlamaParse optional). DECISION-REGISTER has DEC-030 (PDF export via WeasyPrint) and DEC-033 (Jina Reader API), but there is no decision capturing the tiered pipeline strategy itself. A developer implementing document ingestion would not know the three-tier approach is specified in ADR-007 or that Docling is the primary parser.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-006\n- **Severity**: HIGH\n- **Description**: ADR-007 specifies a tiered document processing pipeline (Fast, Standard, Deep) with parser adapters (Docling primary, Unstructured fallback, LlamaParse optional). DECISION-REGISTER has DEC-030 (PDF export via WeasyPrint) and DEC-033 (Jina Reader API), but there is no decision capturing the tiered pipeline strategy itself. A developer implementing document ingestion would not know the three-tier approach is specified in ADR-007 or that Docling is the primary parser.\n- **Affected BL Items**: Any backlog items involving document ingestion or RAG (BL-016 adjacent)\n- **Source Evidence**: hypothesis-consistency.md H2 gap 2 (ADR-007 partial reflection)\n- **Resolution**: Add a decision to DECISION-REGISTER capturing: \"Document processing: tiered pipeline (Fast/Standard/Deep tiers) using Docling 2.3+ as primary parser, Unstructured 0.15+ as fallback, LlamaParse as optional paid API. Canonical output format: DocIR artifact.\" Cross-reference ADR-007.\n- **Owner Recommendation**: Backend track lead\n- **Wave**: W0 \u2014 before any document processing implementation\n\n---\n\n### GAP-007 \u2014 ADR-010 Infrastructure Not in Decision Register",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-007",
    "title": "[GAP-007] ADR-010 specifies the bootstrap infrastructure: PostgreSQL + pgvector + Neo4j + Redis. The DECISION-REGISTER has no infrastructure decision. DEC-037 mentions Langfuse self-hosted but not the database or cache infrastructure. A team member tasked with environment setup has no single locked decision to point to for infrastructure.",
    "body": "# [GAP-007] ADR-010 specifies the bootstrap infrastructure: PostgreSQL + pgvector + Neo4j + Redis. The DECISION-REGISTER has no infrastructure decision. DEC-037 mentions Langfuse self-hosted but not the database or cache infrastructure. A team member tasked with environment setup has no single locked decision to point to for infrastructure.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-007\n- **Severity**: MEDIUM\n- **Description**: ADR-010 specifies the bootstrap infrastructure: PostgreSQL + pgvector + Neo4j + Redis. The DECISION-REGISTER has no infrastructure decision. DEC-037 mentions Langfuse self-hosted but not the database or cache infrastructure. A team member tasked with environment setup has no single locked decision to point to for infrastructure.\n- **Affected BL Items**: All BL items (infrastructure is cross-cutting)\n- **Source Evidence**: hypothesis-consistency.md H2 gap 3\n- **Resolution**: Add a decision \"Bootstrap Infrastructure: PostgreSQL 16+ + pgvector 0.8+ (RDBMS and vector search dev), Neo4j Aura free (domain ontologies), Redis 7+ (cache, arq queue, profiles: full), MinIO (S3-compatible object storage, dev). Sourced from ADR-010.\" This is a documentation task; the infrastructure is already in docker-compose.yml.\n- **Owner Recommendation**: DevOps / infrastructure track\n- **Wave**: W0\n\n---\n\n### GAP-008 \u2014 Stale Claims Not Corrected in Source Documents",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-008",
    "title": "[GAP-008] CONSISTENCY-AUDIT-PLANS Part 3 identifies seven stale claims (SC-01 through SC-07) in planning documents that have not been corrected. The most impactful: (a) IMPLEMENTATION-PLAN \"What We Get For Free\" table lists arq background jobs as \"Available\" when the worker process operational status is unverified; (b) GIT-ISSUES BL-016 claims \"arq + Redis already configured\" implying it works; (c) DECISION-REGISTER DEC-040 says GML healer is Python/Pydantic when the frontend healer is TypeScript/HAST.",
    "body": "# [GAP-008] CONSISTENCY-AUDIT-PLANS Part 3 identifies seven stale claims (SC-01 through SC-07) in planning documents that have not been corrected. The most impactful: (a) IMPLEMENTATION-PLAN \"What We Get For Free\" table lists arq background jobs as \"Available\" when the worker process operational status is unverified; (b) GIT-ISSUES BL-016 claims \"arq + Redis already configured\" implying it works; (c) DECISION-REGISTER DEC-040 says GML healer is Python/Pydantic when the frontend healer is TypeScript/HAST.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-008\n- **Severity**: MEDIUM\n- **Description**: CONSISTENCY-AUDIT-PLANS Part 3 identifies seven stale claims (SC-01 through SC-07) in planning documents that have not been corrected. The most impactful: (a) IMPLEMENTATION-PLAN \"What We Get For Free\" table lists arq background jobs as \"Available\" when the worker process operational status is unverified; (b) GIT-ISSUES BL-016 claims \"arq + Redis already configured\" implying it works; (c) DECISION-REGISTER DEC-040 says GML healer is Python/Pydantic when the frontend healer is TypeScript/HAST.\n- **Affected BL Items**: BL-016 (entity substrate uses arq), BL-004/BL-009 (GML healer)\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS SC-01 through SC-07\n- **Resolution**: Apply all seven corrections listed in CONSISTENCY-AUDIT-PLANS SC-01 through SC-07. Specifically: downgrade arq status to \"unverified\"; add arq operational verification to Phase 0 checklist; split DEC-040 into DEC-040a (backend Python healer) and DEC-040b (frontend TypeScript/HAST healer).\n- **Owner Recommendation**: Documentation lead; review each SC item and apply correction\n- **Wave**: P0\n\n---\n\n### GAP-009 \u2014 Dependency Graph Errors in GIT-ISSUES (8 Blocked-By Fields Wrong)",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-009",
    "title": "[GAP-009] CONSISTENCY-AUDIT-PLANS Part 4 section 2A identifies eight blocked-by field errors in GIT-ISSUES. Specifically: BL-003 incorrectly lists BL-001 as a blocker (it is independent); BL-022 incorrectly lists BL-001 as a blocker (the direction is reversed \u2014 BL-022 design FEEDS BL-001); BL-005, BL-006, BL-018 omit Migration 0005 as a hard dependency; BL-012 acknowledges but doesn't formally list Migration 0005; BL-016 omits Migration 0005.",
    "body": "# [GAP-009] CONSISTENCY-AUDIT-PLANS Part 4 section 2A identifies eight blocked-by field errors in GIT-ISSUES. Specifically: BL-003 incorrectly lists BL-001 as a blocker (it is independent); BL-022 incorrectly lists BL-001 as a blocker (the direction is reversed \u2014 BL-022 design FEEDS BL-001); BL-005, BL-006, BL-018 omit Migration 0005 as a hard dependency; BL-012 acknowledges but doesn't formally list Migration 0005; BL-016 omits Migration 0005.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-009\n- **Severity**: MEDIUM\n- **Description**: CONSISTENCY-AUDIT-PLANS Part 4 section 2A identifies eight blocked-by field errors in GIT-ISSUES. Specifically: BL-003 incorrectly lists BL-001 as a blocker (it is independent); BL-022 incorrectly lists BL-001 as a blocker (the direction is reversed \u2014 BL-022 design FEEDS BL-001); BL-005, BL-006, BL-018 omit Migration 0005 as a hard dependency; BL-012 acknowledges but doesn't formally list Migration 0005; BL-016 omits Migration 0005.\n- **Affected BL Items**: BL-003, BL-005, BL-006, BL-008, BL-012, BL-016, BL-018, BL-022\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS I-02, I-03, I-04, I-05, I-06, I-07; DEPENDENCY-ANALYSIS corrections\n- **Resolution**: Apply the corrections from CONSISTENCY-AUDIT-PLANS Part 4 table 2A to all eight GIT-ISSUES entries. This is a mechanical update \u2014 the correct values are already specified in the audit.\n- **Owner Recommendation**: Project coordinator / documentation lead; 1\u20132 hour task\n- **Wave**: P0 \u2014 must be correct before Wave 0 execution starts\n\n---\n\n### GAP-010 \u2014 BL-015 and BL-008 Assigned to Wrong Milestone",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-010",
    "title": "[GAP-010] BL-015 (DeliverableStore Zustand slice) and BL-008 (DeliverableSelector component) have no dependencies and can start in Week 1 (Wave 0). Both are currently assigned to `phase:3-frontend` and Milestone M3 in GIT-ISSUES \u2014 an artifact of \"all frontend in Phase 3\" waterfall thinking. This means frontend work that unblocks other items is scheduled 8\u201310 weeks later than it needs to be.",
    "body": "# [GAP-010] BL-015 (DeliverableStore Zustand slice) and BL-008 (DeliverableSelector component) have no dependencies and can start in Week 1 (Wave 0). Both are currently assigned to `phase:3-frontend` and Milestone M3 in GIT-ISSUES \u2014 an artifact of \"all frontend in Phase 3\" waterfall thinking. This means frontend work that unblocks other items is scheduled 8\u201310 weeks later than it needs to be.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-010\n- **Severity**: MEDIUM\n- **Description**: BL-015 (DeliverableStore Zustand slice) and BL-008 (DeliverableSelector component) have no dependencies and can start in Week 1 (Wave 0). Both are currently assigned to `phase:3-frontend` and Milestone M3 in GIT-ISSUES \u2014 an artifact of \"all frontend in Phase 3\" waterfall thinking. This means frontend work that unblocks other items is scheduled 8\u201310 weeks later than it needs to be.\n- **Affected BL Items**: BL-015, BL-008\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS I-09, 2B\n- **Resolution**: Update GIT-ISSUES BL-015 and BL-008: change phase label to `phase:0-foundation`, update milestone to M0. No code change required.\n- **Owner Recommendation**: Project coordinator\n- **Wave**: P0\n\n---\n\n### GAP-011 \u2014 IMPLEMENTATION-PLAN Critical Path Arrow Backwards for BL-022",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-011",
    "title": "[GAP-011] IMPLEMENTATION-PLAN dependency graph shows `BL-022 (Data Brief, design only) \u25c4\u2500 BL-001`, placing BL-022 as downstream of BL-001. DEPENDENCY-ANALYSIS explicitly corrects this: the DataBrief schema design (BL-022) must precede BL-001 because BL-001 (Research Orchestrator) requires the DataBrief state field definitions to be locked first. The arrow is directionally wrong, and the critical path description `BL-002 \u2192 BL-001 \u2192 BL-022 \u2192 ...` is incorrect.",
    "body": "# [GAP-011] IMPLEMENTATION-PLAN dependency graph shows `BL-022 (Data Brief, design only) \u25c4\u2500 BL-001`, placing BL-022 as downstream of BL-001. DEPENDENCY-ANALYSIS explicitly corrects this: the DataBrief schema design (BL-022) must precede BL-001 because BL-001 (Research Orchestrator) requires the DataBrief state field definitions to be locked first. The arrow is directionally wrong, and the critical path description `BL-002 \u2192 BL-001 \u2192 BL-022 \u2192 ...` is incorrect.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-011\n- **Severity**: MEDIUM\n- **Description**: IMPLEMENTATION-PLAN dependency graph shows `BL-022 (Data Brief, design only) \u25c4\u2500 BL-001`, placing BL-022 as downstream of BL-001. DEPENDENCY-ANALYSIS explicitly corrects this: the DataBrief schema design (BL-022) must precede BL-001 because BL-001 (Research Orchestrator) requires the DataBrief state field definitions to be locked first. The arrow is directionally wrong, and the critical path description `BL-002 \u2192 BL-001 \u2192 BL-022 \u2192 ...` is incorrect.\n- **Affected BL Items**: BL-001, BL-022\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS I-10, SC-04\n- **Resolution**: Update IMPLEMENTATION-PLAN dependency diagram: flip `BL-022 \u25c4\u2500 BL-001` to `BL-022d \u2192 BL-001`. Update critical path text to show `BL-022 (design) \u2192 BL-001 \u2192 ...`.\n- **Owner Recommendation**: Architecture lead; 15-minute documentation edit\n- **Wave**: P0\n\n---\n\n### GAP-012 \u2014 Router Count Discrepancy in PLATFORM-GROUND-TRUTH",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-012",
    "title": "[GAP-012] PLATFORM-GROUND-TRUTH.md states \"11 routers\" for the API surface. Direct codebase inspection (hypothesis-code-alignment.md H5) confirmed 12 routers \u2014 the tags router was added in migration 0004 and is not included in the documented count.",
    "body": "# [GAP-012] PLATFORM-GROUND-TRUTH.md states \"11 routers\" for the API surface. Direct codebase inspection (hypothesis-code-alignment.md H5) confirmed 12 routers \u2014 the tags router was added in migration 0004 and is not included in the documented count.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-012\n- **Severity**: LOW\n- **Description**: PLATFORM-GROUND-TRUTH.md states \"11 routers\" for the API surface. Direct codebase inspection (hypothesis-code-alignment.md H5) confirmed 12 routers \u2014 the tags router was added in migration 0004 and is not included in the documented count.\n- **Affected BL Items**: None directly (documentation accuracy only)\n- **Source Evidence**: hypothesis-code-alignment.md H5.5\n- **Resolution**: Update PLATFORM-GROUND-TRUTH.md Section 5 (API Routes) from \"11 routers\" to \"12 routers, including tags router added in migration 0004.\"\n- **Owner Recommendation**: Documentation lead; 5-minute fix\n- **Wave**: W0\n\n---\n\n### GAP-013 \u2014 `<answer>` Wrapper Stripping Not Addressed in GML Renderer Spec",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-013",
    "title": "[GAP-013] DEC-022 locks the LLM output format as `<answer>...</answer>` XML wrapper with `<gml-*>` tags inside. GML-RENDERING-ANALYSIS (which specifies the complete GML rendering pipeline) does not mention the `<answer>` wrapper at all. There is no specification for where and how the wrapper is stripped before the GML content reaches the renderer.",
    "body": "# [GAP-013] DEC-022 locks the LLM output format as `<answer>...</answer>` XML wrapper with `<gml-*>` tags inside. GML-RENDERING-ANALYSIS (which specifies the complete GML rendering pipeline) does not mention the `<answer>` wrapper at all. There is no specification for where and how the wrapper is stripped before the GML content reaches the renderer.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-013\n- **Severity**: LOW\n- **Description**: DEC-022 locks the LLM output format as `<answer>...</answer>` XML wrapper with `<gml-*>` tags inside. GML-RENDERING-ANALYSIS (which specifies the complete GML rendering pipeline) does not mention the `<answer>` wrapper at all. There is no specification for where and how the wrapper is stripped before the GML content reaches the renderer.\n- **Affected BL Items**: BL-009 (ReportRenderer)\n- **Source Evidence**: CONSISTENCY-AUDIT-ANALYSIS C-09; CONSISTENCY-AUDIT-PLANS SC-03 (partial)\n- **Resolution**: Add a \"Pre-processing Step\" to GML-RENDERING-ANALYSIS Section 7 (Implementation Checklist): \"1. Extract GML content from `<answer>...</answer>` wrapper before passing to GmlRenderer. Handle: partial `<answer>` during streaming (buffer until closing tag), malformed wrapper (fallback to plain markdown rendering), nested tags inside the answer body.\"\n- **Owner Recommendation**: Frontend track lead; update GML-RENDERING-ANALYSIS only\n- **Wave**: W0 \u2014 before BL-009 implementation\n\n---\n\n## Category 2: Design Gaps\n\n### GAP-014 \u2014 No Explicit Integration Contract for LangGraph \u2192 SSE Pipeline",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-014",
    "title": "[GAP-014] The streaming-events-extract.md documents 22 confirmed Superagent event types plus 4 NYQST proposed types, with complete Pydantic schemas and the NDJSON envelope format. The orchestration-extract.md documents the full fan-out dispatch pattern. However, there is no document that specifies the explicit integration contract between the two: which LangGraph events (on_tool_start, on_chat_model_stream, on_end) map to which SSE event types (node_tool_event, message_delta, done). The LangGraphToAISDKAdapter pseudocode in streaming-events-extract.md is an example, not a locked contract.",
    "body": "# [GAP-014] The streaming-events-extract.md documents 22 confirmed Superagent event types plus 4 NYQST proposed types, with complete Pydantic schemas and the NDJSON envelope format. The orchestration-extract.md documents the full fan-out dispatch pattern. However, there is no document that specifies the explicit integration contract between the two: which LangGraph events (on_tool_start, on_chat_model_stream, on_end) map to which SSE event types (node_tool_event, message_delta, done). The LangGraphToAISDKAdapter pseudocode in streaming-events-extract.md is an example, not a locked contract.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-014\n- **Severity**: CRITICAL\n- **Description**: The streaming-events-extract.md documents 22 confirmed Superagent event types plus 4 NYQST proposed types, with complete Pydantic schemas and the NDJSON envelope format. The orchestration-extract.md documents the full fan-out dispatch pattern. However, there is no document that specifies the explicit integration contract between the two: which LangGraph events (on_tool_start, on_chat_model_stream, on_end) map to which SSE event types (node_tool_event, message_delta, done). The LangGraphToAISDKAdapter pseudocode in streaming-events-extract.md is an example, not a locked contract.\n- **Affected BL Items**: BL-001 (Research Orchestrator), BL-002 (RunEvent schema extensions)\n- **Source Evidence**: streaming-events-extract.md (Two-Stream Architecture, LangGraph \u2192 AI SDK Adapter); orchestration-extract.md Section 1.3; KNOWLEDGE-MAP Phase 0 deliverables\n- **Resolution**: Create a formal \"Event Contract v1\" document (referenced in KNOWLEDGE-MAP as a Phase 0 deliverable but not yet produced as a locked spec). The contract must: enumerate every LangGraph event hook (on_tool_start, on_tool_end, on_chat_model_stream, on_chain_start, on_chain_end) and specify exactly which SSE event type each maps to, what payload fields are included, and which LangGraph state fields are read for each mapping.\n- **Owner Recommendation**: Backend architecture lead (BL-002 owner)\n- **Wave**: P0 \u2014 this is a Phase 0 deliverable per KNOWLEDGE-MAP and must exist before BL-001 implementation\n\n---\n\n### GAP-015 \u2014 Tool Fallback Chain Strategy Not Specified in BL-001",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-015",
    "title": "[GAP-015] Superagent's orchestration shows a clear tool failure cascade: FactSet \u2192 SEC Filings \u2192 AlphaVantage \u2192 FinancialModelingPrep. This \"FALLBACK_CHAINS\" pattern is documented in orchestration-extract.md Section 4.2 with explicit code. BL-001 (Research Orchestrator Graph) is the backlog item that must implement this pattern. However, BL-001's spec (MAPPING-01) does not explicitly design the fallback chain mechanism. The term \"fallback\" appears in the backlog context but the algorithm (try primary \u2192 emit fallback_used event \u2192 try secondary \u2192 emit all_tools_failed if all fail) is not in the spec.",
    "body": "# [GAP-015] Superagent's orchestration shows a clear tool failure cascade: FactSet \u2192 SEC Filings \u2192 AlphaVantage \u2192 FinancialModelingPrep. This \"FALLBACK_CHAINS\" pattern is documented in orchestration-extract.md Section 4.2 with explicit code. BL-001 (Research Orchestrator Graph) is the backlog item that must implement this pattern. However, BL-001's spec (MAPPING-01) does not explicitly design the fallback chain mechanism. The term \"fallback\" appears in the backlog context but the algorithm (try primary \u2192 emit fallback_used event \u2192 try secondary \u2192 emit all_tools_failed if all fail) is not in the spec.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-015\n- **Severity**: HIGH\n- **Description**: Superagent's orchestration shows a clear tool failure cascade: FactSet \u2192 SEC Filings \u2192 AlphaVantage \u2192 FinancialModelingPrep. This \"FALLBACK_CHAINS\" pattern is documented in orchestration-extract.md Section 4.2 with explicit code. BL-001 (Research Orchestrator Graph) is the backlog item that must implement this pattern. However, BL-001's spec (MAPPING-01) does not explicitly design the fallback chain mechanism. The term \"fallback\" appears in the backlog context but the algorithm (try primary \u2192 emit fallback_used event \u2192 try secondary \u2192 emit all_tools_failed if all fail) is not in the spec.\n- **Affected BL Items**: BL-001, BL-003 (web research MCP tools that have fallback providers)\n- **Source Evidence**: hypothesis-consistency.md H4 gap 4; orchestration-extract.md Section 4.1, 4.2\n- **Resolution**: Amend BL-001 technical notes (MAPPING-01) to include the fallback chain algorithm: (1) Try primary provider, emit `tool_call_started`; (2) On failure: emit `node_tool_event(event=\"fallback_used\")`; (3) Try secondary provider; (4) If all fail: emit `node_tool_event(event=\"all_tools_failed\")` and mark task as partial; (5) Fan-in detects partial tasks and routes to meta-reasoning.\n- **Owner Recommendation**: Backend track lead (BL-001 implementer)\n- **Wave**: W0 \u2014 before BL-001 implementation begins\n\n---\n\n### GAP-016 \u2014 Async Entity Creation Worker Has No Dedicated Backlog Item",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-016",
    "title": "[GAP-016] DEC-017 specifies \"Async entity creation: Decoupled from main response stream via arq background worker.\" PLATFORM-GROUND-TRUTH confirms `has_async_entities_in_progress` flag exists. BL-016 covers the entity/citation substrate schema. However, there is no dedicated backlog item for \"Implement async entity creation worker\" \u2014 the arq background job that processes entities after the main stream completes. The work is mentioned in DEC-017 and BL-016 body text but is not a standalone, estimable, assignable item.",
    "body": "# [GAP-016] DEC-017 specifies \"Async entity creation: Decoupled from main response stream via arq background worker.\" PLATFORM-GROUND-TRUTH confirms `has_async_entities_in_progress` flag exists. BL-016 covers the entity/citation substrate schema. However, there is no dedicated backlog item for \"Implement async entity creation worker\" \u2014 the arq background job that processes entities after the main stream completes. The work is mentioned in DEC-017 and BL-016 body text but is not a standalone, estimable, assignable item.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-016\n- **Severity**: HIGH\n- **Description**: DEC-017 specifies \"Async entity creation: Decoupled from main response stream via arq background worker.\" PLATFORM-GROUND-TRUTH confirms `has_async_entities_in_progress` flag exists. BL-016 covers the entity/citation substrate schema. However, there is no dedicated backlog item for \"Implement async entity creation worker\" \u2014 the arq background job that processes entities after the main stream completes. The work is mentioned in DEC-017 and BL-016 body text but is not a standalone, estimable, assignable item.\n- **Affected BL Items**: BL-016 (entity substrate), adjacent to billing and observability\n- **Source Evidence**: hypothesis-consistency.md H4 gap 5; CONSISTENCY-AUDIT-PLANS SC-05 (arq claim)\n- **Resolution**: Create backlog item BL-023: \"Async Entity Creation Worker \u2014 implement arq background job that processes entities after stream completion, triggered by `has_async_entities_pending: true` in the `done` event. Includes: job definition in jobs.py, entity resolution logic, `references_found` emission on completion.\" Size: ~1 SP.\n- **Owner Recommendation**: Backend track lead\n- **Wave**: W1 \u2014 needed before BL-016 is considered complete\n\n---\n\n### GAP-017 \u2014 NDM v1 JSON Schema Not Formalized",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-017",
    "title": "[GAP-017] The KNOWLEDGE-MAP Section 10 explicitly lists \"NDM v1 exact JSON schema (sketched in SUPERAGENT_PARITY_PLAN \u00a73.4, needs formalization)\" as a needed-soon open thread. The orchestration-extract.md specifies the DataBrief schema (BL-022) but the NDM (NYQST Document Markup) v1 schema \u2014 the JSON AST format used for report generation (DEC-015a) \u2014 is only sketched. BL-004 (Markup AST schema) depends on this being locked before implementation.",
    "body": "# [GAP-017] The KNOWLEDGE-MAP Section 10 explicitly lists \"NDM v1 exact JSON schema (sketched in SUPERAGENT_PARITY_PLAN \u00a73.4, needs formalization)\" as a needed-soon open thread. The orchestration-extract.md specifies the DataBrief schema (BL-022) but the NDM (NYQST Document Markup) v1 schema \u2014 the JSON AST format used for report generation (DEC-015a) \u2014 is only sketched. BL-004 (Markup AST schema) depends on this being locked before implementation.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-017\n- **Severity**: HIGH\n- **Description**: The KNOWLEDGE-MAP Section 10 explicitly lists \"NDM v1 exact JSON schema (sketched in SUPERAGENT_PARITY_PLAN \u00a73.4, needs formalization)\" as a needed-soon open thread. The orchestration-extract.md specifies the DataBrief schema (BL-022) but the NDM (NYQST Document Markup) v1 schema \u2014 the JSON AST format used for report generation (DEC-015a) \u2014 is only sketched. BL-004 (Markup AST schema) depends on this being locked before implementation.\n- **Affected BL Items**: BL-004, BL-005 (report generation pipeline), BL-009 (ReportRenderer)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; DEC-015a; BL-004 in BACKLOG.md\n- **Resolution**: Formalize the NDM v1 JSON schema as a standalone specification document. Required fields: node types (18 GML tags mapped to JSON node representations), nesting rules, chart data structure, citation reference format, section hierarchy. This is a prerequisite for BL-004.\n- **Owner Recommendation**: Architecture lead \u2014 can be derived from GML-RENDERING-ANALYSIS tag inventory and orchestration-extract.md Section 3.1\n- **Wave**: W0 \u2014 blocks BL-004\n\n---\n\n### GAP-018 \u2014 MCP Tool Discovery Filtering Algorithm Unspecified",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-018",
    "title": "[GAP-018] KNOWLEDGE-MAP Section 10 lists \"MCP tool discovery filtering (context-scoped, needs algorithm for 'is tool X relevant to session Y?')\" as a needed-soon open thread. ADR-008 specifies MCP as the tool protocol with session-scoped discovery. DEC-046 locks MCP search (hot-swap Brave/Tavily). However, the algorithm for how the orchestrator decides which MCP tools are available in a given session context is not specified. This matters because the Research Orchestrator (BL-001) must know which tools to include in a given PlanTask.",
    "body": "# [GAP-018] KNOWLEDGE-MAP Section 10 lists \"MCP tool discovery filtering (context-scoped, needs algorithm for 'is tool X relevant to session Y?')\" as a needed-soon open thread. ADR-008 specifies MCP as the tool protocol with session-scoped discovery. DEC-046 locks MCP search (hot-swap Brave/Tavily). However, the algorithm for how the orchestrator decides which MCP tools are available in a given session context is not specified. This matters because the Research Orchestrator (BL-001) must know which tools to include in a given PlanTask.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-018\n- **Severity**: HIGH\n- **Description**: KNOWLEDGE-MAP Section 10 lists \"MCP tool discovery filtering (context-scoped, needs algorithm for 'is tool X relevant to session Y?')\" as a needed-soon open thread. ADR-008 specifies MCP as the tool protocol with session-scoped discovery. DEC-046 locks MCP search (hot-swap Brave/Tavily). However, the algorithm for how the orchestrator decides which MCP tools are available in a given session context is not specified. This matters because the Research Orchestrator (BL-001) must know which tools to include in a given PlanTask.\n- **Affected BL Items**: BL-001 (orchestrator tool selection), BL-003 (MCP tool definitions)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; ADR-008; orchestration-extract.md Section 2.1 (tool dispatch)\n- **Resolution**: Specify the tool discovery algorithm in BL-001 technical notes: (1) On session creation, register available MCP tools based on tenant tier (sandbox: subset, professional: full); (2) On PlanTask creation, filter tool list by task category (financial_data \u2192 FactSet chain; web_search \u2192 Brave/Tavily; document \u2192 DocIR tools); (3) Pass filtered tool list to research_executor node.\n- **Owner Recommendation**: Backend architecture lead\n- **Wave**: W0\n\n---\n\n### GAP-019 \u2014 Policy Evaluation Order for HITL Not Specified",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-019",
    "title": "[GAP-019] ADR-009 defines four HITL governance templates (Exploratory, Standard, Regulated, Audit-Critical). KNOWLEDGE-MAP Section 10 lists \"Policy evaluation order (ADR-009 lists 4 templates, needs conflict resolution)\" as an open thread. When a run is configured with a governance template, the exact precedence rules for when to interrupt vs. continue are not specified. DEC-047 defers the clarification UI to v1.5 but the backend schema and interrupt logic are in scope for v1.",
    "body": "# [GAP-019] ADR-009 defines four HITL governance templates (Exploratory, Standard, Regulated, Audit-Critical). KNOWLEDGE-MAP Section 10 lists \"Policy evaluation order (ADR-009 lists 4 templates, needs conflict resolution)\" as an open thread. When a run is configured with a governance template, the exact precedence rules for when to interrupt vs. continue are not specified. DEC-047 defers the clarification UI to v1.5 but the backend schema and interrupt logic are in scope for v1.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-019\n- **Severity**: MEDIUM\n- **Description**: ADR-009 defines four HITL governance templates (Exploratory, Standard, Regulated, Audit-Critical). KNOWLEDGE-MAP Section 10 lists \"Policy evaluation order (ADR-009 lists 4 templates, needs conflict resolution)\" as an open thread. When a run is configured with a governance template, the exact precedence rules for when to interrupt vs. continue are not specified. DEC-047 defers the clarification UI to v1.5 but the backend schema and interrupt logic are in scope for v1.\n- **Affected BL Items**: BL-021 (clarification flow \u2014 backend schema)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; ADR-009; DEC-047\n- **Resolution**: Document the policy evaluation algorithm for the four templates: Exploratory (no interrupts); Standard (interrupt on approval_required tool categories); Regulated (interrupt before any external data access); Audit-Critical (interrupt at every plan step). This specification belongs in BL-021 technical notes and is a prerequisite for the LangGraph interrupt implementation.\n- **Owner Recommendation**: Product lead + backend architecture lead\n- **Wave**: W1 \u2014 before BL-021 implementation\n\n---\n\n### GAP-020 \u2014 Entity Reference Algorithm Edge Cases Unspecified",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-020",
    "title": "[GAP-020] KNOWLEDGE-MAP Section 10 lists \"Entity reference algorithm (sketched, needs edge cases: citations, tool outputs, deliverables)\" as a needed-soon open thread. BL-016 covers the entity/citation substrate, but the exact deduplication algorithm (content-hash-based? URL-based? Both?), the algorithm for resolving inline citation identifiers to entity IDs in the GML output, and the behavior when an entity is referenced in both a deliverable and a tool output are not specified.",
    "body": "# [GAP-020] KNOWLEDGE-MAP Section 10 lists \"Entity reference algorithm (sketched, needs edge cases: citations, tool outputs, deliverables)\" as a needed-soon open thread. BL-016 covers the entity/citation substrate, but the exact deduplication algorithm (content-hash-based? URL-based? Both?), the algorithm for resolving inline citation identifiers to entity IDs in the GML output, and the behavior when an entity is referenced in both a deliverable and a tool output are not specified.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-020\n- **Severity**: MEDIUM\n- **Description**: KNOWLEDGE-MAP Section 10 lists \"Entity reference algorithm (sketched, needs edge cases: citations, tool outputs, deliverables)\" as a needed-soon open thread. BL-016 covers the entity/citation substrate, but the exact deduplication algorithm (content-hash-based? URL-based? Both?), the algorithm for resolving inline citation identifiers to entity IDs in the GML output, and the behavior when an entity is referenced in both a deliverable and a tool output are not specified.\n- **Affected BL Items**: BL-016 (entity substrate), BL-009 (ReportRenderer \u2014 citation rendering)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; orchestration-extract.md Section 1.4 (Entity schema)\n- **Resolution**: Define the entity reference algorithm: (1) Primary deduplication key: SHA-256 of content; (2) Secondary: URL normalization for web sources; (3) Citation identifier: UUID assigned at entity creation, stored in entity.metadata.citation_identifier; (4) GML citation binding: `<gml-inlinecitation identifier=\"X\"/>` resolved by looking up entity where `citation_identifier == X`; (5) Cross-type references: tool output entities and deliverable entities share the same table, differentiated by entity_type.\n- **Owner Recommendation**: Backend track lead\n- **Wave**: W1 \u2014 before BL-016 integration with BL-009\n\n---\n\n### GAP-021 \u2014 Error Handling Failure Modes Not Enumerated",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-021",
    "title": "[GAP-021] The streaming-events-extract.md documents the connection lifecycle and retry strategy (exponential backoff, 5 attempts). The orchestration-extract.md documents the graceful degradation hierarchy (tool error \u2192 task error \u2192 plan error \u2192 run error). However, there is no document that enumerates what happens at each failure level from the platform's perspective: what state is written to the DB, what SSE events are emitted, what the user sees, and how the run is marked in the Run ledger. The \"what happens if ALL fallback tools fail\" case (orchestration-extract.md Section 6, open question 9) is still open.",
    "body": "# [GAP-021] The streaming-events-extract.md documents the connection lifecycle and retry strategy (exponential backoff, 5 attempts). The orchestration-extract.md documents the graceful degradation hierarchy (tool error \u2192 task error \u2192 plan error \u2192 run error). However, there is no document that enumerates what happens at each failure level from the platform's perspective: what state is written to the DB, what SSE events are emitted, what the user sees, and how the run is marked in the Run ledger. The \"what happens if ALL fallback tools fail\" case (orchestration-extract.md Section 6, open question 9) is still open.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-021\n- **Severity**: MEDIUM\n- **Description**: The streaming-events-extract.md documents the connection lifecycle and retry strategy (exponential backoff, 5 attempts). The orchestration-extract.md documents the graceful degradation hierarchy (tool error \u2192 task error \u2192 plan error \u2192 run error). However, there is no document that enumerates what happens at each failure level from the platform's perspective: what state is written to the DB, what SSE events are emitted, what the user sees, and how the run is marked in the Run ledger. The \"what happens if ALL fallback tools fail\" case (orchestration-extract.md Section 6, open question 9) is still open.\n- **Affected BL Items**: BL-001 (orchestrator), BL-002 (RunEvent schema)\n- **Source Evidence**: orchestration-extract.md Section 4, Section 6 open question 9; streaming-events-extract.md SSE Protocol Details\n- **Resolution**: Create a failure mode table in BL-001 technical notes with four rows (tool failure, task failure, plan failure, run failure), specifying: DB state written, SSE events emitted, user-visible message, run ledger status. Define the \"all fallbacks exhausted\" behavior: emit `node_tool_event(event=\"all_tools_failed\")`, mark task as failed, trigger meta-reasoning if at least 50% of other tasks succeeded, else emit plan error.\n- **Owner Recommendation**: Backend architecture lead\n- **Wave**: W0\n\n---\n\n### GAP-022 \u2014 P0 Bug: RunEvent Sequence Number Race Condition",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-022",
    "title": "[GAP-022] Direct codebase inspection confirmed a TOCTOU (time-of-check-to-time-of-use) race condition in `src/intelli/repositories/runs.py` `_get_next_sequence` method. The method SELECT MAX(sequence_num) then INSERT with MAX+1. Under concurrent parallel task execution (which BL-001 Send() fan-out will trigger), multiple tasks can SELECT the same MAX value and attempt to INSERT with the same sequence_num+1, violating the unique constraint `(run_id, sequence_num)`. This causes data corruption in the run ledger under load.",
    "body": "# [GAP-022] Direct codebase inspection confirmed a TOCTOU (time-of-check-to-time-of-use) race condition in `src/intelli/repositories/runs.py` `_get_next_sequence` method. The method SELECT MAX(sequence_num) then INSERT with MAX+1. Under concurrent parallel task execution (which BL-001 Send() fan-out will trigger), multiple tasks can SELECT the same MAX value and attempt to INSERT with the same sequence_num+1, violating the unique constraint `(run_id, sequence_num)`. This causes data corruption in the run ledger under load.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-022\n- **Severity**: CRITICAL\n- **Description**: Direct codebase inspection confirmed a TOCTOU (time-of-check-to-time-of-use) race condition in `src/intelli/repositories/runs.py` `_get_next_sequence` method. The method SELECT MAX(sequence_num) then INSERT with MAX+1. Under concurrent parallel task execution (which BL-001 Send() fan-out will trigger), multiple tasks can SELECT the same MAX value and attempt to INSERT with the same sequence_num+1, violating the unique constraint `(run_id, sequence_num)`. This causes data corruption in the run ledger under load.\n- **Affected BL Items**: BL-001 (fan-out creates concurrent writes), BL-002 (RunEvent schema)\n- **Source Evidence**: hypothesis-code-alignment.md H7.1 (bug confirmed in production code)\n- **Resolution**: Fix `_get_next_sequence` before implementing BL-001 fan-out. Three options: (1) Replace SELECT MAX with `SEQUENCE` or `GENERATED ALWAYS AS IDENTITY` at DB level (cleanest); (2) Use `SELECT FOR UPDATE` with `SERIALIZABLE` isolation; (3) Move to DB-level trigger. Recommend option 1: add `sequence_num BIGINT GENERATED ALWAYS AS IDENTITY` to RunEvent in Migration 0005. Create INFRA-BUG-001 tracking issue.\n- **Owner Recommendation**: Backend track lead \u2014 must fix before any BL-001 work begins\n- **Wave**: P0 \u2014 production-blocking; blocks BL-001\n\n---\n\n### GAP-023 \u2014 P0 Bug: ARQ Worker Registry Initialization Order",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-023",
    "title": "[GAP-023] Direct codebase inspection confirmed that `WorkerSettings.functions` in `src/intelli/core/jobs.py` is evaluated as a class variable at class definition time (module import). At that point, `_job_registry` is still empty because the `@job()` decorators on functions defined below `WorkerSettings` have not yet run. The result: ARQ worker starts with an empty functions list and silently ignores all job submissions. This means any code relying on arq background workers (BL-016 async entity creation, BL-012 billing batch jobs) will appear to work but jobs will never execute.",
    "body": "# [GAP-023] Direct codebase inspection confirmed that `WorkerSettings.functions` in `src/intelli/core/jobs.py` is evaluated as a class variable at class definition time (module import). At that point, `_job_registry` is still empty because the `@job()` decorators on functions defined below `WorkerSettings` have not yet run. The result: ARQ worker starts with an empty functions list and silently ignores all job submissions. This means any code relying on arq background workers (BL-016 async entity creation, BL-012 billing batch jobs) will appear to work but jobs will never execute.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-023\n- **Severity**: CRITICAL\n- **Description**: Direct codebase inspection confirmed that `WorkerSettings.functions` in `src/intelli/core/jobs.py` is evaluated as a class variable at class definition time (module import). At that point, `_job_registry` is still empty because the `@job()` decorators on functions defined below `WorkerSettings` have not yet run. The result: ARQ worker starts with an empty functions list and silently ignores all job submissions. This means any code relying on arq background workers (BL-016 async entity creation, BL-012 billing batch jobs) will appear to work but jobs will never execute.\n- **Affected BL Items**: BL-016 (async entity creation), BL-012 (billing batch jobs)\n- **Source Evidence**: hypothesis-code-alignment.md H7.2 (bug confirmed in production code)\n- **Resolution**: Fix `WorkerSettings.functions` before implementing BL-016 or any arq-dependent work. Fix options: (1) Use `@property` or callable for late binding; (2) Move `WorkerSettings` to a separate module loaded after all job definitions; (3) Use `__init_subclass__` pattern. Recommend option 2 as simplest: create `src/intelli/core/worker_settings.py` that imports from `jobs.py` (ensuring decorator execution order). Also verifies GAP-016's prerequisite: arq must be confirmed operational before BL-016 begins. Create INFRA-BUG-002 tracking issue.\n- **Owner Recommendation**: Backend track lead; prerequisite for arq operational verification (CONSISTENCY-AUDIT-PLANS SC-01)\n- **Wave**: P0 \u2014 production-blocking; must fix before Wave 0 arq verification checkpoint\n\n---\n\n## Category 3: Implementation Gaps\n\n### GAP-024 \u2014 LiteLLM Integration: Designed but Not Coded",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-024",
    "title": "[GAP-024] DEC-042 specifies LiteLLM multi-provider hot-swap for v1.5+ (OpenAI-only for v1). The billing-metering-extract.md documents the LiteLLM + Langfuse integration pattern in detail (Router, callbacks, cost tracking via Langfuse REST API). However, KNOWLEDGE-MAP Section 10 explicitly lists \"LiteLLM hot-swap implementation (DEC-042, designed but not coded)\" as a deferred item. The current platform uses `langchain_openai.ChatOpenAI` directly. The cost tracking pipeline described in billing-metering-extract.md Section 4.2 requires LiteLLM to be in place for Langfuse to capture per-call costs automatically.",
    "body": "# [GAP-024] DEC-042 specifies LiteLLM multi-provider hot-swap for v1.5+ (OpenAI-only for v1). The billing-metering-extract.md documents the LiteLLM + Langfuse integration pattern in detail (Router, callbacks, cost tracking via Langfuse REST API). However, KNOWLEDGE-MAP Section 10 explicitly lists \"LiteLLM hot-swap implementation (DEC-042, designed but not coded)\" as a deferred item. The current platform uses `langchain_openai.ChatOpenAI` directly. The cost tracking pipeline described in billing-metering-extract.md Section 4.2 requires LiteLLM to be in place for Langfuse to capture per-call costs automatically.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-024\n- **Severity**: HIGH\n- **Description**: DEC-042 specifies LiteLLM multi-provider hot-swap for v1.5+ (OpenAI-only for v1). The billing-metering-extract.md documents the LiteLLM + Langfuse integration pattern in detail (Router, callbacks, cost tracking via Langfuse REST API). However, KNOWLEDGE-MAP Section 10 explicitly lists \"LiteLLM hot-swap implementation (DEC-042, designed but not coded)\" as a deferred item. The current platform uses `langchain_openai.ChatOpenAI` directly. The cost tracking pipeline described in billing-metering-extract.md Section 4.2 requires LiteLLM to be in place for Langfuse to capture per-call costs automatically.\n- **Affected BL Items**: BL-012 (billing/metering \u2014 depends on cost tracking), BL-013 (quota enforcement)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10 (Deferred to v1.5+); billing-metering-extract.md Section 4.2; hypothesis-code-alignment.md H5.4 (confirmed: ChatOpenAI only, no LiteLLM)\n- **Resolution**: Determine whether v1 billing requires LiteLLM in the critical path. If cost tracking (DEC-045, $2/run budget) is required for v1, LiteLLM must be introduced before BL-012 can be completed. If cost tracking can be approximated (e.g., count tokens from ChatOpenAI response metadata), LiteLLM can remain deferred. Decision required before BL-012 is scheduled.\n- **Owner Recommendation**: Architecture lead \u2014 needs explicit wave assignment decision\n- **Wave**: W1 \u2014 decision needed before BL-012 begins; implementation timing depends on decision\n\n---\n\n### GAP-025 \u2014 Langfuse Self-Hosted Deployment Not Sized or Planned",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-025",
    "title": "[GAP-025] DEC-045 locks Langfuse self-hosted (MIT license) for observability and billing data. KNOWLEDGE-MAP Section 10 lists \"Langfuse self-hosted deployment (sizing, backup strategy)\" as an external dependency TBD. The docker-compose.yml has a `profiles: [\"observability\"]` profile referenced in hypothesis-code-alignment.md H8 discussion, but there is no specification for: Langfuse container resource sizing, backup strategy, data retention policy, or how the Langfuse REST API will be accessed from the FastAPI backend for billing queries.",
    "body": "# [GAP-025] DEC-045 locks Langfuse self-hosted (MIT license) for observability and billing data. KNOWLEDGE-MAP Section 10 lists \"Langfuse self-hosted deployment (sizing, backup strategy)\" as an external dependency TBD. The docker-compose.yml has a `profiles: [\"observability\"]` profile referenced in hypothesis-code-alignment.md H8 discussion, but there is no specification for: Langfuse container resource sizing, backup strategy, data retention policy, or how the Langfuse REST API will be accessed from the FastAPI backend for billing queries.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-025\n- **Severity**: HIGH\n- **Description**: DEC-045 locks Langfuse self-hosted (MIT license) for observability and billing data. KNOWLEDGE-MAP Section 10 lists \"Langfuse self-hosted deployment (sizing, backup strategy)\" as an external dependency TBD. The docker-compose.yml has a `profiles: [\"observability\"]` profile referenced in hypothesis-code-alignment.md H8 discussion, but there is no specification for: Langfuse container resource sizing, backup strategy, data retention policy, or how the Langfuse REST API will be accessed from the FastAPI backend for billing queries.\n- **Affected BL Items**: BL-012 (billing \u2014 uses Langfuse REST API for cost data), BL-013 (quota middleware)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; billing-metering-extract.md Section 4.2; DEC-045\n- **Resolution**: Add a Langfuse deployment specification: container resource requirements (CPU, RAM), data retention policy (30 days minimum for billing), backup schedule (daily), and a `docker-compose.langfuse.yml` or addition to the `observability` profile. Define the REST API call pattern for billing queries.\n- **Owner Recommendation**: DevOps / infrastructure track\n- **Wave**: W0 \u2014 required before BL-012 implementation\n\n---\n\n### GAP-026 \u2014 Search Provider Selection Requires Cost Comparison",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-026",
    "title": "[GAP-026] DEC-046 specifies MCP search with hot-swap Brave/Tavily. KNOWLEDGE-MAP Section 10 lists \"Search provider selection (Brave API vs Tavily, cost comparison needed)\" as an external dependency TBD. DEC-032 (original) locked Brave Search API, superseded by DEC-046 which adds Tavily as an alternative but does not select between them. BL-003 (web research MCP tools) must implement one as the default with the other as the fallback \u2014 but which is primary is not specified.",
    "body": "# [GAP-026] DEC-046 specifies MCP search with hot-swap Brave/Tavily. KNOWLEDGE-MAP Section 10 lists \"Search provider selection (Brave API vs Tavily, cost comparison needed)\" as an external dependency TBD. DEC-032 (original) locked Brave Search API, superseded by DEC-046 which adds Tavily as an alternative but does not select between them. BL-003 (web research MCP tools) must implement one as the default with the other as the fallback \u2014 but which is primary is not specified.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-026\n- **Severity**: HIGH\n- **Description**: DEC-046 specifies MCP search with hot-swap Brave/Tavily. KNOWLEDGE-MAP Section 10 lists \"Search provider selection (Brave API vs Tavily, cost comparison needed)\" as an external dependency TBD. DEC-032 (original) locked Brave Search API, superseded by DEC-046 which adds Tavily as an alternative but does not select between them. BL-003 (web research MCP tools) must implement one as the default with the other as the fallback \u2014 but which is primary is not specified.\n- **Affected BL Items**: BL-003 (MCP web research tools)\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; DEC-046; hypothesis-consistency.md H4 (tool fallback)\n- **Resolution**: Conduct Brave vs Tavily cost comparison (API pricing per 1000 queries, rate limits, result quality for financial/regulatory queries). Lock a decision specifying primary and fallback. This is an operational/procurement decision that must precede BL-003 implementation. Estimated effort: 2-hour research task.\n- **Owner Recommendation**: Product / engineering lead\n- **Wave**: W0 \u2014 before BL-003\n\n---\n\n### GAP-027 \u2014 Neo4j Aura Free Tier Limits Not Assessed",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-027",
    "title": "[GAP-027] KNOWLEDGE-MAP Section 10 lists \"Neo4j Aura free tier limits \u2192 upgrade/fallback plan\" as an external dependency TBD. ADR-010 specifies Neo4j Aura free for graph domain ontologies. The free tier has storage limits (typically 200K nodes, 400K relationships, 50MB storage on the free plan). If the platform's domain ontologies for PropSygnal/RegSygnal exceed these limits, the free tier will fail without warning. No fallback plan (upgrade to paid, self-hosted Neo4j, or alternative graph DB) is documented.",
    "body": "# [GAP-027] KNOWLEDGE-MAP Section 10 lists \"Neo4j Aura free tier limits \u2192 upgrade/fallback plan\" as an external dependency TBD. ADR-010 specifies Neo4j Aura free for graph domain ontologies. The free tier has storage limits (typically 200K nodes, 400K relationships, 50MB storage on the free plan). If the platform's domain ontologies for PropSygnal/RegSygnal exceed these limits, the free tier will fail without warning. No fallback plan (upgrade to paid, self-hosted Neo4j, or alternative graph DB) is documented.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-027\n- **Severity**: MEDIUM\n- **Description**: KNOWLEDGE-MAP Section 10 lists \"Neo4j Aura free tier limits \u2192 upgrade/fallback plan\" as an external dependency TBD. ADR-010 specifies Neo4j Aura free for graph domain ontologies. The free tier has storage limits (typically 200K nodes, 400K relationships, 50MB storage on the free plan). If the platform's domain ontologies for PropSygnal/RegSygnal exceed these limits, the free tier will fail without warning. No fallback plan (upgrade to paid, self-hosted Neo4j, or alternative graph DB) is documented.\n- **Affected BL Items**: Domain modules (PropSygnal, RegSygnal) \u2014 not current v1 backlog but risk\n- **Source Evidence**: KNOWLEDGE-MAP Section 10; KNOWLEDGE-MAP Section 3 (Infrastructure & Storage)\n- **Resolution**: Assess Neo4j Aura free tier limits against the domain ontology data volume expected for v1 research module (likely well within limits). Document the fallback plan if exceeded: (1) Upgrade to Neo4j AuraDB Professional; (2) Self-hosted Neo4j Docker container. Add as a risk note in STRATEGIC-REVIEW.\n- **Owner Recommendation**: DevOps / architecture lead\n- **Wave**: W1 \u2014 low urgency for v1 research module; higher urgency for domain modules\n\n---\n\n### GAP-028 \u2014 No Migration 0005 Specification",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-028",
    "title": "[GAP-028] DEC-052 specifies that Migration 0005 is split into three sub-migrations: 0005a (DB schema changes), 0005b (LangGraph state extensions), 0005c (indices). The split is decided but the content of each sub-migration is not specified anywhere. Multiple backlog items depend on Migration 0005 (BL-005, BL-006, BL-012, BL-016, BL-018 per GAP-009). Without a specification of what tables/columns/indices are in each sub-migration, there is a risk of merge conflicts and ordering issues during implementation.",
    "body": "# [GAP-028] DEC-052 specifies that Migration 0005 is split into three sub-migrations: 0005a (DB schema changes), 0005b (LangGraph state extensions), 0005c (indices). The split is decided but the content of each sub-migration is not specified anywhere. Multiple backlog items depend on Migration 0005 (BL-005, BL-006, BL-012, BL-016, BL-018 per GAP-009). Without a specification of what tables/columns/indices are in each sub-migration, there is a risk of merge conflicts and ordering issues during implementation.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-028\n- **Severity**: MEDIUM\n- **Description**: DEC-052 specifies that Migration 0005 is split into three sub-migrations: 0005a (DB schema changes), 0005b (LangGraph state extensions), 0005c (indices). The split is decided but the content of each sub-migration is not specified anywhere. Multiple backlog items depend on Migration 0005 (BL-005, BL-006, BL-012, BL-016, BL-018 per GAP-009). Without a specification of what tables/columns/indices are in each sub-migration, there is a risk of merge conflicts and ordering issues during implementation.\n- **Affected BL Items**: BL-005, BL-006, BL-012, BL-016, BL-018\n- **Source Evidence**: DEC-052; CONSISTENCY-AUDIT-PLANS I-05, I-06, I-07\n- **Resolution**: Document MIG-0005A/b/c content: (a) 0005a: subscriptions table, usage_records table, entity_type column on relevant tables, tags schema extensions; (b) 0005b: RunState extensions (planning_hierarchy fields, cost accumulator fields); (c) 0005c: indices for entity lookup, usage aggregation, run timeline queries.\n- **Owner Recommendation**: Backend architecture lead\n- **Wave**: W0 \u2014 prerequisite for multiple BL items\n\n---\n\n### GAP-029 \u2014 Billing Port from DocuIntelli Not Verified",
    "labels": [
      "type:gap",
      "priority:P2"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-029",
    "title": "[GAP-029] DEC-036 specifies \"port working Stripe code from okestraai/DocuIntelli.\" The billing-metering-extract.md Section 10 provides a detailed port strategy (what to take, what to redesign, porting steps). However, the DocuIntelli codebase has not been inspected to verify: (1) that it uses raw body for webhook signature verification (the critical LIB-08 gotcha); (2) that its subscription model matches the NYQST schema; (3) that it doesn't have equivalent bugs to the arq worker initialization issue found in NYQST. The port plan assumes the source code is correct.",
    "body": "# [GAP-029] DEC-036 specifies \"port working Stripe code from okestraai/DocuIntelli.\" The billing-metering-extract.md Section 10 provides a detailed port strategy (what to take, what to redesign, porting steps). However, the DocuIntelli codebase has not been inspected to verify: (1) that it uses raw body for webhook signature verification (the critical LIB-08 gotcha); (2) that its subscription model matches the NYQST schema; (3) that it doesn't have equivalent bugs to the arq worker initialization issue found in NYQST. The port plan assumes the source code is correct.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-029\n- **Severity**: MEDIUM\n- **Description**: DEC-036 specifies \"port working Stripe code from okestraai/DocuIntelli.\" The billing-metering-extract.md Section 10 provides a detailed port strategy (what to take, what to redesign, porting steps). However, the DocuIntelli codebase has not been inspected to verify: (1) that it uses raw body for webhook signature verification (the critical LIB-08 gotcha); (2) that its subscription model matches the NYQST schema; (3) that it doesn't have equivalent bugs to the arq worker initialization issue found in NYQST. The port plan assumes the source code is correct.\n- **Affected BL Items**: BL-012 (billing), BL-013 (quota enforcement)\n- **Source Evidence**: billing-metering-extract.md Section 10; DEC-036; LIB-08 gotcha\n- **Resolution**: Inspect `okestraai/DocuIntelli` billing code before porting. Specifically verify: (a) raw body usage in webhook handler; (b) subscription schema compatibility; (c) no initialization-order bugs; (d) the Stripe SDK version (must be v11+ for the `StripeClient` API used in billing-metering-extract.md).\n- **Owner Recommendation**: Backend track lead (BL-012 owner)\n- **Wave**: W0 \u2014 before BL-012 implementation begins\n\n---\n\n### GAP-030 \u2014 Feature Flag Backend Not Specified for v1",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-030",
    "title": "[GAP-030] DEC-025 references experiments/feature flags. EXTRACTION-SUMMARY Section 6 (Feature Flags) confirms Superagent has `/api/feature-flags` and client-side evaluation endpoints. DEC-047 defers the clarification UI feature to v1.5 (presumably behind a feature flag). However, there is no decision specifying how v1 will implement feature flags: PostHog is excluded (DEC-064 uses Langfuse), and the DEC-025 entry is vague. The `streaming-events-extract.md` also makes no reference to a v1 feature flag mechanism.",
    "body": "# [GAP-030] DEC-025 references experiments/feature flags. EXTRACTION-SUMMARY Section 6 (Feature Flags) confirms Superagent has `/api/feature-flags` and client-side evaluation endpoints. DEC-047 defers the clarification UI feature to v1.5 (presumably behind a feature flag). However, there is no decision specifying how v1 will implement feature flags: PostHog is excluded (DEC-064 uses Langfuse), and the DEC-025 entry is vague. The `streaming-events-extract.md` also makes no reference to a v1 feature flag mechanism.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-030\n- **Severity**: MEDIUM\n- **Description**: DEC-025 references experiments/feature flags. EXTRACTION-SUMMARY Section 6 (Feature Flags) confirms Superagent has `/api/feature-flags` and client-side evaluation endpoints. DEC-047 defers the clarification UI feature to v1.5 (presumably behind a feature flag). However, there is no decision specifying how v1 will implement feature flags: PostHog is excluded (DEC-064 uses Langfuse), and the DEC-025 entry is vague. The `streaming-events-extract.md` also makes no reference to a v1 feature flag mechanism.\n- **Affected BL Items**: DEC-047 (clarification UI deferred implies a feature flag), future domain modules\n- **Source Evidence**: EXTRACTION-SUMMARY Section 6; DEC-064 (no PostHog); DEC-025; DEC-047\n- **Resolution**: Decide v1 feature flag mechanism. Options: (a) Tenant-level configuration in the database (simplest \u2014 `tenant.features JSONB`); (b) Langfuse experiment tracking (reuses existing observability); (c) Simple environment variable flags. Recommend option (a) for v1: add `features JSONB` column to tenants table in MIG-0005A.\n- **Owner Recommendation**: Architecture lead \u2014 small decision with disproportionate downstream impact\n- **Wave**: W0\n\n---\n\n### GAP-031 \u2014 Slides Generation Viewer Not Fully Specified",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-031",
    "title": "[GAP-031] BL-018 (Slides Generation) is in scope for v1. DEC for slides viewer (OQ-002 resolution) specifies: reuse iframe approach, `gml-viewpresentation` renders a link card in Phase 1/2, embedded reveal.js deferred to Phase 3. The slides generation pipeline (7 stages documented in orchestration-extract.md Section 3.3 for website) is documented for websites, but the slides-specific pipeline is not documented. The DataBrief-to-slides transformation logic and the GML tag set for presentations (`gml-viewpresentation`) are not specified.",
    "body": "# [GAP-031] BL-018 (Slides Generation) is in scope for v1. DEC for slides viewer (OQ-002 resolution) specifies: reuse iframe approach, `gml-viewpresentation` renders a link card in Phase 1/2, embedded reveal.js deferred to Phase 3. The slides generation pipeline (7 stages documented in orchestration-extract.md Section 3.3 for website) is documented for websites, but the slides-specific pipeline is not documented. The DataBrief-to-slides transformation logic and the GML tag set for presentations (`gml-viewpresentation`) are not specified.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-031\n- **Severity**: LOW\n- **Description**: BL-018 (Slides Generation) is in scope for v1. DEC for slides viewer (OQ-002 resolution) specifies: reuse iframe approach, `gml-viewpresentation` renders a link card in Phase 1/2, embedded reveal.js deferred to Phase 3. The slides generation pipeline (7 stages documented in orchestration-extract.md Section 3.3 for website) is documented for websites, but the slides-specific pipeline is not documented. The DataBrief-to-slides transformation logic and the GML tag set for presentations (`gml-viewpresentation`) are not specified.\n- **Affected BL Items**: BL-018 (Slides Generation)\n- **Source Evidence**: orchestration-extract.md Section 3.3 (website 7 stages); DEC-043 (OQ-002 resolution); KNOWLEDGE-MAP Section 5 (Document Generation Contract)\n- **Resolution**: Add slides-specific pipeline specification to BL-018 technical notes. Minimally: (1) DataBrief \u2192 slides generator LLM prompt template; (2) Output format: series of `<gml-viewpresentation>` sections with section slides; (3) Viewer: link card with download option for v1; (4) Streaming: `node_report_preview_start/delta/done` events reused with `deliverable_type: slides`.\n- **Owner Recommendation**: Backend track lead\n- **Wave**: W1 \u2014 before BL-018 implementation\n\n---\n\n### GAP-032 \u2014 Clarification Flow Resume Endpoint Not Specified",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-032",
    "title": "[GAP-032] DEC-047 defers the clarification UI to v1.5 but specifies that v1 includes \"schema + backend checkpoint.\" BL-021 covers the clarification flow. The streaming-events-extract.md documents `clarification_needed` and `update_message_clarification_message` events. However, the API endpoint that accepts user input and resumes the LangGraph run after an interrupt is not specified (no route, no request/response schema, no LangGraph checkpoint resume pattern documented).",
    "body": "# [GAP-032] DEC-047 defers the clarification UI to v1.5 but specifies that v1 includes \"schema + backend checkpoint.\" BL-021 covers the clarification flow. The streaming-events-extract.md documents `clarification_needed` and `update_message_clarification_message` events. However, the API endpoint that accepts user input and resumes the LangGraph run after an interrupt is not specified (no route, no request/response schema, no LangGraph checkpoint resume pattern documented).\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-032\n- **Severity**: LOW\n- **Description**: DEC-047 defers the clarification UI to v1.5 but specifies that v1 includes \"schema + backend checkpoint.\" BL-021 covers the clarification flow. The streaming-events-extract.md documents `clarification_needed` and `update_message_clarification_message` events. However, the API endpoint that accepts user input and resumes the LangGraph run after an interrupt is not specified (no route, no request/response schema, no LangGraph checkpoint resume pattern documented).\n- **Affected BL Items**: BL-021 (clarification flow)\n- **Source Evidence**: DEC-047; streaming-events-extract.md (Clarification Events); KNOWLEDGE-MAP Phase 4 deliverables\n- **Resolution**: Specify the resume endpoint in BL-021: `POST /api/v1/runs/{run_id}/resume` with body `{user_input: str, interrupt_id: str}`. This calls `graph.ainvoke(Command(resume=user_input), config={thread_id: run_id})` using LangGraph's interrupt/resume pattern. Add to BL-021 acceptance criteria.\n- **Owner Recommendation**: Backend track lead\n- **Wave**: W1\n\n---\n\n## Category 4: Competitive Intelligence Gaps\n\n### GAP-033 \u2014 Superagent GML Formal Spec Not Recovered",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-033",
    "title": "[GAP-033] The Superagent GML markup language is inferred from the JS bundle analysis. The EXTRACTION-SUMMARY and orchestration-extract.md document 17\u201318 GML tags with high confidence. However, the formal schema \u2014 the exact rules for which tags can nest inside which, the full attribute set for `gml-chartcontainer` props, the complete `gml-infoblockmetric` schema, and the healer's nesting rules \u2014 is inferred from code, not documented from a formal spec (which is not publicly available). The NYQST implementation must be compatible with Superagent's output but cannot verify compatibility without the formal spec.",
    "body": "# [GAP-033] The Superagent GML markup language is inferred from the JS bundle analysis. The EXTRACTION-SUMMARY and orchestration-extract.md document 17\u201318 GML tags with high confidence. However, the formal schema \u2014 the exact rules for which tags can nest inside which, the full attribute set for `gml-chartcontainer` props, the complete `gml-infoblockmetric` schema, and the healer's nesting rules \u2014 is inferred from code, not documented from a formal spec (which is not publicly available). The NYQST implementation must be compatible with Superagent's output but cannot verify compatibility without the formal spec.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-033\n- **Severity**: HIGH\n- **Description**: The Superagent GML markup language is inferred from the JS bundle analysis. The EXTRACTION-SUMMARY and orchestration-extract.md document 17\u201318 GML tags with high confidence. However, the formal schema \u2014 the exact rules for which tags can nest inside which, the full attribute set for `gml-chartcontainer` props, the complete `gml-infoblockmetric` schema, and the healer's nesting rules \u2014 is inferred from code, not documented from a formal spec (which is not publicly available). The NYQST implementation must be compatible with Superagent's output but cannot verify compatibility without the formal spec.\n- **Affected BL Items**: BL-004 (Markup AST schema), BL-009 (ReportRenderer)\n- **Source Evidence**: EXTRACTION-SUMMARY (GML inferred from 344 KB bundle); orchestration-extract.md Section 3.1 (healer rules inferred)\n- **Resolution**: Accept the inference approach as sufficient for v1 (the 18 tags and nesting rules are extracted at HIGH confidence). Document the inference confidence in the NDM v1 schema spec (GAP-017). Plan a validation step in Phase 2: generate a report using the NYQST system, compare its GML structure to a Superagent reference report, and adjust nesting rules if needed. This is acceptable risk.\n- **Owner Recommendation**: Architecture lead \u2014 risk acceptance decision\n- **Wave**: W2 \u2014 validation step post-implementation\n\n---\n\n### GAP-034 \u2014 Superagent Authentication Method Unknown",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-034",
    "title": "[GAP-034] EXTRACTION-SUMMARY Section (Gaps/Unknowns) lists \"Authentication: JWT vs session cookies unclear from bundle.\" The Superagent bundle shows `/api/session/redeem-token` and `credentials: include` on SSE requests, suggesting cookie-based sessions. NYQST uses JWT + API keys (confirmed in PLATFORM-GROUND-TRUTH). If Superagent's session-redeem pattern is something NYQST needs to replicate for enterprise SSO or shared workspace access, the design gap is unclear.",
    "body": "# [GAP-034] EXTRACTION-SUMMARY Section (Gaps/Unknowns) lists \"Authentication: JWT vs session cookies unclear from bundle.\" The Superagent bundle shows `/api/session/redeem-token` and `credentials: include` on SSE requests, suggesting cookie-based sessions. NYQST uses JWT + API keys (confirmed in PLATFORM-GROUND-TRUTH). If Superagent's session-redeem pattern is something NYQST needs to replicate for enterprise SSO or shared workspace access, the design gap is unclear.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-034\n- **Severity**: MEDIUM\n- **Description**: EXTRACTION-SUMMARY Section (Gaps/Unknowns) lists \"Authentication: JWT vs session cookies unclear from bundle.\" The Superagent bundle shows `/api/session/redeem-token` and `credentials: include` on SSE requests, suggesting cookie-based sessions. NYQST uses JWT + API keys (confirmed in PLATFORM-GROUND-TRUTH). If Superagent's session-redeem pattern is something NYQST needs to replicate for enterprise SSO or shared workspace access, the design gap is unclear.\n- **Affected BL Items**: Enterprise Shell layer (Layer 3 \u2014 post-v1)\n- **Source Evidence**: EXTRACTION-SUMMARY Section (Gaps/Unknowns); streaming-events-extract.md (Frontend Event Consumption, credentials: include)\n- **Resolution**: Assess whether Superagent's token-redeem pattern has a v1 analog in NYQST. If enterprise SSO is deferred (it is \u2014 per PLATFORM-FRAMING.md Layer 3), this gap is post-v1. Document as a known unknown in the Enterprise Shell layer specifications.\n- **Owner Recommendation**: Product lead \u2014 scope clarification\n- **Wave**: W3 \u2014 post-v1 enterprise shell\n\n---\n\n### GAP-035 \u2014 Superagent SSO Details Not Recovered",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-035",
    "title": "[GAP-035] EXTRACTION-SUMMARY notes `/api/sso/google/generate-url` is present in the Superagent API surface \"but details minimal.\" NYQST's v1 auth is JWT + API keys (DEC-038, using existing intelli auth, not Ory Kratos). The SSO design for regulated enterprise ($200k/yr) customers will require SAML/OIDC. The Superagent SSO approach is not recoverable from the bundle analysis.",
    "body": "# [GAP-035] EXTRACTION-SUMMARY notes `/api/sso/google/generate-url` is present in the Superagent API surface \"but details minimal.\" NYQST's v1 auth is JWT + API keys (DEC-038, using existing intelli auth, not Ory Kratos). The SSO design for regulated enterprise ($200k/yr) customers will require SAML/OIDC. The Superagent SSO approach is not recoverable from the bundle analysis.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-035\n- **Severity**: MEDIUM\n- **Description**: EXTRACTION-SUMMARY notes `/api/sso/google/generate-url` is present in the Superagent API surface \"but details minimal.\" NYQST's v1 auth is JWT + API keys (DEC-038, using existing intelli auth, not Ory Kratos). The SSO design for regulated enterprise ($200k/yr) customers will require SAML/OIDC. The Superagent SSO approach is not recoverable from the bundle analysis.\n- **Affected BL Items**: Layer 3 Enterprise Shell (SSO/OIDC \u2014 post-v1)\n- **Source Evidence**: EXTRACTION-SUMMARY Section (API Surface Map \u2014 Session & Auth); DEC-038; PLATFORM-FRAMING.md Layer 3\n- **Resolution**: Explicitly defer to Layer 3 Enterprise Shell. Ensure the JWT auth system in v1 is designed to accommodate SSO as an additive layer (not a replacement). Add OIDC-compatibility as a non-functional requirement for the auth system.\n- **Owner Recommendation**: Architecture lead \u2014 ensure v1 auth is SSO-extensible\n- **Wave**: W3\n\n---\n\n### GAP-036 \u2014 Multi-Channel Output Width Gap",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-036",
    "title": "[GAP-036] EXTRACTION-SUMMARY Section (Comparison to DocuIntelli Platform Primitives) notes: \"Multi-channel Output: Superagent offers Report, Website, Presentation \u2014 Superagent is wider.\" NYQST v1 scope includes Report (Phase 2), Website iframe (Phase 2), Slides (BL-018). However, Superagent's \"Generated Document\" type (`gml-viewgenerateddocument`) is not explicitly addressed in the backlog. It is unclear whether this maps to the NYQST document export (BL-019) or is a distinct output type.",
    "body": "# [GAP-036] EXTRACTION-SUMMARY Section (Comparison to DocuIntelli Platform Primitives) notes: \"Multi-channel Output: Superagent offers Report, Website, Presentation \u2014 Superagent is wider.\" NYQST v1 scope includes Report (Phase 2), Website iframe (Phase 2), Slides (BL-018). However, Superagent's \"Generated Document\" type (`gml-viewgenerateddocument`) is not explicitly addressed in the backlog. It is unclear whether this maps to the NYQST document export (BL-019) or is a distinct output type.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-036\n- **Severity**: MEDIUM\n- **Description**: EXTRACTION-SUMMARY Section (Comparison to DocuIntelli Platform Primitives) notes: \"Multi-channel Output: Superagent offers Report, Website, Presentation \u2014 Superagent is wider.\" NYQST v1 scope includes Report (Phase 2), Website iframe (Phase 2), Slides (BL-018). However, Superagent's \"Generated Document\" type (`gml-viewgenerateddocument`) is not explicitly addressed in the backlog. It is unclear whether this maps to the NYQST document export (BL-019) or is a distinct output type.\n- **Affected BL Items**: BL-018 (Slides), BL-019 (Document Export)\n- **Source Evidence**: EXTRACTION-SUMMARY (GML View Types: gml-viewreport, gml-viewwebsite, gml-viewpresentation, gml-viewgenerateddocument); KNOWLEDGE-MAP Section 5\n- **Resolution**: Clarify whether `gml-viewgenerateddocument` maps to BL-019 (Document Export \u2014 PDF/DOCX). If yes, ensure BL-019 acceptance criteria include the `gml-viewgenerateddocument` tag handling. If it is a distinct output type (e.g., \"generated data document\" as opposed to a \"report\"), determine whether it is in v1 scope or deferred.\n- **Owner Recommendation**: Product lead\n- **Wave**: W1 \u2014 before BL-018 and BL-019 implementation\n\n---\n\n### GAP-037 \u2014 Competitor Analytics Maturity Gap Not Quantified",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-037",
    "title": "[GAP-037] EXTRACTION-SUMMARY documents Superagent's analytics stack: PostHog with 5 modules (recorder, surveys, web vitals, dead-click detection, exception tracking), GA4 with 5 properties, Facebook/Twitter/LinkedIn pixels. NYQST v1 uses Langfuse for observability (DEC-037) and explicitly excludes PostHog (DEC-064). This is the correct strategic choice for a B2B enterprise platform, but the gap in behavioral analytics (session recording, funnel analysis, product analytics) is not quantified or planned for.",
    "body": "# [GAP-037] EXTRACTION-SUMMARY documents Superagent's analytics stack: PostHog with 5 modules (recorder, surveys, web vitals, dead-click detection, exception tracking), GA4 with 5 properties, Facebook/Twitter/LinkedIn pixels. NYQST v1 uses Langfuse for observability (DEC-037) and explicitly excludes PostHog (DEC-064). This is the correct strategic choice for a B2B enterprise platform, but the gap in behavioral analytics (session recording, funnel analysis, product analytics) is not quantified or planned for.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-037\n- **Severity**: LOW\n- **Description**: EXTRACTION-SUMMARY documents Superagent's analytics stack: PostHog with 5 modules (recorder, surveys, web vitals, dead-click detection, exception tracking), GA4 with 5 properties, Facebook/Twitter/LinkedIn pixels. NYQST v1 uses Langfuse for observability (DEC-037) and explicitly excludes PostHog (DEC-064). This is the correct strategic choice for a B2B enterprise platform, but the gap in behavioral analytics (session recording, funnel analysis, product analytics) is not quantified or planned for.\n- **Affected BL Items**: Enterprise Shell Layer 3 (analytics and notifications)\n- **Source Evidence**: EXTRACTION-SUMMARY Section (Analytics Stack); DEC-064; PLATFORM-FRAMING.md\n- **Resolution**: Accept the gap for v1. Document in STRATEGIC-REVIEW that product analytics (session recording, funnels) is a Layer 3 Enterprise Shell concern and will be addressed when the enterprise billing tier requires product-led growth tooling. This is an acceptable deferred risk for a $200k/yr sales-led enterprise motion.\n- **Owner Recommendation**: Product lead\n- **Wave**: W3 \u2014 post-v1\n\n---\n\n## Category 5: Operational Gaps\n\n### GAP-038 \u2014 No CI/CD Pipeline for the Platform",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-038",
    "title": "[GAP-038] No CI/CD pipeline is documented for the `nyqst-intelli-230126` platform repository. CONSISTENCY-AUDIT-ANALYSIS C-05 notes \"Deployment/containerization (no Dockerfile exists \u2014 genuine gap, no locked decision)\" from the Codex analysis. The KNOWLEDGE-MAP lists Docker for containerization but docker-compose is a dev-only setup. There is no GitHub Actions workflow, no automated test run on PR, no container build pipeline, no staging environment specification. As implementation progresses across 5 parallel tracks, the absence of CI will cause integration failures to accumulate undetected.",
    "body": "# [GAP-038] No CI/CD pipeline is documented for the `nyqst-intelli-230126` platform repository. CONSISTENCY-AUDIT-ANALYSIS C-05 notes \"Deployment/containerization (no Dockerfile exists \u2014 genuine gap, no locked decision)\" from the Codex analysis. The KNOWLEDGE-MAP lists Docker for containerization but docker-compose is a dev-only setup. There is no GitHub Actions workflow, no automated test run on PR, no container build pipeline, no staging environment specification. As implementation progresses across 5 parallel tracks, the absence of CI will cause integration failures to accumulate undetected.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-038\n- **Severity**: CRITICAL\n- **Description**: No CI/CD pipeline is documented for the `nyqst-intelli-230126` platform repository. CONSISTENCY-AUDIT-ANALYSIS C-05 notes \"Deployment/containerization (no Dockerfile exists \u2014 genuine gap, no locked decision)\" from the Codex analysis. The KNOWLEDGE-MAP lists Docker for containerization but docker-compose is a dev-only setup. There is no GitHub Actions workflow, no automated test run on PR, no container build pipeline, no staging environment specification. As implementation progresses across 5 parallel tracks, the absence of CI will cause integration failures to accumulate undetected.\n- **Affected BL Items**: All BL items \u2014 CI gates every merge\n- **Source Evidence**: CONSISTENCY-AUDIT-ANALYSIS C-05 (Codex unresolved item: \"Deployment/containerization\"); KNOWLEDGE-MAP Section 4 (DevOps & Observability); no CI files found in codebase review\n- **Resolution**: Create minimal CI pipeline: (1) GitHub Actions workflow on PR to `main`: run `pytest` (backend), `tsc --noEmit` (frontend), `alembic check` (migration drift); (2) Docker build step to validate containerization; (3) Lint step (`ruff`, `eslint`). This is a 1-day setup task that prevents weeks of integration debt.\n- **Owner Recommendation**: DevOps track; should be the first W0 task\n- **Wave**: W0 \u2014 highest priority operational task\n\n---\n\n### GAP-039 \u2014 No Phase 0 Validation Checklist Formalized",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-039",
    "title": "[GAP-039] CONSISTENCY-AUDIT-PLANS Part 4 section 3D specifies a \"Week 1 Validation Checklist\" with six verification tasks that MUST pass before Wave 1 begins. These tasks de-risk critical assumptions: arq operational (de-risks BL-016, BL-012), Send() prototype (de-risks BL-001), GmlRenderer spike (de-risks BL-009), WeasyPrint system deps (de-risks BL-019), Brave Search API (de-risks BL-003), existing tests green (de-risks all BL). This checklist exists in the audit document but has NOT been added to IMPLEMENTATION-PLAN Phase 0 or created as a GIT-ISSUES gate milestone.",
    "body": "# [GAP-039] CONSISTENCY-AUDIT-PLANS Part 4 section 3D specifies a \"Week 1 Validation Checklist\" with six verification tasks that MUST pass before Wave 1 begins. These tasks de-risk critical assumptions: arq operational (de-risks BL-016, BL-012), Send() prototype (de-risks BL-001), GmlRenderer spike (de-risks BL-009), WeasyPrint system deps (de-risks BL-019), Brave Search API (de-risks BL-003), existing tests green (de-risks all BL). This checklist exists in the audit document but has NOT been added to IMPLEMENTATION-PLAN Phase 0 or created as a GIT-ISSUES gate milestone.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-039\n- **Severity**: HIGH\n- **Description**: CONSISTENCY-AUDIT-PLANS Part 4 section 3D specifies a \"Week 1 Validation Checklist\" with six verification tasks that MUST pass before Wave 1 begins. These tasks de-risk critical assumptions: arq operational (de-risks BL-016, BL-012), Send() prototype (de-risks BL-001), GmlRenderer spike (de-risks BL-009), WeasyPrint system deps (de-risks BL-019), Brave Search API (de-risks BL-003), existing tests green (de-risks all BL). This checklist exists in the audit document but has NOT been added to IMPLEMENTATION-PLAN Phase 0 or created as a GIT-ISSUES gate milestone.\n- **Affected BL Items**: BL-001, BL-003, BL-009, BL-012, BL-016, BL-019\n- **Source Evidence**: CONSISTENCY-AUDIT-PLANS Part 4 3D; STRATEGIC-REVIEW Section 8 (Week 1 Validation Checklist)\n- **Resolution**: Add to IMPLEMENTATION-PLAN Phase 0 a mandatory \"Validation Checkpoint\" section with the six tasks. Create a blocking GIT-ISSUES milestone gate (M0-GATE) that must be closed before M1 work begins. Link each validation task to the BL items it de-risks.\n- **Owner Recommendation**: Project coordinator + engineering lead; 2-hour documentation task\n- **Wave**: P0 \u2014 must exist before Wave 0 begins\n\n---\n\n### GAP-040 \u2014 No Monitoring or Alerting Specification",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-040",
    "title": "[GAP-040] The platform has Langfuse for trace observability and LangSmith Studio for graph debugging. Neither of these is a production monitoring and alerting solution. There is no specification for: (1) application-level health monitoring (FastAPI health endpoint exists at `/health` but no uptime monitoring); (2) database monitoring (PostgreSQL connection pool exhaustion, replication lag); (3) arq worker monitoring (job queue depth, job failure rate); (4) SSE stream health (active connections, disconnection rate); (5) budget overrun alerting (when a tenant approaches their monthly quota).",
    "body": "# [GAP-040] The platform has Langfuse for trace observability and LangSmith Studio for graph debugging. Neither of these is a production monitoring and alerting solution. There is no specification for: (1) application-level health monitoring (FastAPI health endpoint exists at `/health` but no uptime monitoring); (2) database monitoring (PostgreSQL connection pool exhaustion, replication lag); (3) arq worker monitoring (job queue depth, job failure rate); (4) SSE stream health (active connections, disconnection rate); (5) budget overrun alerting (when a tenant approaches their monthly quota).\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-040\n- **Severity**: HIGH\n- **Description**: The platform has Langfuse for trace observability and LangSmith Studio for graph debugging. Neither of these is a production monitoring and alerting solution. There is no specification for: (1) application-level health monitoring (FastAPI health endpoint exists at `/health` but no uptime monitoring); (2) database monitoring (PostgreSQL connection pool exhaustion, replication lag); (3) arq worker monitoring (job queue depth, job failure rate); (4) SSE stream health (active connections, disconnection rate); (5) budget overrun alerting (when a tenant approaches their monthly quota).\n- **Affected BL Items**: BL-012 (billing alerts), BL-013 (quota alerts), cross-cutting\n- **Source Evidence**: KNOWLEDGE-MAP Section 4 (DevOps & Observability \u2014 only lists Langfuse and LangSmith Studio); billing-metering-extract.md Section 7 (monthly invoice generation \u2014 no alerting on failure)\n- **Resolution**: Define minimal v1 monitoring: (1) Uptime: use Langfuse health check endpoint + external uptime monitor (UptimeRobot free tier); (2) DB: pg_stat_statements for slow query detection; (3) arq: job failure rate logged to Langfuse trace; (4) Budget: add a webhook or email notification when tenant reaches 80% of monthly quota. Document in a new `docs/plans/OPERATIONS.md`.\n- **Owner Recommendation**: DevOps track\n- **Wave**: W1 \u2014 needed before staging deployment\n\n---\n\n### GAP-041 \u2014 No Developer Experience (DX) Tooling Spec",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-041",
    "title": "[GAP-041] KNOWLEDGE-MAP Section 9 specifies a \"Critical Knowledge Path\" for new team members (Day 1: read PLATFORM-FRAMING.md, etc.) but this is reading-based onboarding. There is no specification for: (1) a local development setup guide (`make dev` or equivalent); (2) database seeding scripts for local testing; (3) LangSmith Studio integration for local graph debugging; (4) Langfuse local instance for local trace observation; (5) mock data for development that doesn't require live API keys (Brave, Stripe).",
    "body": "# [GAP-041] KNOWLEDGE-MAP Section 9 specifies a \"Critical Knowledge Path\" for new team members (Day 1: read PLATFORM-FRAMING.md, etc.) but this is reading-based onboarding. There is no specification for: (1) a local development setup guide (`make dev` or equivalent); (2) database seeding scripts for local testing; (3) LangSmith Studio integration for local graph debugging; (4) Langfuse local instance for local trace observation; (5) mock data for development that doesn't require live API keys (Brave, Stripe).\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-041\n- **Severity**: MEDIUM\n- **Description**: KNOWLEDGE-MAP Section 9 specifies a \"Critical Knowledge Path\" for new team members (Day 1: read PLATFORM-FRAMING.md, etc.) but this is reading-based onboarding. There is no specification for: (1) a local development setup guide (`make dev` or equivalent); (2) database seeding scripts for local testing; (3) LangSmith Studio integration for local graph debugging; (4) Langfuse local instance for local trace observation; (5) mock data for development that doesn't require live API keys (Brave, Stripe).\n- **Affected BL Items**: All BL items \u2014 affects all developer velocity\n- **Source Evidence**: KNOWLEDGE-MAP Section 9 (Critical Knowledge Paths \u2014 reading-based only); CONSISTENCY-AUDIT-PLANS SC-01 (arq verification task implies no existing setup verification)\n- **Resolution**: Create a `docs/plans/DEVELOPER-SETUP.md` that specifies: (1) prerequisites check script; (2) `docker-compose up` sequence and validation; (3) database initialization command; (4) test data seeding; (5) local Langfuse + LangSmith Studio startup; (6) `.env.example` with all required variables. This is a 4-hour task that pays for itself in the first week of multi-track development.\n- **Owner Recommendation**: Any senior engineer; should be done during P0\n- **Wave**: W0\n\n---\n\n### GAP-042 \u2014 No Staging Environment Specification",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:frontend",
      "area:backend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-042",
    "title": "[GAP-042] The platform targets enterprise deployment but there is no specification for a staging environment. The only documented environments are local development (docker-compose) and production (implied). For a $200k/yr enterprise product, buyers will require sandbox testing against a non-production instance. Stripe itself requires test-mode integration before going live. Without a staging environment spec, every integration (Stripe, Langfuse, search providers) is validated in production.",
    "body": "# [GAP-042] The platform targets enterprise deployment but there is no specification for a staging environment. The only documented environments are local development (docker-compose) and production (implied). For a $200k/yr enterprise product, buyers will require sandbox testing against a non-production instance. Stripe itself requires test-mode integration before going live. Without a staging environment spec, every integration (Stripe, Langfuse, search providers) is validated in production.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-042\n- **Severity**: MEDIUM\n- **Description**: The platform targets enterprise deployment but there is no specification for a staging environment. The only documented environments are local development (docker-compose) and production (implied). For a $200k/yr enterprise product, buyers will require sandbox testing against a non-production instance. Stripe itself requires test-mode integration before going live. Without a staging environment spec, every integration (Stripe, Langfuse, search providers) is validated in production.\n- **Affected BL Items**: BL-012 (Stripe \u2014 must be tested in test mode first), BL-013\n- **Source Evidence**: billing-metering-extract.md Section 10.3 (Stripe CLI testing); KNOWLEDGE-MAP (no staging reference); PLATFORM-FRAMING.md (enterprise target)\n- **Resolution**: Define a staging environment specification: (1) Same docker-compose setup as production with `ENVIRONMENT=staging` flag; (2) Separate Stripe test-mode API keys; (3) Separate Langfuse instance or project; (4) Reduced resource allocation (single Postgres, no Neo4j); (5) Data reset capability (for demo purposes). Add to `docs/plans/OPERATIONS.md`.\n- **Owner Recommendation**: DevOps track\n- **Wave**: W1\n\n---\n\n### GAP-043 \u2014 Multi-Tenant Data Isolation Not Specified for v1",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-043",
    "title": "[GAP-043] The KNOWLEDGE-MAP confirms `workspace_id` (multi-tenant isolation) is part of all streaming events. The platform has `tenant_id` in the auth system. However, there is no document specifying the row-level security (RLS) strategy for the database, the tenant isolation guarantee for SSE streams (ensuring tenant A cannot receive tenant B's events), or the isolation of LangGraph checkpoints by tenant. For an enterprise product, this is a compliance requirement, not a nice-to-have.",
    "body": "# [GAP-043] The KNOWLEDGE-MAP confirms `workspace_id` (multi-tenant isolation) is part of all streaming events. The platform has `tenant_id` in the auth system. However, there is no document specifying the row-level security (RLS) strategy for the database, the tenant isolation guarantee for SSE streams (ensuring tenant A cannot receive tenant B's events), or the isolation of LangGraph checkpoints by tenant. For an enterprise product, this is a compliance requirement, not a nice-to-have.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-043\n- **Severity**: MEDIUM\n- **Description**: The KNOWLEDGE-MAP confirms `workspace_id` (multi-tenant isolation) is part of all streaming events. The platform has `tenant_id` in the auth system. However, there is no document specifying the row-level security (RLS) strategy for the database, the tenant isolation guarantee for SSE streams (ensuring tenant A cannot receive tenant B's events), or the isolation of LangGraph checkpoints by tenant. For an enterprise product, this is a compliance requirement, not a nice-to-have.\n- **Affected BL Items**: BL-001 (orchestrator must be tenant-scoped), all data models\n- **Source Evidence**: KNOWLEDGE-MAP (workspace_id in all events); streaming-events-extract.md (X-Gradient-Workspace-Id header); PLATFORM-FRAMING.md Layer 3 (multi-tenant isolation listed as Layer 3 concern)\n- **Resolution**: Define v1 tenant isolation: (1) All DB queries include `WHERE tenant_id = $current_tenant` (application-level isolation); (2) LangGraph `thread_id` includes `{tenant_id}:{run_id}` to prevent checkpoint namespace collisions; (3) SSE channels namespaced as `run_stream_{tenant_id}_{run_id}` in NOTIFY; (4) Document that PostgreSQL RLS is a Layer 3 enhancement (stronger isolation with row-level policies). Add to BL-001 technical notes.\n- **Owner Recommendation**: Architecture lead\n- **Wave**: W0 \u2014 must be specified before BL-001 implementation\n\n---\n\n### GAP-044 \u2014 No Data Retention or Backup Policy",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs",
      "area:frontend"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-044",
    "title": "[GAP-044] The run ledger is append-only and grows indefinitely. SSE event logs per run include the full NDJSON event stream (stored as `event_stream_artifact_id` per the Message schema). Langfuse traces accumulate. There is no documented data retention policy (how long are runs kept, how long are events kept, when are artifacts purged), no backup schedule for the PostgreSQL primary, and no disaster recovery plan.",
    "body": "# [GAP-044] The run ledger is append-only and grows indefinitely. SSE event logs per run include the full NDJSON event stream (stored as `event_stream_artifact_id` per the Message schema). Langfuse traces accumulate. There is no documented data retention policy (how long are runs kept, how long are events kept, when are artifacts purged), no backup schedule for the PostgreSQL primary, and no disaster recovery plan.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-044\n- **Severity**: LOW\n- **Description**: The run ledger is append-only and grows indefinitely. SSE event logs per run include the full NDJSON event stream (stored as `event_stream_artifact_id` per the Message schema). Langfuse traces accumulate. There is no documented data retention policy (how long are runs kept, how long are events kept, when are artifacts purged), no backup schedule for the PostgreSQL primary, and no disaster recovery plan.\n- **Affected BL Items**: BL-012 (billing records must be retained for audit), cross-cutting\n- **Source Evidence**: billing-metering-extract.md (UsageRecord table \u2014 billing audit requires long retention); streaming-events-extract.md (event_stream_artifact_id \u2014 event logs stored); no retention policy in any document\n- **Resolution**: Define a minimal v1 data retention policy: (1) Run ledger events: 90 days active, 1 year cold storage; (2) Billing records: 7 years (regulatory requirement); (3) Langfuse traces: 30 days (consistent with DEC-045 Langfuse plan); (4) Daily PostgreSQL backups via `pg_dump` to S3/MinIO; (5) Weekly backup restore tests. Add to `docs/plans/OPERATIONS.md`.\n- **Owner Recommendation**: DevOps track\n- **Wave**: W2 \u2014 before production deployment\n\n---\n\n### GAP-045 \u2014 Slice Structure Plan (CLAUDE.md Team Briefs) Not Created",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "GAP-045",
    "title": "[GAP-045] MEMORY.md (Pending Work section) notes: \"Slice structure plan (plan mode): 10 CLAUDE.md team briefs in dev repo \u2014 approved but not yet created.\" The 10 team briefs are the primary onboarding and context documents for AI agent subteams working in parallel on the 5 tracks. Without these briefs, each agent team must reconstruct context from the full document corpus, which violates the \"NEVER read full source files\" context management rule and will cause compounding context errors across parallel tracks.",
    "body": "# [GAP-045] MEMORY.md (Pending Work section) notes: \"Slice structure plan (plan mode): 10 CLAUDE.md team briefs in dev repo \u2014 approved but not yet created.\" The 10 team briefs are the primary onboarding and context documents for AI agent subteams working in parallel on the 5 tracks. Without these briefs, each agent team must reconstruct context from the full document corpus, which violates the \"NEVER read full source files\" context management rule and will cause compounding context errors across parallel tracks.\n\n_Source: reference/gaps/COMPREHENSIVE-GAP-ANALYSIS.md_\n\n## Details\n\n- **ID**: GAP-045\n- **Severity**: LOW\n- **Description**: MEMORY.md (Pending Work section) notes: \"Slice structure plan (plan mode): 10 CLAUDE.md team briefs in dev repo \u2014 approved but not yet created.\" The 10 team briefs are the primary onboarding and context documents for AI agent subteams working in parallel on the 5 tracks. Without these briefs, each agent team must reconstruct context from the full document corpus, which violates the \"NEVER read full source files\" context management rule and will cause compounding context errors across parallel tracks.\n- **Affected BL Items**: All BL items \u2014 affects parallel execution quality\n- **Source Evidence**: MEMORY.md Pending Work; KNOWLEDGE-MAP Section 9 (Critical Knowledge Paths)\n- **Resolution**: Create the 10 CLAUDE.md team briefs in the dev repo, each 1\u20132 pages covering: team scope, assigned BL items, key decisions (relevant DEC-xxx), dependencies on other teams, files they own, files they must not modify. This is a 1-day documentation task. Approved by user but not yet executed.\n- **Owner Recommendation**: Engineering lead / plan owner\n- **Wave**: P0 \u2014 must exist before any parallel agent execution\n\n---\n\n## Cross-Cutting Observations\n\n### Propagation Debt Pattern\n\nThe most pervasive gap class is **propagation debt**: decisions are made correctly in the Decision Register but are not written back to the source documents where they will be read by implementers. The project has strong decision hygiene (52+ locked decisions) but poor propagation hygiene. The CONSISTENCY-AUDIT-PLANS document correctly identifies all required propagations but is itself an intermediate artifact \u2014 the propagations still need to be applied.\n\nEstimated propagation debt resolution: 2\u20133 engineer-days of documentation work before Wave 0 implementation begins.\n\n### Production Bug Risk\n\nTwo production-blocking bugs (GAP-022, GAP-023) were confirmed by direct codebase inspection. These are not theoretical risks \u2014 they are real code paths that will fail under the exact conditions (parallel fan-out writes, arq job execution) that the BL-001 and BL-016 implementations will trigger. Both bugs have straightforward fixes (\u2264 4 hours each) but must be in place before any implementation that depends on them.\n\n### Phase 0 Validation Checkpoint Is Critical\n\nThe six-task Phase 0 validation checklist (GAP-039) is the single highest-leverage risk-reduction action available. Running these validations before any Wave 1 code is written will expose hidden infrastructure failures (arq worker, WeasyPrint system deps, API key validity) in a low-cost, low-stakes context rather than mid-implementation.\n\n---\n\n## Prioritized Resolution Order\n\n### P0 \u2014 Before Any Code Is Written (Estimated: 3\u20134 engineer-days)\n\n1. **GAP-022** \u2014 Fix sequence number race condition (CRITICAL, 4 hours)\n2. **GAP-023** \u2014 Fix arq worker registry initialization (CRITICAL, 4 hours)\n3. **GAP-001** \u2014 Propagate Plotly decision to 4 documents (CRITICAL, 2 hours)\n4. **GAP-002** \u2014 Propagate GML rendering split to affected docs (CRITICAL, 2 hours)\n5. **GAP-003** \u2014 Mark OQ-001\u2013007 as resolved in source documents (CRITICAL, 3 hours)\n6. **GAP-009** \u2014 Correct 8 blocked-by fields in GIT-ISSUES (MEDIUM, 1 hour)\n7. **GAP-010** \u2014 Move BL-015 and BL-008 to Wave 0 milestone (MEDIUM, 30 minutes)\n8. **GAP-011** \u2014 Flip BL-022 dependency arrow in IMPLEMENTATION-PLAN (MEDIUM, 15 minutes)\n9. **GAP-008** \u2014 Apply SC-01 through SC-07 stale claim corrections (MEDIUM, 2 hours)\n10. **GAP-039** \u2014 Formalize Phase 0 validation checklist in IMPLEMENTATION-PLAN (HIGH, 2 hours)\n11. **GAP-045** \u2014 Create 10 CLAUDE.md team briefs in dev repo (LOW, 8 hours)\n\n### W0 \u2014 Phase 0 Foundation (Estimated: 1 engineer-week parallel with implementation)\n\n12. **GAP-014** \u2014 Create formal Event Contract v1 document (CRITICAL, 4 hours)\n13. **GAP-017** \u2014 Formalize NDM v1 JSON schema (HIGH, 4 hours)\n14. **GAP-038** \u2014 Create minimal CI pipeline (CRITICAL, 1 day)\n15. **GAP-028** \u2014 Document MIG-0005A/b/c content (MEDIUM, 2 hours)\n16. **GAP-015** \u2014 Document tool fallback chain in BL-001 spec (HIGH, 2 hours)\n17. **GAP-025** \u2014 Langfuse deployment specification (HIGH, 2 hours)\n18. **GAP-026** \u2014 Search provider cost comparison and lock (HIGH, 2 hours)\n19. **GAP-018** \u2014 Specify MCP tool discovery algorithm (HIGH, 2 hours)\n20. **GAP-021** \u2014 Enumerate failure modes in BL-001 spec (MEDIUM, 2 hours)\n21. **GAP-043** \u2014 Specify v1 tenant isolation approach (MEDIUM, 2 hours)\n22. **GAP-041** \u2014 Create developer setup guide (MEDIUM, 4 hours)\n23. **GAP-004** \u2014 Add deferred scope section to IMPLEMENTATION-PLAN (HIGH, 1 hour)\n24. **GAP-005** \u2014 Add Index Service to platform primitives list (HIGH, 30 minutes)\n25. **GAP-006** \u2014 Add document processing pipeline decision (HIGH, 1 hour)\n26. **GAP-007** \u2014 Add infrastructure decision to DECISION-REGISTER (MEDIUM, 1 hour)\n27. **GAP-012** \u2014 Update router count in PLATFORM-GROUND-TRUTH (LOW, 5 minutes)\n28. **GAP-013** \u2014 Add `<answer>` wrapper spec to GML-RENDERING-ANALYSIS (LOW, 30 minutes)\n29. **GAP-030** \u2014 Decide feature flag mechanism for v1 (MEDIUM, 1 hour)\n\n### W1 \u2014 Phase 1 Build\n\n30. **GAP-016** \u2014 Create BL-023 (async entity worker backlog item) (HIGH, 1 hour)\n31. **GAP-024** \u2014 Decision: LiteLLM in v1 critical path? (HIGH, 2-hour design discussion)\n32. **GAP-029** \u2014 Inspect and verify DocuIntelli billing code (MEDIUM, 4 hours)\n33. **GAP-019** \u2014 Specify HITL policy evaluation order (MEDIUM, 2 hours)\n34. **GAP-020** \u2014 Specify entity reference algorithm edge cases (MEDIUM, 2 hours)\n35. **GAP-031** \u2014 Specify slides generation pipeline (LOW, 2 hours)\n36. **GAP-032** \u2014 Specify clarification resume endpoint (LOW, 1 hour)\n37. **GAP-040** \u2014 Define production monitoring and alerting (HIGH, 1 day)\n38. **GAP-042** \u2014 Define staging environment (MEDIUM, 2 hours)\n39. **GAP-036** \u2014 Clarify gml-viewgenerateddocument scope (MEDIUM, 1 hour)\n\n### W2 \u2014 Phase 2 Build\n\n40. **GAP-044** \u2014 Data retention and backup policy (LOW, 2 hours)\n41. **GAP-033** \u2014 Validate GML spec against live reference (HIGH, 4 hours)\n42. **GAP-027** \u2014 Assess Neo4j Aura free tier limits (MEDIUM, 1 hour)\n\n### W3 / Post-v1\n\n43. **GAP-034** \u2014 Superagent auth method assessment (MEDIUM \u2014 enterprise shell)\n44. **GAP-035** \u2014 SSO design for enterprise tier (MEDIUM \u2014 enterprise shell)\n45. **GAP-037** \u2014 Product analytics gap for enterprise (LOW \u2014 Layer 3)\n\n---\n\n*Revision Log:*\n\n| Date | Author | Change |\n|------|--------|--------|\n| 2026-02-20 | Claude Sonnet 4.6 (Senior Engineering Lead role) | Initial comprehensive gap analysis \u2014 synthesizes all hypothesis tests, inventory data, extract documents, and consistency audits |",
    "labels": [
      "type:gap",
      "priority:P2",
      "area:docs"
    ],
    "milestone": "GAPS: Cleanup",
    "blocked_by": [],
    "blocks": [],
    "source": "COMPREHENSIVE-GAP-ANALYSIS.md"
  },
  {
    "id": "NX-001",
    "title": "[NX-001] Skills framework v1 (registry, versioning, permissions)",
    "body": "# [NX-001] Skills framework v1 (registry, versioning, permissions)\n\n**Inspiration**\n- \u201cSkills\u201d in products like Claude/Cowork are essentially: packaged toolchains + permissions + a context bundle.\n- NYQST already has primitives to do this (MCP tools, pointers, manifests, runs). This issue makes them first-class.\n\n**Goal**\n- Define, store, and run \u201cskills\u201d as versioned assets:\n  - A skill declares required tools, allowed connectors, default prompts, and optional UI surfaces.\n  - A skill can be attached to a project/workspace and used by agents.\n\n**Scope**\nBackend:\n- Skill model + migrations:\n  - `skills` (id, tenant_id, name, description, version, manifest_pointer_id, permissions JSON, created_by, created_at)\n  - `skill_versions` (optional if versions are manifests)\n- CRUD API:\n  - list/create/update/publish (publish = pin a version)\n- Permission model:\n  - explicit allowlist of tools/connectors; no implicit access.\n\nFrontend:\n- Skills library page:\n  - list skills, view versions, publish/unpublish\n- Skill detail page:\n  - show tools, permissions, linked knowledge pointers, test-run button\n\n**Acceptance criteria**\n- You can create a skill, version it, and attach it to a run.\n- A run fails fast if a skill requests a tool that is not permitted.\n- Skills are tenant-scoped; cross-tenant access blocked.\n\n**References**\n- Repo PRD docs under `docs/prd/` (skills + platform primitives).\n",
    "labels": [
      "type:feature",
      "area:platform",
      "priority:P2"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "PRD/Vision digest"
  },
  {
    "id": "NX-002",
    "title": "[NX-002] Tool directory UI + permission gating for MCP tools (Claude-style directory pattern)",
    "body": "# [NX-002] Tool directory UI + permission gating for MCP tools (Claude-style directory pattern)\n\n**Problem**\nMCP server exists, but there is no first-class \u201ctool directory\u201d surface for:\n- discovery (what tools exist)\n- permissions (what this tenant/project can use)\n- observability (what tools were called)\n\n**Goal**\n- A UI and API that behaves like a tool marketplace/directory:\n  - list available tools (built-in + external MCP servers)\n  - enable/disable per tenant/project\n  - show required scopes (read/write)\n  - audit log of tool invocations\n\n**Implementation**\nBackend:\n- Extend MCP tool registry to expose structured tool metadata (name, description, args schema, scopes).\n- Add `tool_grants` table keyed by tenant_id/project_id/tool_name.\n- Enforce tool grants in the tool-calling layer (deny by default).\n\nFrontend:\n- Add \u201cTools\u201d page:\n  - directory list\n  - enable/disable toggle\n  - tool detail drawer (args, scopes, example)\n- Add \u201cRun \u2192 Tool calls\u201d panel for auditability (pull from run events).\n\n**Acceptance criteria**\n- Disabling a tool prevents calls (and surfaces a clear error).\n- Tool list is accurate and generated from the runtime registry.\n\n",
    "labels": [
      "type:feature",
      "area:mcp",
      "area:frontend",
      "priority:P2"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "Cowork/MCP patterns"
  },
  {
    "id": "NX-003",
    "title": "[NX-003] Connector platform integration (Composio + n8n) as optional tool providers",
    "body": "# [NX-003] Connector platform integration (Composio + n8n) as optional tool providers\n\n**Goal**\n- Integrate at least one connector platform to accelerate SaaS integrations:\n  - Composio (prebuilt app actions)\n  - n8n (workflow engine + webhooks)\n\n**Approach**\n- Treat connector platforms as *tool providers* behind MCP:\n  - Provide an MCP server adapter that exposes connector actions as tools.\n  - Standardize auth secrets handling (tenant scoped).\n\n**Implementation steps**\n1. Add a `connectors` module:\n   - connector definitions (provider, name, scopes, auth_type)\n   - secret storage integration (vault / KMS later; env for dev)\n2. Composio:\n   - Add a provider adapter that lists actions and invokes them.\n   - Map action schemas to MCP tool schemas.\n3. n8n:\n   - Add webhook trigger tool and a \u201crun workflow\u201d tool.\n4. Add UI:\n   - Connectors page (connect account, manage scopes)\n5. Threat model:\n   - prevent prompt injection / data exfil; explicit permission prompts.\n\n**Acceptance criteria**\n- User can connect a SaaS account and run a tool call against it from an agent.\n- All connector calls are logged as run events and tied to tenant.\n\n",
    "labels": [
      "type:feature",
      "area:connectors",
      "priority:P2",
      "security"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "Vision digest + external connector patterns"
  },
  {
    "id": "NX-004",
    "title": "[NX-004] NotebookLM-style \u201cResearch Notebook\u201d (SurfSense-inspired) using existing substrate primitives",
    "body": "# [NX-004] NotebookLM-style \u201cResearch Notebook\u201d (SurfSense-inspired) using existing substrate primitives\n\n**Goal**\nDeliver an opinionated \u201cnotebook\u201d workflow:\n- upload/attach multiple documents\n- auto-summarize and extract entities/claims\n- chat with citations grounded in the attached corpus\n- keep generated notes as versioned artifacts\n\n**Leverage existing repo**\n- Notebooks + pointers exist in UI.\n- Artifact/Manifest/Pointer primitives exist in backend.\n- RAG/OpenSearch exists.\n\n**Missing**\n- Notebook-specific indexing strategy (per-notebook corpus)\n- Entity/citation persistence\n- UX patterns: \u201csources on the right\u201d, \u201cnotes panel\u201d, \u201cevidence map\u201d\n\n**Implementation**\nBackend:\n- Add notebook corpus index keying (workspace_id + notebook_id).\n- Add endpoints:\n  - attach/detach docs to notebook\n  - generate notebook summary artifact\n  - list extracted entities/claims for notebook\nFrontend:\n- Notebook workspace view:\n  - doc list, notes list, chat pane\n  - citations jump-to-source\n\n**Acceptance criteria**\n- A notebook can be created, populated with docs, and queried with grounded answers.\n- Every answer includes citations that resolve to stored source artifacts.\n\n",
    "labels": [
      "type:feature",
      "area:product",
      "priority:P2"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "SurfSense/NotebookLM pattern"
  },
  {
    "id": "NX-005",
    "title": "[NX-005] Dify-style \u201cApps\u201d system (configure and publish agent workflows)",
    "body": "# [NX-005] Dify-style \u201cApps\u201d system (configure and publish agent workflows)\n\n**Goal**\nAllow non-engineers to configure and publish an \u201cApp\u201d:\n- choose base agent graph template\n- configure tools + permissions\n- attach knowledge bases (pointers)\n- set input schema (form)\n- define output type (deliverable)\n- publish versioned app; run it inside projects\n\n**Key design decisions**\n- Apps are versioned manifests/pointers (don\u2019t invent new storage).\n- Apps run through the same Run ledger + event stream.\n- Apps should be exportable/importable (JSON).\n\n**Implementation**\nBackend:\n- `apps` table (tenant_id, name, description, latest_version_pointer_id, status)\n- `app_versions` as manifests (or explicit table)\n- API: create/version/publish/run\nFrontend:\n- Apps library + App builder:\n  - \u201cConfigure\u201d screen (tools/knowledge/output)\n  - \u201cRun app\u201d screen (inputs + run timeline + deliverable panel)\n\n**Acceptance criteria**\n- Can publish an app and run it repeatedly with different inputs.\n- Runs are reproducible: rerunning the same app version + inputs yields the same plan structure (within model stochasticity).\n\n",
    "labels": [
      "type:feature",
      "area:product",
      "priority:P3"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "Dify patterns"
  },
  {
    "id": "NX-006",
    "title": "[NX-006] Analysis canvas v1 (infinite canvas with entity/run/doc nodes + provenance links)",
    "body": "# [NX-006] Analysis canvas v1 (infinite canvas with entity/run/doc nodes + provenance links)\n\n**Goal**\nA first usable \u201cinfinite canvas\u201d for analysis:\n- place nodes representing artifacts, entities, runs, and notes\n- draw links; links carry provenance (why this edge exists)\n- embed excerpts + citations\n\n**Leverage**\n- Entities + citations tables (MIG-0005B)\n- Artifact/pointer primitives\n\n**Implementation**\nBackend:\n- `canvases` (tenant_id, project_id, name)\n- `canvas_nodes` (canvas_id, node_type, entity_id/artifact_id/run_id, x,y,w,h, meta)\n- `canvas_edges` (canvas_id, from_node, to_node, relation_type, provenance JSON)\nFrontend:\n- Canvas UI (ReactFlow or similar):\n  - node palette, drag/drop, edge creation\n  - side panel shows node details + citations\n- Persist layout via API\n\n**Acceptance criteria**\n- Create a canvas, add nodes, reload page \u2192 layout persists.\n- Clicking an entity shows citations; clicking citation opens source doc.\n\n",
    "labels": [
      "type:feature",
      "area:frontend",
      "priority:P3"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "Vision digest"
  },
  {
    "id": "NX-007",
    "title": "[NX-007] Structured diffing for deliverables (report/markdown/doc) with provenance-aware highlights",
    "body": "# [NX-007] Structured diffing for deliverables (report/markdown/doc) with provenance-aware highlights\n\n**Goal**\nWhen a deliverable is regenerated, users can see what changed and why:\n- semantic diff at section level (not just line diff)\n- each changed section shows the run/task/tool event that caused it\n\n**Implementation**\n- Store deliverable sections as structured JSON (or manifest tree nodes).\n- Diff algorithm:\n  - align sections by stable IDs\n  - diff content with fallback to text diff\n- UI:\n  - \u201cCompare versions\u201d view\n  - highlight changes and show provenance panel\n\n**Acceptance criteria**\n- Two versions of a report can be compared and differences are readable.\n- Each diff chunk can link back to run events and citations.\n\n",
    "labels": [
      "type:feature",
      "area:product",
      "priority:P3"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "Product vision"
  },
  {
    "id": "NX-008",
    "title": "[NX-008] Agent management UI (create/clone agents, assign tools, set guardrails)",
    "body": "# [NX-008] Agent management UI (create/clone agents, assign tools, set guardrails)\n\n**Goal**\nMake agents configurable assets:\n- manage system prompts, model choice, tool set, context policy, and max spend\n- clone agents\n- assign to projects/apps\n\n**Implementation**\nBackend:\n- `agents` table (tenant_id, name, config JSON, status)\n- API: CRUD + \u201ctest\u201d endpoint\nFrontend:\n- Agents page:\n  - list, create, edit\n  - tool assignment with permissions\n  - guardrails (max cost, max tokens, restricted connectors)\n\n**Acceptance criteria**\n- An agent can be created and used in a run without code changes.\n- Guardrails are enforced server-side.\n\n",
    "labels": [
      "type:feature",
      "area:platform",
      "priority:P3",
      "security"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "Vision digest"
  },
  {
    "id": "NX-009",
    "title": "[NX-009] Observability: LangSmith + OpenTelemetry baseline (traces, costs, tool calls)",
    "body": "# [NX-009] Observability: LangSmith + OpenTelemetry baseline (traces, costs, tool calls)\n\n**Goal**\n- End-to-end trace visibility for:\n  - agent runs\n  - tool calls\n  - retrieval\n  - deliverable generation\n- Costs attributed per run + per tenant.\n\n**Implementation**\n1. Add LangSmith instrumentation to LangGraph execution (traces + metadata).\n2. Add OpenTelemetry SDK (FastAPI + DB + Redis) for infra-level spans.\n3. Correlate:\n   - trace_id \u2194 run_id \u2194 tenant_id\n4. Surface minimal \u201cTrace\u201d link in UI run view.\n\n**Acceptance criteria**\n- A run produces a LangSmith trace containing:\n  - model calls, tool calls, retrieval spans\n- A run view shows a working trace link (in dev at least).\n\n",
    "labels": [
      "type:feature",
      "area:observability",
      "priority:P2"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "User requirement (langsmith)"
  },
  {
    "id": "NX-010",
    "title": "[NX-010] Security hardening for agentic connectors (prompt injection + file/tool safety)",
    "body": "# [NX-010] Security hardening for agentic connectors (prompt injection + file/tool safety)\n\n**Goal**\nAs the system becomes more agentic (Cowork-like), enforce safety controls:\n- least privilege tool permissions\n- content security for retrieved web/doc content (prompt injection stripping)\n- explicit confirmation for destructive actions\n- audit log for every tool invocation\n\n**Implementation**\n- Add a \u201ctool firewall\u201d layer:\n  - allow/deny, rate limits, sensitive scopes\n- Add prompt-injection mitigations:\n  - sanitize tool outputs (especially web)\n  - separate instruction channels\n- Add \u201cdestructive action confirmation\u201d events and UI confirmations.\n\n**Acceptance criteria**\n- Disallowed tools cannot be invoked even if the model tries.\n- Destructive actions require user approval and leave an audit trail.\n\n",
    "labels": [
      "type:feature",
      "security",
      "priority:P1",
      "area:platform"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "Cowork safety notes"
  },
  {
    "id": "NX-011",
    "title": "[NX-011] Knowledge base manager v1 (Dify-style): ingestion, chunking policy, reindex, doc status",
    "body": "# [NX-011] Knowledge base manager v1 (Dify-style): ingestion, chunking policy, reindex, doc status\n\n**Goal**\nProvide an operator/user UI for managing \u201cknowledge bases\u201d:\n- upload docs into a KB\n- set chunking + embedding policy\n- show indexing status + errors\n- reindex / delete\n- evaluate retrieval quality\n\n**Leverage**\n- Existing document upload + RAG/OpenSearch services.\n- Existing pointers/manifests for storing KB membership manifests.\n\n**Implementation**\nBackend:\n- KB model (tenant_id, name, description, config JSON)\n- membership links (kb_id \u2192 pointer_id or document_id)\n- indexing job queue + status table\n\nFrontend:\n- Knowledge Bases page:\n  - list KBs\n  - create KB\n  - view documents, index status, reindex\n\n**Acceptance criteria**\n- A KB can be created and used by an agent as its retrieval scope.\n- Index status is visible and actionable.\n\n",
    "labels": [
      "type:feature",
      "area:rag",
      "area:frontend",
      "priority:P3"
    ],
    "milestone": "M6+: Product Modules",
    "blocked_by": [],
    "blocks": [],
    "source": "Dify analysis"
  },
  {
    "id": "NX-012",
    "title": "[NX-012] Add optional NDJSON fetch streaming for run events (Superagent-style) alongside SSE",
    "body": "# [NX-012] Add optional NDJSON fetch streaming for run events (Superagent-style) alongside SSE\n\n**Why**\nSome environments/proxies handle chunked fetch streaming more reliably than native EventSource, and Superagent uses NDJSON over `fetch + ReadableStream`.\n\n**Goal**\n- Keep SSE endpoint (current) but add an alternative:\n  - `GET /api/v1/streams/runs/{run_id}?transport=ndjson`\n  - or `GET /api/v1/runs/{run_id}/stream.ndjson`\n\n**Implementation**\n- Backend: same event payloads; different framing:\n  - SSE: `data: {json}\\n\\n`\n  - NDJSON: `{json}\\n`\n- Frontend: add a hook that can use either transport.\n\n**Acceptance criteria**\n- Both transports deliver identical event objects.\n- A feature flag can switch transport.\n\n",
    "labels": [
      "type:feature",
      "area:streaming",
      "priority:P3"
    ],
    "milestone": "M5+: Platform Extensions",
    "blocked_by": [],
    "blocks": [],
    "source": "Superagent patterns"
  }
]