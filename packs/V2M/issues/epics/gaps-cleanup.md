# GAPS: Cleanup

Issues: 45

## Included issues
- [GAP-001] DEC-048 locks Plotly.js (`react-plotly.js`) as the chart library. This is correct and grounded in Superagent bundle analysis (Superagent uses Plotly via `gml-chartcontainer`). However, the decision has NOT been written back into four documents that still specify Recharts: IMPLEMENTATION-PLAN section 3.6, GIT-ISSUES BL-009 acceptance criteria ("CHART nodes render as Recharts charts"), STRATEGIC-REVIEW (recommended Recharts for bundle size), and the LIBRARY-REFERENCE LIB-13 section. A developer reading any of these documents will use the wrong library.
- [GAP-002] DEC-015 was split into DEC-015a (backend MarkupDocument JSON AST, used by BL-004/BL-005 report generation) and DEC-015b (frontend GML rendering uses rehype-to-JSX, NOT a JSON AST intermediate layer). This split resolves the conflict between DEC-015 and GML-RENDERING-ANALYSIS. However, multiple documents still reference the old undivided DEC-015 and the conflict is still listed as open. CONSISTENCY-AUDIT-ANALYSIS Section 5.3 flagged this as the "most significant unresolved conflict in the entire document set." GML-RENDERING-ANALYSIS's Section 4 recommendation (skip JSON AST, use rehype-to-JSX) is NOW CORRECT under DEC-015b, but the document doesn't know this because DEC-015 was not split when GML-RENDERING-ANALYSIS was written.
- [GAP-003] OQ-001 through OQ-007 were resolved in DECISION-REGISTER v2 with new decisions DEC-042–052 (as of 2026-02-19). However, documents that originally asked these questions still show them as open. A developer reading STRATEGIC-REVIEW Section 8 will see seven unresolved questions. GML-RENDERING-ANALYSIS OQ-005 framing is based on a false premise that has since been resolved by DEC-043 (separate ReportPanel). CODEX-ANALYSIS-SUMMARY lists infrastructure choices as "Unresolved" that are in fact locked (Auth: DEC-038, Web search: DEC-032/DEC-046, Observability: DEC-037).
- [GAP-004] The PRD (03_PLATFORM.md) specifies six integrated modules: Research, Document Management, Analysis (infinite canvas), Modelling (provable methods), Knowledge & Domain, and Organisational Insight. The IMPLEMENTATION-PLAN v3 frames work as "ten platform primitives" validated through the Research Module. The Analysis Module (infinite canvas for visual analysis) does not appear anywhere in BL-001 through BL-022. There is no explicit statement in the IMPLEMENTATION-PLAN that the Analysis Module is deferred and why. A product manager or new team member reading both documents cannot determine the deferred scope without cross-referencing all six modules against the backlog.
- [GAP-005] ADR-004 specifies the Index Service Architecture (contract-first, pluggable backends: OpenSearch + pgvector). The KNOWLEDGE-MAP confirms it is a key platform component. However, the IMPLEMENTATION-PLAN's "ten platform primitives" list does not include the Index Service. It is documented in the ADR and referenced in PLATFORM-FRAMING.md, but a developer building the primitives would not know it belongs at Layer 1 from reading the IMPLEMENTATION-PLAN alone.
- [GAP-006] ADR-007 specifies a tiered document processing pipeline (Fast, Standard, Deep) with parser adapters (Docling primary, Unstructured fallback, LlamaParse optional). DECISION-REGISTER has DEC-030 (PDF export via WeasyPrint) and DEC-033 (Jina Reader API), but there is no decision capturing the tiered pipeline strategy itself. A developer implementing document ingestion would not know the three-tier approach is specified in ADR-007 or that Docling is the primary parser.
- [GAP-007] ADR-010 specifies the bootstrap infrastructure: PostgreSQL + pgvector + Neo4j + Redis. The DECISION-REGISTER has no infrastructure decision. DEC-037 mentions Langfuse self-hosted but not the database or cache infrastructure. A team member tasked with environment setup has no single locked decision to point to for infrastructure.
- [GAP-008] CONSISTENCY-AUDIT-PLANS Part 3 identifies seven stale claims (SC-01 through SC-07) in planning documents that have not been corrected. The most impactful: (a) IMPLEMENTATION-PLAN "What We Get For Free" table lists arq background jobs as "Available" when the worker process operational status is unverified; (b) GIT-ISSUES BL-016 claims "arq + Redis already configured" implying it works; (c) DECISION-REGISTER DEC-040 says GML healer is Python/Pydantic when the frontend healer is TypeScript/HAST.
- [GAP-009] CONSISTENCY-AUDIT-PLANS Part 4 section 2A identifies eight blocked-by field errors in GIT-ISSUES. Specifically: BL-003 incorrectly lists BL-001 as a blocker (it is independent); BL-022 incorrectly lists BL-001 as a blocker (the direction is reversed — BL-022 design FEEDS BL-001); BL-005, BL-006, BL-018 omit Migration 0005 as a hard dependency; BL-012 acknowledges but doesn't formally list Migration 0005; BL-016 omits Migration 0005.
- [GAP-010] BL-015 (DeliverableStore Zustand slice) and BL-008 (DeliverableSelector component) have no dependencies and can start in Week 1 (Wave 0). Both are currently assigned to `phase:3-frontend` and Milestone M3 in GIT-ISSUES — an artifact of "all frontend in Phase 3" waterfall thinking. This means frontend work that unblocks other items is scheduled 8–10 weeks later than it needs to be.
- [GAP-011] IMPLEMENTATION-PLAN dependency graph shows `BL-022 (Data Brief, design only) ◄─ BL-001`, placing BL-022 as downstream of BL-001. DEPENDENCY-ANALYSIS explicitly corrects this: the DataBrief schema design (BL-022) must precede BL-001 because BL-001 (Research Orchestrator) requires the DataBrief state field definitions to be locked first. The arrow is directionally wrong, and the critical path description `BL-002 → BL-001 → BL-022 → ...` is incorrect.
- [GAP-012] PLATFORM-GROUND-TRUTH.md states "11 routers" for the API surface. Direct codebase inspection (hypothesis-code-alignment.md H5) confirmed 12 routers — the tags router was added in migration 0004 and is not included in the documented count.
- [GAP-013] DEC-022 locks the LLM output format as `<answer>...</answer>` XML wrapper with `<gml-*>` tags inside. GML-RENDERING-ANALYSIS (which specifies the complete GML rendering pipeline) does not mention the `<answer>` wrapper at all. There is no specification for where and how the wrapper is stripped before the GML content reaches the renderer.
- [GAP-014] The streaming-events-extract.md documents 22 confirmed Superagent event types plus 4 NYQST proposed types, with complete Pydantic schemas and the NDJSON envelope format. The orchestration-extract.md documents the full fan-out dispatch pattern. However, there is no document that specifies the explicit integration contract between the two: which LangGraph events (on_tool_start, on_chat_model_stream, on_end) map to which SSE event types (node_tool_event, message_delta, done). The LangGraphToAISDKAdapter pseudocode in streaming-events-extract.md is an example, not a locked contract.
- [GAP-015] Superagent's orchestration shows a clear tool failure cascade: FactSet → SEC Filings → AlphaVantage → FinancialModelingPrep. This "FALLBACK_CHAINS" pattern is documented in orchestration-extract.md Section 4.2 with explicit code. BL-001 (Research Orchestrator Graph) is the backlog item that must implement this pattern. However, BL-001's spec (MAPPING-01) does not explicitly design the fallback chain mechanism. The term "fallback" appears in the backlog context but the algorithm (try primary → emit fallback_used event → try secondary → emit all_tools_failed if all fail) is not in the spec.
- [GAP-016] DEC-017 specifies "Async entity creation: Decoupled from main response stream via arq background worker." PLATFORM-GROUND-TRUTH confirms `has_async_entities_in_progress` flag exists. BL-016 covers the entity/citation substrate schema. However, there is no dedicated backlog item for "Implement async entity creation worker" — the arq background job that processes entities after the main stream completes. The work is mentioned in DEC-017 and BL-016 body text but is not a standalone, estimable, assignable item.
- [GAP-017] The KNOWLEDGE-MAP Section 10 explicitly lists "NDM v1 exact JSON schema (sketched in SUPERAGENT_PARITY_PLAN §3.4, needs formalization)" as a needed-soon open thread. The orchestration-extract.md specifies the DataBrief schema (BL-022) but the NDM (NYQST Document Markup) v1 schema — the JSON AST format used for report generation (DEC-015a) — is only sketched. BL-004 (Markup AST schema) depends on this being locked before implementation.
- [GAP-018] KNOWLEDGE-MAP Section 10 lists "MCP tool discovery filtering (context-scoped, needs algorithm for 'is tool X relevant to session Y?')" as a needed-soon open thread. ADR-008 specifies MCP as the tool protocol with session-scoped discovery. DEC-046 locks MCP search (hot-swap Brave/Tavily). However, the algorithm for how the orchestrator decides which MCP tools are available in a given session context is not specified. This matters because the Research Orchestrator (BL-001) must know which tools to include in a given PlanTask.
- [GAP-019] ADR-009 defines four HITL governance templates (Exploratory, Standard, Regulated, Audit-Critical). KNOWLEDGE-MAP Section 10 lists "Policy evaluation order (ADR-009 lists 4 templates, needs conflict resolution)" as an open thread. When a run is configured with a governance template, the exact precedence rules for when to interrupt vs. continue are not specified. DEC-047 defers the clarification UI to v1.5 but the backend schema and interrupt logic are in scope for v1.
- [GAP-020] KNOWLEDGE-MAP Section 10 lists "Entity reference algorithm (sketched, needs edge cases: citations, tool outputs, deliverables)" as a needed-soon open thread. BL-016 covers the entity/citation substrate, but the exact deduplication algorithm (content-hash-based? URL-based? Both?), the algorithm for resolving inline citation identifiers to entity IDs in the GML output, and the behavior when an entity is referenced in both a deliverable and a tool output are not specified.
- [GAP-021] The streaming-events-extract.md documents the connection lifecycle and retry strategy (exponential backoff, 5 attempts). The orchestration-extract.md documents the graceful degradation hierarchy (tool error → task error → plan error → run error). However, there is no document that enumerates what happens at each failure level from the platform's perspective: what state is written to the DB, what SSE events are emitted, what the user sees, and how the run is marked in the Run ledger. The "what happens if ALL fallback tools fail" case (orchestration-extract.md Section 6, open question 9) is still open.
- [GAP-022] Direct codebase inspection confirmed a TOCTOU (time-of-check-to-time-of-use) race condition in `src/intelli/repositories/runs.py` `_get_next_sequence` method. The method SELECT MAX(sequence_num) then INSERT with MAX+1. Under concurrent parallel task execution (which BL-001 Send() fan-out will trigger), multiple tasks can SELECT the same MAX value and attempt to INSERT with the same sequence_num+1, violating the unique constraint `(run_id, sequence_num)`. This causes data corruption in the run ledger under load.
- [GAP-023] Direct codebase inspection confirmed that `WorkerSettings.functions` in `src/intelli/core/jobs.py` is evaluated as a class variable at class definition time (module import). At that point, `_job_registry` is still empty because the `@job()` decorators on functions defined below `WorkerSettings` have not yet run. The result: ARQ worker starts with an empty functions list and silently ignores all job submissions. This means any code relying on arq background workers (BL-016 async entity creation, BL-012 billing batch jobs) will appear to work but jobs will never execute.
- [GAP-024] DEC-042 specifies LiteLLM multi-provider hot-swap for v1.5+ (OpenAI-only for v1). The billing-metering-extract.md documents the LiteLLM + Langfuse integration pattern in detail (Router, callbacks, cost tracking via Langfuse REST API). However, KNOWLEDGE-MAP Section 10 explicitly lists "LiteLLM hot-swap implementation (DEC-042, designed but not coded)" as a deferred item. The current platform uses `langchain_openai.ChatOpenAI` directly. The cost tracking pipeline described in billing-metering-extract.md Section 4.2 requires LiteLLM to be in place for Langfuse to capture per-call costs automatically.
- [GAP-025] DEC-045 locks Langfuse self-hosted (MIT license) for observability and billing data. KNOWLEDGE-MAP Section 10 lists "Langfuse self-hosted deployment (sizing, backup strategy)" as an external dependency TBD. The docker-compose.yml has a `profiles: ["observability"]` profile referenced in hypothesis-code-alignment.md H8 discussion, but there is no specification for: Langfuse container resource sizing, backup strategy, data retention policy, or how the Langfuse REST API will be accessed from the FastAPI backend for billing queries.
- [GAP-026] DEC-046 specifies MCP search with hot-swap Brave/Tavily. KNOWLEDGE-MAP Section 10 lists "Search provider selection (Brave API vs Tavily, cost comparison needed)" as an external dependency TBD. DEC-032 (original) locked Brave Search API, superseded by DEC-046 which adds Tavily as an alternative but does not select between them. BL-003 (web research MCP tools) must implement one as the default with the other as the fallback — but which is primary is not specified.
- [GAP-027] KNOWLEDGE-MAP Section 10 lists "Neo4j Aura free tier limits → upgrade/fallback plan" as an external dependency TBD. ADR-010 specifies Neo4j Aura free for graph domain ontologies. The free tier has storage limits (typically 200K nodes, 400K relationships, 50MB storage on the free plan). If the platform's domain ontologies for PropSygnal/RegSygnal exceed these limits, the free tier will fail without warning. No fallback plan (upgrade to paid, self-hosted Neo4j, or alternative graph DB) is documented.
- [GAP-028] DEC-052 specifies that Migration 0005 is split into three sub-migrations: 0005a (DB schema changes), 0005b (LangGraph state extensions), 0005c (indices). The split is decided but the content of each sub-migration is not specified anywhere. Multiple backlog items depend on Migration 0005 (BL-005, BL-006, BL-012, BL-016, BL-018 per GAP-009). Without a specification of what tables/columns/indices are in each sub-migration, there is a risk of merge conflicts and ordering issues during implementation.
- [GAP-029] DEC-036 specifies "port working Stripe code from okestraai/DocuIntelli." The billing-metering-extract.md Section 10 provides a detailed port strategy (what to take, what to redesign, porting steps). However, the DocuIntelli codebase has not been inspected to verify: (1) that it uses raw body for webhook signature verification (the critical LIB-08 gotcha); (2) that its subscription model matches the NYQST schema; (3) that it doesn't have equivalent bugs to the arq worker initialization issue found in NYQST. The port plan assumes the source code is correct.
- [GAP-030] DEC-025 references experiments/feature flags. EXTRACTION-SUMMARY Section 6 (Feature Flags) confirms Superagent has `/api/feature-flags` and client-side evaluation endpoints. DEC-047 defers the clarification UI feature to v1.5 (presumably behind a feature flag). However, there is no decision specifying how v1 will implement feature flags: PostHog is excluded (DEC-064 uses Langfuse), and the DEC-025 entry is vague. The `streaming-events-extract.md` also makes no reference to a v1 feature flag mechanism.
- [GAP-031] BL-018 (Slides Generation) is in scope for v1. DEC for slides viewer (OQ-002 resolution) specifies: reuse iframe approach, `gml-viewpresentation` renders a link card in Phase 1/2, embedded reveal.js deferred to Phase 3. The slides generation pipeline (7 stages documented in orchestration-extract.md Section 3.3 for website) is documented for websites, but the slides-specific pipeline is not documented. The DataBrief-to-slides transformation logic and the GML tag set for presentations (`gml-viewpresentation`) are not specified.
- [GAP-032] DEC-047 defers the clarification UI to v1.5 but specifies that v1 includes "schema + backend checkpoint." BL-021 covers the clarification flow. The streaming-events-extract.md documents `clarification_needed` and `update_message_clarification_message` events. However, the API endpoint that accepts user input and resumes the LangGraph run after an interrupt is not specified (no route, no request/response schema, no LangGraph checkpoint resume pattern documented).
- [GAP-033] The Superagent GML markup language is inferred from the JS bundle analysis. The EXTRACTION-SUMMARY and orchestration-extract.md document 17–18 GML tags with high confidence. However, the formal schema — the exact rules for which tags can nest inside which, the full attribute set for `gml-chartcontainer` props, the complete `gml-infoblockmetric` schema, and the healer's nesting rules — is inferred from code, not documented from a formal spec (which is not publicly available). The NYQST implementation must be compatible with Superagent's output but cannot verify compatibility without the formal spec.
- [GAP-034] EXTRACTION-SUMMARY Section (Gaps/Unknowns) lists "Authentication: JWT vs session cookies unclear from bundle." The Superagent bundle shows `/api/session/redeem-token` and `credentials: include` on SSE requests, suggesting cookie-based sessions. NYQST uses JWT + API keys (confirmed in PLATFORM-GROUND-TRUTH). If Superagent's session-redeem pattern is something NYQST needs to replicate for enterprise SSO or shared workspace access, the design gap is unclear.
- [GAP-035] EXTRACTION-SUMMARY notes `/api/sso/google/generate-url` is present in the Superagent API surface "but details minimal." NYQST's v1 auth is JWT + API keys (DEC-038, using existing intelli auth, not Ory Kratos). The SSO design for regulated enterprise ($200k/yr) customers will require SAML/OIDC. The Superagent SSO approach is not recoverable from the bundle analysis.
- [GAP-036] EXTRACTION-SUMMARY Section (Comparison to DocuIntelli Platform Primitives) notes: "Multi-channel Output: Superagent offers Report, Website, Presentation — Superagent is wider." NYQST v1 scope includes Report (Phase 2), Website iframe (Phase 2), Slides (BL-018). However, Superagent's "Generated Document" type (`gml-viewgenerateddocument`) is not explicitly addressed in the backlog. It is unclear whether this maps to the NYQST document export (BL-019) or is a distinct output type.
- [GAP-037] EXTRACTION-SUMMARY documents Superagent's analytics stack: PostHog with 5 modules (recorder, surveys, web vitals, dead-click detection, exception tracking), GA4 with 5 properties, Facebook/Twitter/LinkedIn pixels. NYQST v1 uses Langfuse for observability (DEC-037) and explicitly excludes PostHog (DEC-064). This is the correct strategic choice for a B2B enterprise platform, but the gap in behavioral analytics (session recording, funnel analysis, product analytics) is not quantified or planned for.
- [GAP-038] No CI/CD pipeline is documented for the `nyqst-intelli-230126` platform repository. CONSISTENCY-AUDIT-ANALYSIS C-05 notes "Deployment/containerization (no Dockerfile exists — genuine gap, no locked decision)" from the Codex analysis. The KNOWLEDGE-MAP lists Docker for containerization but docker-compose is a dev-only setup. There is no GitHub Actions workflow, no automated test run on PR, no container build pipeline, no staging environment specification. As implementation progresses across 5 parallel tracks, the absence of CI will cause integration failures to accumulate undetected.
- [GAP-039] CONSISTENCY-AUDIT-PLANS Part 4 section 3D specifies a "Week 1 Validation Checklist" with six verification tasks that MUST pass before Wave 1 begins. These tasks de-risk critical assumptions: arq operational (de-risks BL-016, BL-012), Send() prototype (de-risks BL-001), GmlRenderer spike (de-risks BL-009), WeasyPrint system deps (de-risks BL-019), Brave Search API (de-risks BL-003), existing tests green (de-risks all BL). This checklist exists in the audit document but has NOT been added to IMPLEMENTATION-PLAN Phase 0 or created as a GIT-ISSUES gate milestone.
- [GAP-040] The platform has Langfuse for trace observability and LangSmith Studio for graph debugging. Neither of these is a production monitoring and alerting solution. There is no specification for: (1) application-level health monitoring (FastAPI health endpoint exists at `/health` but no uptime monitoring); (2) database monitoring (PostgreSQL connection pool exhaustion, replication lag); (3) arq worker monitoring (job queue depth, job failure rate); (4) SSE stream health (active connections, disconnection rate); (5) budget overrun alerting (when a tenant approaches their monthly quota).
- [GAP-041] KNOWLEDGE-MAP Section 9 specifies a "Critical Knowledge Path" for new team members (Day 1: read PLATFORM-FRAMING.md, etc.) but this is reading-based onboarding. There is no specification for: (1) a local development setup guide (`make dev` or equivalent); (2) database seeding scripts for local testing; (3) LangSmith Studio integration for local graph debugging; (4) Langfuse local instance for local trace observation; (5) mock data for development that doesn't require live API keys (Brave, Stripe).
- [GAP-042] The platform targets enterprise deployment but there is no specification for a staging environment. The only documented environments are local development (docker-compose) and production (implied). For a $200k/yr enterprise product, buyers will require sandbox testing against a non-production instance. Stripe itself requires test-mode integration before going live. Without a staging environment spec, every integration (Stripe, Langfuse, search providers) is validated in production.
- [GAP-043] The KNOWLEDGE-MAP confirms `workspace_id` (multi-tenant isolation) is part of all streaming events. The platform has `tenant_id` in the auth system. However, there is no document specifying the row-level security (RLS) strategy for the database, the tenant isolation guarantee for SSE streams (ensuring tenant A cannot receive tenant B's events), or the isolation of LangGraph checkpoints by tenant. For an enterprise product, this is a compliance requirement, not a nice-to-have.
- [GAP-044] The run ledger is append-only and grows indefinitely. SSE event logs per run include the full NDJSON event stream (stored as `event_stream_artifact_id` per the Message schema). Langfuse traces accumulate. There is no documented data retention policy (how long are runs kept, how long are events kept, when are artifacts purged), no backup schedule for the PostgreSQL primary, and no disaster recovery plan.
- [GAP-045] MEMORY.md (Pending Work section) notes: "Slice structure plan (plan mode): 10 CLAUDE.md team briefs in dev repo — approved but not yet created." The 10 team briefs are the primary onboarding and context documents for AI agent subteams working in parallel on the 5 tracks. Without these briefs, each agent team must reconstruct context from the full document corpus, which violates the "NEVER read full source files" context management rule and will cause compounding context errors across parallel tracks.
