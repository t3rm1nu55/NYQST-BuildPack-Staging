# SuperAgent Generation Pipeline (Reverse-Engineered)

Forensic reconstruction of how Airtable SuperAgent generates v0.app report exports, based on artifact analysis across three reports.

**Date**: 2026-02-16
**Confidence**: High for structural findings, medium for orchestration details, speculative for server-side stages.

---

## Evidence Base

| Evidence | Source | What It Proves |
|----------|--------|----------------|
| Identical timestamps on all files | Reports B & C (104/113 files each) | Atomic server-side export, not interactive development |
| Git history with 4 named agents | Report A's `.git/` | Multi-agent parallel execution for visualization building |
| `"Generated by Superagent."` | Footer of all 3 reports | SuperAgent is the product/orchestrator |
| `generator: 'v0.app'` | layout.tsx metadata, all 3 reports | v0.app is the code generation engine |
| `[v0] Failed to load D3:` | Report B, knowledge-graph-explorer.tsx | v0.app debug artifacts not cleaned before export |
| `"name": "my-v0-project"` | package.json, all 3 reports | Default v0.app project name, never customized |
| 181,174-byte identical UI bundle | Reports B & C `components/ui/` | Frozen template dump, not generated per-report |
| 93-byte pnpm-lock.yaml | Reports B & C | Stub lockfile — deps never resolved, pure source export |
| Cross-file data consistency | Report C (MSFT $281.7B in 5+ files) | Shared data context/brief feeds all generators |
| `/* ───── DATA ───── */` separators | Report C widgets (all 10) | System prompt specifies component scaffold structure |
| Identical import ordering | Report C widgets (all 10) | System prompt enforces import conventions |
| `next.config: ignoreBuildErrors: true` | Reports B & C | Generated code may have type issues; pragmatic flag |
| No `.next/`, no `node_modules/` | Reports B & C | Never built or run — pure code generation |
| Vestigial `styles/globals.css` | Reports B & C (never imported) | Template artifact not cleaned up |
| `use-mobile` duplicated in hooks/ AND ui/ | Reports B & C | Template bundle includes hook; report scaffold also generates it |
| `.duplicate` files with SHA-256 hashes | Reports B & C `public/` | v0.app uses content-addressed file storage |

---

## Pipeline Stages

### Stage 0: Research / Data Collection

**Evidence**: Report C contains 5-year financial time series for AAPL/MSFT/GOOG across revenue, net income, operating cash flow, plus quarterly interpolations, AI capability scores, ESG metrics, and regional revenue breakdowns. These figures are internally consistent across sections and widgets (e.g., MSFT FY2025 revenue of $281.7B appears identically in competitive-matrix, dynamic-financial-chart, financial-performance prose, and executive-summary).

**Inference**: An upstream process (RAG, web search, or Airtable data ingestion) produces a structured "data brief" before code generation begins. This brief is shared across all downstream generators to ensure consistency.

**Confidence**: Medium. The consistency is proven; the mechanism is inferred.

### Stage 1: Template Assembly

**Evidence**: The `components/ui/` directory is byte-for-byte identical between Reports B and C (181,174 bytes, 57 files). Also identical: `lib/utils.ts`, `components.json`, `tsconfig.json`, `next.config.mjs`, `postcss.config.mjs`, `pnpm-lock.yaml`, `public/` directory contents, `hooks/use-toast.ts`, `hooks/use-mobile.ts`, `components/theme-provider.tsx`.

**What ships**: A pre-built package containing:
- 57 shadcn/ui components (8 custom SuperAgent additions, ~45 modified stock, ~5 unchanged stock)
- Standard utility hooks (use-mobile, use-toast)
- Configuration files (tsconfig, next.config, postcss, components.json)
- Utility functions (lib/utils.ts with `cn()` helper)
- Public assets (favicon SVGs, placeholder images with content-hash dedup)
- Vestigial default theme CSS (styles/globals.css — never imported)

**Confidence**: High. Byte-identical comparison is conclusive.

### Stage 2: Architecture Decision

**Evidence**: Three distinct architectural patterns observed:

| Report | page.tsx | Pattern | Component Organization |
|--------|----------|---------|----------------------|
| A | 997 lines | Monolithic | All HTML + data inline in single file |
| B | 567 lines | Coordinator | Imports 20 components, some inline JSX for wrappers |
| C | 30 lines | Pure composition | Imports only, zero inline JSX |

Report C introduces a new `components/sections/` layer not present in B, creating four tiers: ui → report → sections → widgets.

**Inference**: The system selects an architecture mode based on content complexity, report topic, or possibly an evolving default. The progression may also reflect v0.app platform improvements over time.

**Confidence**: Medium. The patterns are clear; the selection mechanism is unknown.

### Stage 3: Theme / Design System Generation

**Evidence**: Each report has a distinct design system:

| Report | Theme Name | Primary | Accent | Shadows | Fonts |
|--------|-----------|---------|--------|---------|-------|
| A | (default shadcn) | OKLCH blue | — | None | Geist, Geist Mono |
| B | "Royal Blue Corporate Theme" | #1e3a8a | #dbeafe (light blue) | None | Inter, Geist Mono, Playfair Display |
| C | "Soft Brutalism - Royal Blue Theme" | #1e3a8a | #ea580c (muted orange) | 4px offset | Inter, Space Grotesk, IBM Plex Mono |

Generated per-report:
- `app/globals.css` — CSS variables, brand tokens, animation keyframes, custom utilities
- `app/layout.tsx` — Font imports, metadata (title, description), viewport config
- `hooks/use-scroll-reveal.ts` — Implementation varies to match CSS animation strategy (Report B returns `{ref, isRevealed}` with React state; Report C returns just `ref` with CSS class toggle)

**Confidence**: High. The variation is proven; whether themes are from presets or free-form generation is unknown.

### Stage 4: Layout Primitive Generation

**Evidence**: Report B has 7 layout primitives in `components/report/`. Report C has 11 layout primitives in `components/report/`. They share the same concepts but with different implementations:

| Concept | Report B | Report C |
|---------|----------|----------|
| Section container | `section-wrapper.tsx` (alternate: boolean) | `section-wrapper.tsx` (variant: 4 options) |
| Metric display | `info-metric-card.tsx` (sentiment colors) | `metric-card.tsx` (sentiment + brutalist shadows + dark variant) |
| Content layout | `content-row.tsx` (grid + sidebar) | `content-columns.tsx` (flex + sticky sidebar) |
| Widget wrapper | `interactive-placeholder.tsx` | `widget-placeholder.tsx` (brutalist border + icon title bar) |
| Navigation | `sticky-nav.tsx` (intersection observer) | — (ToC replaces sticky nav) |
| — | — | `table-of-contents.tsx` (NEW) |
| — | — | `section-header.tsx` (NEW: numbered badges) |
| — | — | `prose.tsx` (NEW: typography wrapper) |
| — | — | `insight-box.tsx` (NEW: 3 color variants) |
| — | — | `block-quote.tsx` (NEW: brutalist styled) |

All primitives are fully parameterized with zero domain-specific content.

**Confidence**: High. The components exist and are clearly report-agnostic.

### Stage 5: Content Section Generation

**Evidence**: Report C introduces `components/sections/` (8 files) — a layer not present in Report B. Each section follows a consistent composition pattern:

```tsx
<SectionWrapper id="..." variant="sunken">
  <SectionHeader sectionNumber="02" title="..." subtitle="..." />
  <ContentColumns sidebar={<MetricCard ... />}>
    <Prose><p>Domain content from data brief...</p></Prose>
    <InsightBox variant="teal"><p>Strategic insight...</p></InsightBox>
    <WidgetWrapper><InteractiveWidget /></WidgetWrapper>
  </ContentColumns>
</SectionWrapper>
```

In Report B, this composition logic lived inline in `page.tsx`. Report C extracts it to dedicated components.

**Confidence**: High for the pattern; medium for whether this is a newer capability or report-specific decision.

### Stage 6: Interactive Widget Generation

**Evidence**: All 10 Report C widgets follow an identical scaffold:

```
1. "use client" directive
2. React imports (useState, useCallback, useMemo)
3. cn() utility import
4. useScrollReveal hook import
5. Recharts imports (if charting)
6. Lucide icon imports
7. /* ───── DATA ───── */ separator
8. TypeScript interfaces
9. const data arrays (inline, from data brief)
10. /* ───── COMPONENTS ───── */ separator
11. Sub-components as named functions
12. /* ───── MAIN ───── */ separator
13. Default export of main component
```

Widget sizes cluster between 506-685 lines (8 of 10), suggesting a per-component output budget.

Per-widget dependencies are injected into package.json:
- Report B: `d3` added for knowledge-graph-explorer
- Report C: `react-simple-maps` added for geographic-heat-map

**Confidence**: High for scaffold pattern and dependency injection. The system prompt itself is inferred, not observed.

### Stage 7: Atomic Export

**Evidence**: Every file in Reports B (104 files) and C (113 files) has the exact same modification timestamp. This means the entire project — template bundle, generated code, configuration — is written to the filesystem in a single operation.

The export is a source-code bundle, not a runnable project:
- No `node_modules/` (dependencies never installed)
- No `.next/` (never built)
- `pnpm-lock.yaml` is a 93-byte stub (no resolved dependencies)
- `next.config: ignoreBuildErrors: true` (pragmatic — generated code may have minor type issues)

**Confidence**: High. Timestamp evidence is conclusive.

---

## Multi-Agent Execution

### Direct Evidence (Report A)

Report A's git history and `INSIGHTS.md` explicitly document parallel agent execution:

```
Phase 1: Standards agent creates chart-styles.ts, conventions doc
Phase 2: 4 agents work in parallel on feature branches:
  - Agent A: LineChartDemo, BarChartDemo (cartesian)
  - Agent B: ScatterPlotDemo, HistogramDemo (analytical)
  - Agent C: HeatmapDemo (custom CSS Grid)
  - Agent D: SankeyDemo, TreemapDemo (specialized)
Phase 3: Integration agent merges, fixes type errors, validates build
```

Each agent completed in ~100 seconds. The standards phase ran first; the integration phase ran last.

### Indirect Evidence (Reports B & C)

The atomic export of B and C hides internal timing. We cannot determine from the artifacts whether they also used parallel agents. However, the consistent widget scaffold in Report C (10 widgets, identical structure) is consistent with either:
- A single agent generating sequentially with a strong system prompt
- Multiple agents generating in parallel with shared conventions

---

## Output Limits

| Metric | Report A | Report B | Report C |
|--------|----------|----------|----------|
| Zip size | 13K | 161K | 155K |
| Total output | 288K | 562K | 506K |
| Template bundle | N/A | 181K | 181K |
| Generated TSX | 115K (2,719 lines) | 342K (9,286 lines) | 286K (7,206 lines) |

Reports B and C cluster near ~550K total output (~350K generated). Widget sizes in Report C are remarkably uniform (506-685 lines for 8 of 10 widgets), suggesting a per-component or total output budget.

---

## Relationship: SuperAgent vs v0.app

**SuperAgent** = The orchestrator/product layer. Handles:
- User interaction and prompt processing
- Research/RAG (data brief generation)
- Architecture and design system decisions
- Multi-agent coordination
- Report branding ("Generated by Superagent.")

**v0.app** = The code generation engine. Handles:
- React/TypeScript code synthesis
- Template bundle management
- File system export
- Component scaffold enforcement
- Dependency resolution

SuperAgent calls v0.app as a backend service to generate the actual code, then exports the result as a zip file.

---

## Open Questions

1. **Is the architecture decision (monolithic/coordinator/four-tier) automated or user-selected?**
2. **Are design systems ("Soft Brutalism", "Royal Blue Corporate") from presets or generated per-prompt?**
3. **Does v0.app always use the full 57-component template, or can it ship a stripped version?** (Report A's 3-component bundle suggests the latter, but may be from an older version.)
4. **What triggers D3 vs Recharts vs react-simple-maps selection?** Widget type? User prompt? Report complexity?
5. **Is the ~550K output ceiling a hard limit or a soft target?**
6. **Does the research/RAG stage use web search, Airtable data, or user-provided documents?**
